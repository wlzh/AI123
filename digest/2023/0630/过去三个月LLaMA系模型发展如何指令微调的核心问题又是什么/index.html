

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>过去三个月，LLaMA系模型发展如何？指令微调的核心问题又是什么？ 作者： 机器之心 来源： [机器之心](https://mp.weixin.qq.com/s/cXPNyOeK9vFjJcgxc_LqZQ) 机器之心发布 作者：符尧 符尧（yao.fu@ed.ac.uk），爱丁堡大学 (University of Edinburgh) 博士生，本科毕业于北京大学。  | AI123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AI123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-cCAOSG8MBO" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2073588164294660"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://ai123.869hr.uk/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://ai123.869hr.uk/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AI123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">过去三个月，LLaMA系模型发展如何？指令微调的核心问题又是什么？</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://ai123.869hr.uk/about>AI123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              June 30, 2023 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8DABrm9t9S5pEM5G7D8B3D3ibguE5ID8q1tPbFcd4NAAAxktg6keQOTfZovdxyxjJAMDB9CRzHibfg/640?wx_fmt=png" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <pre><code>作者： 机器之心  来源： [机器之心](https://mp.weixin.qq.com/s/cXPNyOeK9vFjJcgxc_LqZQ)
</code></pre>
<p>机器之心发布</p>
<p><strong>作者：符尧</strong></p>
<blockquote>
<p>符尧（yao.fu@ed.ac.uk），爱丁堡大学 (University of Edinburgh) 博士生，本科毕业于北京大学。</p>
</blockquote>
<p>ChatGPT 大火之后，在 2023 年 2 月 24 日，LLaMA 的出现让 instruction tuning 这个方向变得火热；3 月 18 日，Alpaca 让大家看到从成熟的模型 distill 小模型成为还不错的 ChatBot 的可能性，从而引发羊驼系模型寒武纪大爆发。但仅仅过去三个月，大家开始发现意识到用 ChatGPT 的数据训练 LLaMA 的各种问题。本文回顾在过去三个月内的 LLaMA 系模型的发展，讨论 Instruction Tuning 的下一步挑战。</p>
<p>Disclaimer: 这篇文章算是一个 quick research memo，是从我近期的一个分享大纲里 edit 出来的，做了一些删减和补充；现阶段开源社区对于 LLM 训练清楚 / 不清楚的地方同时存在，我尽量做到引用 / 讨论的内容都是有切实证据，而不是基于流言。很多的内容是我跟对应论文的原作者直接讨论过的。但即便这样，我的 take 也可能有误，很多也讨论不出来，所以请大家直接在评论区 comment，积极参与讨论，真理越辩越明。</p>
<p><strong>目录</strong></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8DABrm9t9S5pEM5G7D8B3D3ibguE5ID8q1tPbFcd4NAAAxktg6keQOTfZovdxyxjJAMDB9CRzHibfg/640?wx_fmt=png" alt=""></p>
<p><strong>1 - 起源</strong></p>
<p>最开始三篇</p>
<ul>
<li>
<p>InstructGPT: Training language models to follow instructions with human feedback</p>
</li>
<li>
<p>FLANv1: Finetuned Language Models Are Zero-Shot Learners</p>
</li>
<li>
<p>T0: Multitask Prompted Training Enables Zero-Shot Task Generalization</p>
</li>
</ul>
<p>对比</p>
<ul>
<li>
<p>InstructGPT 的目标是对齐，zero-shot /cross lingual 是副产物</p>
</li>
<li>
<p>这篇文章用的 7B 的 Reward model 来对应 175B 的 Policy model，然后被 DeepSpeed Chat 以及之后一系列 RL 的开源工作 follow，这种做法应该是错的。</p>
</li>
<li>
<p>正确的做法应该是用 Reward model scale up 换取 policy model 减小，见 <a href="https://arxiv.org/abs/2210.10760">Scaling Laws for Reward Model Overoptimization</a> — 也就是说把两个模型大小换过来，用 175B 的 reward 去 PPO 7B 的 policy</p>
</li>
<li>
<p>模型上线现阶段 10-50B 是一个比较跑得起的量级，再大太贵了</p>
</li>
<li>
<p>FLANv1 和 T0 的目标是 zero-shot，所以不对齐</p>
</li>
</ul>
<p>然后是 Self-instruct</p>
<ul>
<li>Self-Instruct: Aligning Language Models with Self-Generated Instructions</li>
</ul>
<p>注意 self-instruct 的重点</p>
<ul>
<li>
<p>Base model 可以是任意，不需要是经过了 alignment 之后的模型 (ChatGPT)</p>
</li>
<li>
<p>复现了从初代 davinci 到 text-davinci-001 的过程 — 非常 insightful!!</p>
</li>
</ul>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8DABrm9t9S5pEM5G7D8B3DuicWweb46cqXNgrx4icyLZh4v8kVIYDibQPDTNuWDpVcgw9xUKlIQgnibQ/640?wx_fmt=png" alt=""></p>
<p>然后是 FLANv2 — 很重要，我可能读了十遍以上，建议背诵全文</p>
<ul>
<li>
<p>Scaling Instruction-Finetuned Language Models</p>
</li>
<li>
<p>效果除了不加 human preference 之外其他都加，等下专门讨论</p>
</li>
<li>
<p>Human preference 确实是喜欢能说的，但是能说的模型不一定能干活。Flan 能干活，但是不能说，跟程序员一样</p>
</li>
</ul>
<p><strong>2 - LLaMA 出现之后</strong></p>
<ul>
<li>
<p><strong>Alpaca</strong> ：起始文章，但是模型本身强度并不多高</p>
</li>
<li>
<p><strong>Vicuna</strong> ****</p>
</li>
<li>
<p>在开源中只做对话强度不错，格式符合人类喜好，生成内容多，unique token 多</p>
</li>
<li>
<p>Automatic eval 中，可能 in-context learning /reasoning/knowledge suboptimal (体现在 MMLU，BBH 分数)，不是说它不行，而是说它可以更好</p>
</li>
<li>
<p>GPT-4 eval 到底行不行还不好说，LMSys 团队自己说行，前提是 prompt engineering 做得足够到位：Judging LLM-as-a-judge with MT-Bench and Chatbot Arena</p>
</li>
<li>
<p>另外 LMSys 的团队在 efficiency 方面非常强，模型的 serve 看 <a href="https://github.com/vllm-project/vllm">vllm</a> 这个 project，或许是开源最快的</p>
</li>
<li>
<p>然后<strong>一系列以 GPT-4 做 judge 然后号称自己达到了 GPT3.5 x% 水准的模型，全部不推荐，因为 Eval 不可靠</strong></p>
</li>
<li>
<p>但是存在几篇工作在 alignment 的时候没有依赖 ChatGPT，这些工作推荐，它们包括</p>
</li>
<li>
<p>LIMA: Less Is More for Alignment — 关注他们选数据的方法，推荐花一个小时的时间把他们的 <a href="https://huggingface.co/datasets/GAIR/lima">数据</a> 有感情地朗读一遍，这样就知道什么样的 SFT 的数据是好数据了</p>
</li>
<li>
<p>Dromedary: Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision — 关注他们 prompt engineering 的方法，这个基本上是一个 LLaMA 版的 Constitutional AI - SFT</p>
</li>
<li>
<p>然后是一些 paper （终于） 开始分析 instruction tuning 的 data mixture</p>
</li>
<li>
<p>Tulu: How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources</p>
</li>
<li>
<p>结果非常 mix，没办法下结论哪种 mixture 好</p>
</li>
<li>
<p>但是知道哪种不好：NLP benchmark</p>
</li>
</ul>
<p><strong>3 - Eval 怎么做</strong></p>
<p>首先，不要在一堆 benchmark 上算分数看平均，特别是不要在 GPT-3 的测试任务上看平均，因为平均下来大家都一样；推荐只看核心的有区分度的 benchmark</p>
<p>没有区分度的例子：</p>
<ul>
<li>
<p><strong>LM-Eval-Harness</strong> （https://github.com/EleutherAI/lm-evaluation-harness） ，benchmark 太多，平均下来掩盖优质 benchmark</p>
</li>
<li>
<p>这里面其实涵盖了 MMLU 和 MATH，但是被其他数据集平均了</p>
</li>
<li>
<p>Summarization + Rouge / Translation + BLEU:</p>
</li>
<li>
<p>Rouge 和 BLEU 模型强弱只有四五分的差别，数字太小 v.s. accuracy 下模型强弱是 90 分和 10 分的差别，数字足够大</p>
</li>
<li>
<p>Rouge 和 BLEU 和人类偏好不 align — 注意 BLEU 也不完全 align</p>
</li>
</ul>
<p>那么 Pretrain 建议看哪些呢？</p>
<ul>
<li>
<p>区分度，模型强弱需要能一眼看出</p>
</li>
<li>
<p>分方向，现阶段可以暂时分成</p>
</li>
<li>
<p>英文知识 — MMLU</p>
</li>
<li>
<p>中文知识 — C-Eval</p>
</li>
<li>
<p>推理 — GSM8k / BBH</p>
</li>
<li>
<p>代码 — HumanEval / MBPP</p>
</li>
<li>
<p>解决上面四项平衡之后，可以接着做</p>
</li>
<li>
<p>MATH：高难度 reasoning</p>
</li>
<li>
<p>Dialog：这个可能只有 human eval 才行，automatic eval 搞不定</p>
</li>
</ul>
<p>接下来讲 Automatic Eval</p>
<p><strong>Automatic Eval</strong>  - 适合 pretrained checkpoint - 基本上可以看 <a href="https://github.com/FranxYao/chain-of-thought-hub">https://github.com/FranxYao/chain-of-thought-hub</a> 的做法</p>
<ul>
<li>
<p><strong>Knowledge</strong> : MMLU</p>
</li>
<li>
<p>这个数据集很稳定，基本上没有 sensitivity issue</p>
</li>
<li>
<p><strong>Reasoning</strong> :</p>
</li>
<li>
<p>GSM8k: 也比较稳定，但要注意答案提取函数的提出率，低于九十的话得多加 regular expression</p>
</li>
<li>
<p><strong>BBH - Algorithmic:</strong></p>
</li>
<li>
<p>不是很稳定，需要注意答案提出率</p>
</li>
<li>
<p><strong>BBH - Language:</strong></p>
</li>
<li>
<p>不是很稳定，需要注意答案提出率 — Chain-of-thought Hub 马上会出一个答案提出率对于结果的 sensitivity 的分析，结论是 BBH 比较 sensitive</p>
</li>
<li>
<p>现在除了增大模型之外，还不清楚哪些操作可以增加 BBH 数据集上的分数</p>
</li>
<li>
<p><strong>Coding</strong> :</p>
</li>
<li>
<p>Human Eval / MBPP: 似乎比较稳定但需要注意做 unbiased estimation</p>
</li>
<li>
<p>先看上面的几个数据集，分数能够 match llama 之后，就看 MATH</p>
</li>
<li>
<p><strong>MATH</strong> ：</p>
</li>
<li>
<p>超级难，GPT-4 的分数</p>
</li>
<li>
<p>naive prompting: 42</p>
</li>
<li>
<p>→ complexity based prompting: 50 <a href="https://openreview.net/forum?id=yf1icZHC-l9">https://openreview.net/forum?id=yf1icZHC-l9</a></p>
</li>
<li>
<p>→ progressive hint prompting: 53 <a href="https://arxiv.org/abs/2304.09797">https://arxiv.org/abs/2304.09797</a></p>
</li>
<li>
<p>→ majority voting over 18k: 69.6</p>
</li>
<li>
<p>→ best of n with outcome based reward modeling: 72.4</p>
</li>
<li>
<p>→ best of n with <a href="https://arxiv.org/abs/2305.20050">process-based reward modeling</a>: 78.2</p>
</li>
<li>
<p>→ PPO + process-based reward modeling = ? 推测会上 90</p>
</li>
<li>
<p>泛化？— 应该是比较强的，泛化一般而言跟基础模型大小正相关，跟 SFT 数据总量负相关，跟 SFT 数据丰富度正相关</p>
</li>
<li>
<p>如果不是 GPT-4</p>
</li>
<li>
<p>Minerva / PaLM-2: 34.3</p>
</li>
<li>
<p>Galactica: 33.6 — 这篇文章操作很好，因为 Hallucination 被喷下架导致重要性被严重低估</p>
</li>
<li>
<p>88B paper + 7B code + 7B encyclopedias, textbooks and educational material + 2B KB + 1B CC + 0.4B prompt /instruction * 4 epochs</p>
</li>
<li>
<p>LLaMA 65B: 10.6</p>
</li>
<li>
<p>其他：低于 10 分</p>
</li>
</ul>
<p>对于一个已经 finetune 成了 chatbot 的模型</p>
<ul>
<li>
<p>首先把上述 benchmark 用 few-shot 的方式过一遍，确保不要掉点</p>
</li>
<li>
<p>如果只是 dialog finetuning 的话可能会伤已有的能力 (MMLU / BBH)</p>
</li>
<li>
<p>如果掉点，则考虑 LM mixing / FLANv2 mixing</p>
</li>
<li>
<p>注意 Chatbot 的 few-shot prompting 要用 dialog 的版本因为 single round 里塞很多 in-context example 模型可能不 instruction-following 不够强，见 CoT Hub 的 standard prompt library（https://github.com/FranxYao/chain-of-thought-hub/blob/main/spl/gsm8k/chat/few_shot_cot.chatml）</p>
</li>
<li>
<p>然后就是去 eval 用户偏好了，这个时候只能人做</p>
</li>
<li>
<p>如果有很大的，已经训练好了的 reward model，可以用它 eval 上线的小型 / 中等模型，这个其实跟人做 eval 区别不大</p>
</li>
<li>
<p>对于一个很大的 Policy Model</p>
</li>
<li>
<p>Online iterative RLHF 前期怎样都需要需要 expert eval</p>
</li>
<li>
<p>后期需要 expert eval <a href="https://arxiv.org/abs/2206.05802">with AI assistance</a></p>
</li>
</ul>
<p>那么能不能用稍微弱一点的模型做 eval 呢？— 可以用，但是注意 query 的难度和分布，注意 prompt engineering</p>
<ul>
<li>
<p>如果不经过 prompt engineering ，肯定不行，因为各种 bias</p>
</li>
<li>
<p>如果 query 难度不够，diversity 不够，也不一定行</p>
</li>
<li>
<p>如果 query 难度足够 + 经过了疯狂 prompt engineering，则对于 information seeking 类型的 eval ，或许可以，see <a href="https://arxiv.org/abs/2306.05685">https://arxiv.org/abs/2306.05685</a></p>
</li>
<li>
<p>但是对于 reasoning 相关，non-information seeking 相关（比如 TLDR），又不一定行</p>
</li>
<li>
<p>对于 information seeking 相关的 query 会 biased 到长的回复</p>
</li>
</ul>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8DABrm9t9S5pEM5G7D8B3DHiaFkfu1BXgfuDVuK5dYgqMxx2gMbJKHa3r3s5jj8ibyMbcdCGtaC9LA/640?wx_fmt=png" alt=""></p>
<p><em>回复越长，GPT-4 越喜欢，分越高</em></p>
<p><strong>4 - FLANv2 的效果，Long-Context</strong></p>
<p>FLANv2 是一个很神奇的数据集，它除了不加 user preference 之外什么都加</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8DABrm9t9S5pEM5G7D8B3Dlt67YjA24yt347libYNIa7g58g1cVlx7CEqrrtl0g8YAbRbwkvfiaQdQ/640?wx_fmt=png" alt=""></p>
<ul>
<li>
<p>注意 CoT prompting</p>
</li>
<li>
<p>只在 62B 之后才会比 Direct 更好</p>
</li>
<li>
<p>不加 knowledge (MMLU) 只加 reasoning (BBH)</p>
</li>
<li>
<p>FLANv2 增加的效果有</p>
</li>
<li>
<p>knowledge (MMLU)</p>
</li>
<li>
<p>reasoning (BBH)</p>
</li>
<li>
<p>Multilingual (TyDiQA / MGSM)</p>
</li>
<li>
<p>注意 FLAN 的作者们验证过，没有数据泄露</p>
</li>
<li>
<p>注意以上内容对 in-context learning 和 zero-shot 均成立</p>
</li>
<li>
<p>但是 FLAN 的回复短，所以不加 user preference — Flan 的性格就像直男，能干活儿，话太少</p>
</li>
</ul>
<p>注意区分数据泄漏和分布内泛化</p>
<ul>
<li>
<p>如果一个数据集的测试集被用来训练模型，叫做数据泄漏，此时模型的分数会特别高，不可信</p>
</li>
<li>
<p>如果一个数据集的训练集被用来训练模型，叫做分布内泛化，此时模型的分数是可信的</p>
</li>
<li>
<p>有些数据集分布内泛化的难度不高，比如 MMLU / C-Eval，基本上做 data scaling 就可以加分</p>
</li>
<li>
<p>有些数据集，如果模型不强，即使看过了训练集，模型在测试集上也做不好，比如 GSM8K — 这种类型的数据集是优质 eval 数据集</p>
</li>
<li>
<p>代码的难度可能介于 MMLU 和 GSM8k 之间，分布内泛化不像 GSM8K 那么难，但也不简单</p>
</li>
</ul>
<p>然后根据最近Zero-Scrolls 上的数据(<a href="https://www.zero.scrolls-benchmark.com/leaderboard">https://www.zero.scrolls-benchmark.com/leaderboard</a>)，FLAN 还可以加 Long-context Reasoning ，不知道为什么</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8DABrm9t9S5pEM5G7D8B3DEfiacUYRn62X07cO7RJGJSeTgvWrn2Eqffic8IH3dx4CUNSlhplnzBxg/640?wx_fmt=png" alt=""></p>
<p>注意这里 FlanT5 和 T0pp 只有 instruction 的数据集有区别，但是 FlanT5 仅靠 T5 的 relative positional encoding 来 naively scale 到 8k 的 context length 会显著高于 T0</p>
<p>Long Context 或许 data engineering 跟 neural architecture engineering 同样重要</p>
<p><strong>5 - 代码</strong></p>
<p>两篇文章的 data engineering 非常出色</p>
<ul>
<li>
<p><strong>WizardCoder</strong> : Empowering Code Large Language Models with Evol-Instruct</p>
</li>
<li>
<p>通过不断 prompt AlpacaCoder 构造 instruction tuning 数据集，基于wizardlm的方法，使用了 chatgpt 来生成复杂指令和对应的回答</p>
</li>
<li>
<p>HumanEval，DS-1000 仅次于 GPT-4，超过 Claude / Bard</p>
</li>
<li>
<p>base model 用的是 StarCoder，这意味着 The Stack V3 的质量再次得到验证，同时注意 pretrain code data 可以过多个 epoch 但网页只过一个 epoch</p>
</li>
<li>
<p>Phi-1: Textbooks Are All You Need</p>
</li>
<li>
<p>Pretrain 数据集来源于 filtered code + prompt ChatGPT</p>
</li>
<li>
<p>Instruction tuning 的数据集来自于 prompt ChatGPT</p>
</li>
<li>
<p>base model 只有 1B</p>
</li>
</ul>
<p>怎么评价</p>
<ul>
<li>
<p>一定要好好研究他们是如何 prompt base model 的 — 要对 base model 有信心，只要 MMLU / BBH / HumanEval 分高，它的潜力就超过你的想象</p>
</li>
<li>
<p>prompt 出来的数据集相当于给 HumanEval / MBPP 这种比较短的算法题搞了一个超大训练集</p>
</li>
<li>
<p>但是不可以认为它对着测试集优化，因为它泛化的空间应该大于 HumanEval / MBPP — 这个泛化空间跟 model scale 显著正相关</p>
</li>
<li>
<p>在此基础上，比较难的点是</p>
</li>
<li>
<p>Repo-level code understanding /completion — HumanEval / MBPP 还是有点短</p>
</li>
<li>
<p>Ability balance — 如果照着 Phi-1 的做法，除了代码之外的其他能力都会被冲掉</p>
</li>
</ul>
<p>另外关于代码和文本的 data mixture: <a href="https://arxiv.org/abs/2305.16264">https://arxiv.org/abs/2305.16264</a></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8DABrm9t9S5pEM5G7D8B3DVzmqBibb1mc7kBwS61ckSEEYic19FL9BEzqgufdN4emMXYLFXHAXlHIw/640?wx_fmt=png" alt=""></p>
<p>*Continue training 时使用 50% 的代码作为 data mixture 不会伤模型 language 的能力，反而会提升 coding 和 reasoning *</p>
<p><strong>6 - Putting them together: 能力平衡</strong></p>
<p>目标：</p>
<ul>
<li>
<p>构造一个 instruction tuning data mixture，使得 dialog /coding 增加</p>
</li>
<li>
<p>同时 MMLU (English knowledge) / C-Eval (Chinese knowledge) / BBH and GSM8K (reasoning) 不掉点</p>
</li>
<li>
<p>In-context learning 不掉点</p>
</li>
</ul>
<p>思路</p>
<ul>
<li>可以用 FLAN 打底 — 它非常大几乎相当于 continue training</li>
</ul>
<p>考虑做一个中文版的 FLAN — 最近智源发的COIG-PC(<a href="https://huggingface.co/datasets/BAAI/COIG-PC">https://huggingface.co/datasets/BAAI/COIG-PC</a>) 似乎有点像</p>
<ul>
<li>
<p>code 的部分参照 WizardCoder 和 Phi-1 的做法</p>
</li>
<li>
<p>以上数据做好之后，搜 instruction tuning 的 data mixture and data curriculum 的超参数</p>
</li>
<li>
<p>用上面提到的方法做 Eval</p>
</li>
</ul>
<p><strong>7 - 总结</strong></p>
<ul>
<li>
<p>现阶段 instruction tuning 核心问题是能力平衡</p>
</li>
<li>
<p>基础能力的 Eval 可以参照 Chain-of-thought Hub，但 dialog 还是得人来，且人也不一定 eval 得足够好</p>
</li>
<li>
<p>FLAN 非常神奇，可以考虑做一个中文版</p>
</li>
<li>
<p>抓紧把 instruction tuning 收尾，快点进到 reward modeling 阶段</p>
</li>
<li>
<p>注意要先把 reward modeling 本身做好，确保 reward model 有判断力，再去做 PPO</p>
</li>
<li>
<p>不要 reward model 还没搞清楚就上 PPO ，步子迈太大容易扯到</p>
</li>
</ul>
<p>原文链接：https://yaofu.notion.site/6dafe3f8d11445ca9dc</p>
<p>8a2ca1c5b199</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibqs3dicZ1ibGicA1BHoaoMf3Im3KMaWO4e4OeUMNhIEuYfTib5b6fMialKic9qVWic4OvTyOwxSO6cLhyiaQ/640?wx_fmt=png" alt=""></p>
<p>© THE END</p>
<p>转载请联系本公众号获得授权</p>
<p>投稿或寻求报道：content@jiqizhixin.com</p>



          </div>



<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


