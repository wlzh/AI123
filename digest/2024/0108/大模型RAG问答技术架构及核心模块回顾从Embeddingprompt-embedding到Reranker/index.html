

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>大模型RAG问答技术架构及核心模块回顾：从Embedding、prompt-embedding到Reranker 作者： 老刘说NLP 来源： 老刘说NLP 今天是2024年1月7日，星期日，北京，天气晴，2024年的第一周就这么过去了。 回顾这一周，我们主要围绕模型缝合 （《有趣的大模型嫁接思路SOLAR：兼论面向实体识别及数学能力的大规模开源数据集，https  | AI123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AI123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-cCAOSG8MBO" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2073588164294660"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://ai123.869hr.uk/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://ai123.869hr.uk/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AI123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">大模型RAG问答技术架构及核心模块回顾：从Embedding、prompt-embedding到Reranker</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://ai123.869hr.uk/about>AI123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              January 8, 2024 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseq1ibEiaxM8jFnkLyoOq9Yiaa9Vl45M6Y5t0GsDS7Qz5PVb5vMea4um589A/640?wx_fmt=png&amp;from=appmsg" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <p>作者： 老刘说NLP  来源： <a href="https://mp.weixin.qq.com/s/Ymp0qnujJA0iHturZ0bIjw">老刘说NLP</a></p>
<p>今天是2024年1月7日，星期日，北京，天气晴，2024年的第一周就这么过去了。</p>
<p>回顾这一周，我们主要围绕<strong>模型缝合</strong> （《有趣的大模型嫁接思路SOLAR：兼论面向实体识别及数学能力的大规模开源数据集，https://mp.weixin.qq.com/s/9-4P3ZL8ozIrCDdWAPUIHQ》）、<strong>RAG召回阶段的embedding优化</strong> (《引入任务Instruction指令的句子向量化方案：Instructor的实现思路及训练数据集构造方案》,https://mp.weixin.qq.com/s/qIh07eU8_lYL2gBVzTFzKA)，</p>
<p>并由此延伸的<strong>关于instruction任务数据集的一些数据增强</strong> 开源工作(《2024开篇之大模型遇见信息抽取：常见数据增强、形式化语言及可练手小模型开源项目》,https://mp.weixin.qq.com/s/86FF6w91zompGsb6C80N6g)，这些工作都是微调RAG展开。</p>
<p>而对于RAG而言，<strong>23年已经出现了很多工作，草台班子有了一堆，架构也初步走通，24年应该会围绕搜索增强做更多的优化工作</strong> ，因此我们今天来系统回顾下RAG中的模块，包括一些架构，文本嵌入embedding等，供大家一起参考。</p>
<h4 id="一从rag的整体架构及开源两阶段rag项目说起">一、从RAG的整体架构及开源两阶段RAG项目说起</h4>
<p>我们在之前的文章《<strong>也读大模型RAG问答技术综述及评估思路：兼看UHGEval幻觉评估数据集的构建细节》(<a href="https://mp.weixin.qq.com/s/PiTWDht3rOTwXE2vN5p6PQ">https://mp.weixin.qq.com/s/PiTWDht3rOTwXE2vN5p6PQ</a>)中对《Retrieval-Augmented Generation for Large Language Models: A Survey》(<a href="https://arxiv.org/pdf/2312.10997">https://arxiv.org/pdf/2312.10997</a>)</strong>  进行了介绍，其对于增强大家对RAG的基本理论认知有一定的帮助。</p>
<p>例如，该工作将RAG分成navie RAG, Advanced RAG以及Modular RAG，</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqN9nA2dxOJiayYkeeMFQf0TNPwQiaHe1jCekHlNBcKWK4m4JBe0GZokCQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>而另一个文章：https://blog.llamaindex.ai/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b又整理了个图，在圈子里火了起来。</p>
<p><strong>Motivation 与 Basic RAG</strong></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqOkb2ZGQDDNsN4A2cFjUrFszuAVhYqibicMlTCKnJWSzekPOFxf5bUjAw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p><strong>Advanced RAG</strong></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqNmvJgiaib8rickVsGicSiaq5tiaib5GCLRMrPf5L6GkZECm7caiaOia1h4AxCww/640?wx_fmt=png&amp;from=appmsg" alt=""><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseq2VVsQl3YnwZDiae6akhZYM1icpkwDlZB5Pp0N6VObSODN0pPW4ibenibRw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>感兴趣的可以去看看，而最近也有开源一个涵盖到<strong>reranker阶段</strong> 的RAG开源项目QAnything</p>
<p>QAnything (Question and Answer based on Anything) 致力于支持任意格式文件或数据库的本地知识库问答系统，支持PDF，Word(doc/docx)，PPT，Markdown，Eml，TXT，图片（jpg，png等），网页链接等。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqNdibUNsVyZfjEnUs3DvHMuMKco8LDfa6rsT1QKRE7xqIwIU3kQcd6XQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>地址：https://github.com/netease-youdao/QAnything</p>
<p>QAnything使用两阶段检索范式，其提到，<strong>知识库数据量大的场景下两阶段优势非常明显，如果只用一阶段embedding检索，随着数据量增大会出现检索退化的问题，二阶段rerank重排后能实现准确率稳定增长，即数据越多，效果越好。</strong></p>
<h4 id="二再看rag中的embedding模型">二、再看RAG中的embedding模型</h4>
<p>本周，也出现了一些新的文本嵌入模型和RAG项目，例如NetEase Youdao开源了其嵌入项目BCEmbedding以及问答系统QAnything。</p>
<p>EmbeddingModel用于生成语义向量，在语义搜索和问答中起着关键作用，EmbeddingModel支持中文和英文。</p>
<p>EmbeddingModel通常用于粗排，<strong>因为其可以预先对文本进行向量表示，并预先建立索引，在真实场景下只需要检索计算相似度即可，很快速，并且各个文本计算相似度可以</strong></p>
<pre><code>from BCEmbedding import EmbeddingModel  
  
# list of sentences  
sentences = ['sentence_0', 'sentence_1', ...]  
  
# init embedding model  
model = EmbeddingModel(model_name_or_path=&quot;maidalun1020/bce-embedding-base_v1&quot;)  
  
# extract embeddings  
  
embeddings = model.encode(sentences)  
</code></pre>
<p>不过EmbeddingModel并为考虑文本之间的交互，并且不同的场景下，相似度阈值并不好控制。</p>
<p><strong>1、BCEmbedding</strong></p>
<p>BCEmbedding(BCEmbedding: Bilingual and Crosslingual Embedding for RAG)是由网易有道开发的双语和跨语种语义表征算法模型库，其中包含EmbeddingModel和RerankerModel两类基础模型。</p>
<p>实际上，与此相对应的更早的模型，有智源开放的BGE模型。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqXg5iaBHN5xXKZTwXibuWdtAmAOXhvIFKomhNNjmZGpjZCowdS4ryJV9w/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>地址：https://github.com/netease-youdao/BCEmbedding</p>
<p><strong>2、BGEEmbedding</strong></p>
<p>BGEEmbedding是一个通用向量模型，基于retroma 对模型进行预训练，再用对比学习在大规模成对数据上训练模型，地址：https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/baai_general_embedding</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqzvqk7wMF7ADIKiamgysBpkFFkM8pMxHicqoibIw72nfrYV5JZv11keAfw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p><strong>3、效果对比</strong></p>
<p>可以在https://github.com/netease-youdao/BCEmbedding中找到embedding侧的对比结果。</p>
<p>其采用基于MTEB的语义表征评估基准（https://github.com/embeddings-benchmark/mteb）。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseq9sC52pz87K97BLwPwuZu4NpKfQ4FROP5gQtT7g7ah1pqV266Vh0Oiaw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<h4 id="二再看带有prompt的向量化embedding">二、再看带有prompt的向量化embedding</h4>
<p>知乎文章《https://zhuanlan.zhihu.com/p/661867062》针对这块有了个不错的总结【感兴趣的可以进一步看看】，其提到，在大模型微调这块，有个hard prompt tuning的方式，在进行多任务微调的时候，给不同的任务的input前边都加入固定模式的文字，让模型学会，看到某一段文字之后，就知道要做什么任务了，有助于提高下游不同任务的效果。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqevFqFjttNVa8nAYvCFnTVgZKjLJrAMq7K9GWDryTpB8r2vaJmH8x8w/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>举一反三，都是语言模型，当然也可以在向量化模型上用这个trick了，<strong>也就是做不同的任务时，分别给不同任务的query和key加上不同的prompt之后在做向量化</strong> ，因此，母亲也出现了许多很有意思的idea。</p>
<p><strong>1、TART</strong></p>
<p>《Task-aware Retrieval with Instructions》(<a href="https://arxiv.org/pdf/2211.09260.pdf">https://arxiv.org/pdf/2211.09260.pdf</a>)是在2022年很早期的一个工作，该工作目标是利用多任务指令调整技术开<strong>发一种通用的任务感知检索系统，该系统可以按照人类编写的指令为给定查询找到最佳文档</strong> ，首次大规模收集了约40个带指令的数据集（BERRI,Bank of Explicit RetRieval Instructions），并介绍了在带指令的BERRI上训练的多任务检索系统TART(TAsk-aware ReTriever)，TART展示了通过指令适应新检索任务的可行性。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqsM9Tpl5ZYvN4bfvFCQXCQpvcGz3Xx5pbS0HYcvtMqvOcKmCEGA3sHQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p><strong>2、instructor</strong></p>
<p>我们在之前的文章《引入任务Instruction指令的句子向量化方案：Instructor的实现思路及训练数据集构造方案》(<a href="https://mp.weixin.qq.com/s/qIh07eU8_lYL2gBVzTFzKA">https://mp.weixin.qq.com/s/qIh07eU8_lYL2gBVzTFzKA</a>)** 中有介绍到instructor的方案，其在每个query上，加上了指令信息，并一次来计算对比学习loss：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqWuwon6SL3mKg427FhnthVV5LbuCqhCuYHxNjMLDEpYlswFNNBTVgsA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>这种思路引入了适配特定instruction任务的嵌入方案，这与instruction微调美妙结合。</p>
<p>对应的工作《One Embedder, Any Task: Instruction-Finetuned Text Embeddings》(<a href="https://arxiv.org/abs/2212.09741">https://arxiv.org/abs/2212.09741</a>)这一工作，提出了INSTRUCTOR(Instruction-based Omnifarious Representations)的思路，是一种根据任务说明计算文本嵌入的新方法：每个文本输入会与解释用例的说明（如任务和领域描述）一起进行嵌入。</p>
<p>在具体实现上，该工作通过构造330种不同任务的说明，并在这种多任务上对INSTRUCTOR进行了对比损失训练，这个和当前大模型的instruction tuning工作很像。</p>
<p>项目地址：https://instructor-embedding.github.io</p>
<p><strong>3、基于合成任务优化embedding</strong></p>
<p>而最近的另一个工作，<strong>《Improving Text Embeddings with Large Language Models》(<a href="https://arxiv.org/abs/2401.00368">https://arxiv.org/abs/2401.00368</a>)</strong>  这一工作，利用LLM为近100种语言的文本嵌入任务生成多样化的合成数据，在合成数据上使用标准对比损失对开源模型LLM进行微调，得到更好的嵌入表示。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseq1ibEiaxM8jFnkLyoOq9Yiaa9Vl45M6Y5t0GsDS7Qz5PVb5vMea4um589A/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>具体思路上，用了两步提示策略：<strong>首先提示LLMs对候选任务库进行头脑风暴，然后提示LLMs从任务库中生成以给定任务为条件的数据。为了涵盖各种应用场景，为每种任务类型设计了多个提示模板，并将不同模板生成的数据结合起来，以提高多样性。对于文本嵌入模型，选择微调功能强大的开源LLM，而不是BERT式的小型模型。</strong></p>
<p><strong>4、LLM Embedder</strong></p>
<p><strong>LLM-Embedder《Retrieve Anything To Augment Large Language Models》(<a href="https://arxiv.org/abs/2310.07554">https://arxiv.org/abs/2310.07554</a>)</strong> ，也就是BGE2。其实，其在第一个版本的时候，就已经引入了instruction的思想，做向量化召回时候只将召回任务分成两类：对称检索（相似句匹配）和非对称检索（QA匹配），如果做是QA匹配，需要在Q进行向量化时候，加入前缀：“为这个句子生成表示(for s2p(short query to long passage) retrieval task, each short query should start with an instruction )，不同版本的模型对应的prompt如下：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqXybZZuRb8bMpZialhrNQHE9McKfsSmyflWYhFTP6t29DrMvxzibEicD5w/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>例如使用BGE模型时，源代码可以为：</p>
<pre><code>from sentence_transformers import SentenceTransformer  
queries = ['query_1', 'query_2']  
passages = [&quot;样例文档-1&quot;, &quot;样例文档-2&quot;]  
instruction = &quot;为这个句子生成表示以用于检索相关文章：&quot;  
  
model = SentenceTransformer('BAAI/bge-large-zh-v1.5')  
q_embeddings = model.encode([instruction+q for q in queries], normalize_embeddings=True)  
p_embeddings = model.encode(passages, normalize_embeddings=True)  
scores = q_embeddings @ p_embeddings.T  
</code></pre>
<p>在具体实现上，BGE2根据LLM的反馈进行微调，支持大型语言模型的检索增强需求，包括知识检索、记忆检索、示例检索和工具检索，在具体实现上，在6个任务上进行了微调:问题回答、对话搜索、长对话、长文本建模、上下文学习和工具学习。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqNqFw4gwMybib7WnCTl77XppfwOl8icgexYDr42dC3Ve06kAJl9BUIzdA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>对应的prompt如下：</p>
<pre><code>INSTRUCTIONS = {  
    &quot;qa&quot;: {  
        &quot;query&quot;: &quot;Represent this query for retrieving relevant documents: &quot;,  
        &quot;key&quot;: &quot;Represent this document for retrieval: &quot;,  
    },  
    &quot;icl&quot;: {  
        &quot;query&quot;: &quot;Convert this example into vector to look for useful examples: &quot;,  
        &quot;key&quot;: &quot;Convert this example into vector for retrieval: &quot;,  
    },  
    &quot;chat&quot;: {  
        &quot;query&quot;: &quot;Embed this dialogue to find useful historical dialogues: &quot;,  
        &quot;key&quot;: &quot;Embed this historical dialogue for retrieval: &quot;,  
    },  
    &quot;lrlm&quot;: {  
        &quot;query&quot;: &quot;Embed this text chunk for finding useful historical chunks: &quot;,  
        &quot;key&quot;: &quot;Embed this historical text chunk for retrieval: &quot;,  
    },  
    &quot;tool&quot;: {  
        &quot;query&quot;: &quot;Transform this user request for fetching helpful tool descriptions: &quot;,  
        &quot;key&quot;: &quot;Transform this tool description for retrieval: &quot;  
    },  
    &quot;convsearch&quot;: {  
        &quot;query&quot;: &quot;Encode this query and context for searching relevant passages: &quot;,  
        &quot;key&quot;: &quot;Encode this passage for retrieval: &quot;,  
    },  
}  
</code></pre>
<p>其在具体实现上很有意思，重点在于基于大语言模型反馈的奖励机制、知识蒸馏的稳定化以及明确指示的多任务微调。具体的：</p>
<p>在基于大语言模型反馈的奖励机制方面，</p>
<p>LLM的期望输出表示为𝑂，检索候选表示为𝐶，候选的奖励表示为𝑟𝐶|𝑂，由以下方程导出：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqtdNZP38yu7GBaJYhPH4woI625ibiaaqKxegIW9jcE87VKvJZKibN58SlA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>𝑜𝑖表示期望输出的第𝑖个标记，而LLM(𝑥|𝑦)表示在给定上下文𝑦的情况下，LLM生成𝑥的可能性。换句话说，如果一个检索候选导致期望输出的生成可能性更高，那么将分配更高的奖励。</p>
<p>对于问答任务，奖励计算为在给定一个单一候选段落的情况下，生成答案的可能性；对于指令调整任务，奖励计算为在给定一个候选示例的情况下，生成指定的输出的可能性。对于生成任务，奖励计算为在给定一个候选历史块的情况下，生成新内容的可能性。不过，LLM奖励不适用于会话搜索和工具学习数据集，因为在这些情况下没有对LLM输出的明确期望。</p>
<p>在损失函数方面，使用对比学习的损失函数：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqGlcj2vqbKxkPYG8eUqSHxuibaJQaIaXr7MYtfyOvwmlucO7IhBm0tow/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>在知识蒸馏方面，通过最小化使用LLM的奖励计算的候选样本分布与由嵌入模型预测的分布之间的差距来提高模型性能，通过计算KL散度，以减小LLM的奖励的波动对蒸馏的负面影响：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWsequ5kRR2SghQzSqm9sIbDExIknNFWeLdiaQgGKDQHGde3YtyqVjCCYChQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>最后，在训练数据方面，</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqlC4MVurVGOkvhj0aPjon370VGQYcQm2r3GOJ9PtvsK9J6CwqwPqhibw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<h4 id="三最后看关于rerankermodel精排模型">三、最后看关于RerankerModel精排模型</h4>
<p>交叉编码器将对查询和答案实时计算相关性分数，这比向量模型(即双编码器)更准确，但比向量模型更耗时。 因此，它可以用来对嵌入模型返回的前k个文档重新排序。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqoCS0UWlWYxEvyssGx3KpMMI03OlWswznJmticVtk8fvqLEYV78SFOag/640?wx_fmt=png&amp;from=appmsg" alt="">不同于向量模型需要输出向量，直接文本对输出相似度(<strong>因为交叉编码器在句子层面的任务上表现非常好，但它存在一个“致命”缺点：交交叉编码器不产生句子嵌入，这个嵌入没有绝对意义</strong> )，排序准确度更高，可用于对向量召回结果的重新排序，提升最终结果的相关性。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqRpFavHyp9r7IyQkj0vqLia9ibYXpySAmDXmVhDNgTpT4uPODvm6Aj8Aw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>在技术实现上，Query-Passage paire组成的正负样例，一块送入模型，训练目标是，正样例的logits score大于batch内的负样例。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqiaQzK3n1uPcfBerE4icKI7SN4y8j2QOicaXGqt59yBEibiaJK6hibzg6oXWA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>也就是说，其通过句子对及表征其语义相似程度的基本事实标签（可能是离散的类别标签，或者是连续性的相似度数值）来进行有监督训练。</p>
<p>这块的实现可以参考：<strong><a href="https://github.com/luyug/Reranker/tree/main">https://github.com/luyug/Reranker/tree/main</a></strong></p>
<pre><code>from BCEmbedding import RerankerModel  
# your query and corresponding passages  
query = 'input_query'  
passages = ['passage_0', 'passage_1', ...]  
  
# init reranker model  
model = RerankerModel(model_name_or_path=&quot;maidalun1020/bce-reranker-base_v1&quot;)  
  
# method 1: rerank passages  
rerank_results = model.rerank(query, passages)  
</code></pre>
<p>但是，很现实的是，交叉编码器在实际应用中的速度很慢，所以通常都是作为精排出现，关于rerank精排这块的对比实验，可以查看《Agents大模型外挂检索优化》(<a href="https://zhuanlan.zhihu.com/p/657653570">https://zhuanlan.zhihu.com/p/657653570</a>)，有些结论很有意思：</p>
<p><strong>bge-reRank模型虽然是一个rank模型，但其的score值还是较好的稳定在一个取值范围，业务场景中，可在自己的测评数据上，找到的一个不错的score值，来解决不应该召回的情况。</strong></p>
<p><strong>使用reRank，可显著提升检索效果，前提还是bge-reranker-large效果比较好。笔者对比，阿里的通用reRank模型，效果比检索还差了。</strong></p>
<p><strong>检索的候选多了，效果上限会提高但ReRank效果可能会下降。</strong></p>
<p><strong>通过domain数据finetune，可进一步提升，检索效果，为业务指标提升，展现了一条康庄大道。</strong></p>
<p>而进一步的，在训练数据方面，常用的数据包括</p>
<p>T2ranking：https://huggingface.co/datasets/THUIR/T2Ranking</p>
<p>MMmarco：https://github.com/unicamp-dl/mMARCO</p>
<p>dulreader：https://github.com/baidu/DuReader</p>
<p>Cmedqa-v2：https://github.com/zhangsheng93/cMedQA2</p>
<p>nli-zh：https://huggingface.co/datasets/shibing624/nli_zh</p>
<p>msmarco：https://huggingface.co/datasets/sentence-transformers/embedding-training-data</p>
<p>nq：https://huggingface.co/datasets/sentence-transformers/embedding-training-data</p>
<p>hotpotqa：https://huggingface.co/datasets/sentence-transformers/embedding-training-data</p>
<p>NLI：https://github.com/princeton-nlp/SimCSE</p>
<p>Mr.TyDi：https://github.com/castorini/mr.tydi</p>
<p><strong>1、youdao RerankerModel</strong></p>
<p>RerankerModel擅长优化语义搜索结果和语义相关顺序精排，支持中文，英文，日文和韩文。</p>
<p>地址：https://github.com/netease-youdao/BCEmbedding</p>
<p><strong>2、BGE Reranker</strong></p>
<p>FlagEmbedding(<a href="https://github.com/FlagOpen/FlagEmbedding/">https://github.com/FlagOpen/FlagEmbedding/</a>)在检索增强llm领域做了许多开源工作，Reranker Model也是其中的一个重点，其在在多语言数据上训练了交叉编码器。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqju44PuDzM9GEM76eTyYEeicUS6HrYWr12NWMAcMo1SSUoW9OiczCj6Wg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>地址：https://huggingface.co/BAAI/bge-reranker-large</p>
<p><strong>3、模型对比效果</strong></p>
<p>模型评测方面，使用llamaindex进行测试，可以从https://github.com/netease-youdao/BCEmbedding中找到对应的评测结果，如下表所示：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/fUBU1yiaEmJgcWdEndhl6P4xJ0xnoWseqbeNwJWhXrB0QnGlUghOQe8xEIvzy7cmR0ibhdpTt7CibKlprEoZ71jFA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>当然具体的数值还可以参考：《Boosting RAG: Picking the Best Embedding &amp; Reranker models(<a href="https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83">https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83</a>)</p>
<h4 id="总结">总结</h4>
<p>本文主要介绍了RAG系统中的一些有趣的话题，包括从RAG的整体架构及开源两阶段RAG项目、带有prompt的向量化embedding、关于RerankerModel精排模型，这些都在2024年开年这一周出现了很多有趣的工作。</p>
<p>搜索增强，在24年会有很多工作，大家可以多跟进。</p>
<h4 id="参考文献">参考文献</h4>
<p>1、https://www.datagrand.com/blog/技术干货：如何训练高性能语义表示模型-交叉.html</p>
<p>2、https://zhuanlan.zhihu.com/p/661867062</p>
<p>3、https://www.sbert.net/examples/applications/retrieve_rerank/README.html</p>
<p>4、https://blog.llamaindex.ai/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b</p>
<h4 id="关于我们">关于我们</h4>
<p>老刘，刘焕勇，NLP开源爱好者与践行者，主页：https://liuhuanyong.github.io。</p>
<p>老刘说NLP，将定期发布语言资源、工程实践、技术总结等内容，欢迎关注。</p>
<p><strong>对于想加入更优质的知识图谱、事件图谱、大模型AIGC实践、相关分享的，可关注公众号，在后台菜单栏中点击会员社区-&gt;会员入群加入。</strong></p>
<p>更多AI工具，参考<a href="https://ai123.869hr.uk/">Github-AI123</a>，<a href="https://ai123.869hr.uk/">国内AI123</a></p>



          </div>

<<<<<<< HEAD

=======
 可扫如下微信二维码加好友
>>>>>>> HEAD@{1}

<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


