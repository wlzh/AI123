

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>图文详解Transformer为什么如此强大 作者： AI大模型实验室 来源： AI大模型实验室 在过去几年中，Transformer 在自然语言处理（NLP）领域引起了巨大关注。现在，它们在 NLP 之外的领域也得到了成功使用。 Transformer 之所以如此强大，关键在于它的 “注意力（Attention）模块”。这个模  | AI123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AI123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-cCAOSG8MBO" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2073588164294660"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://ai123.869hr.uk/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://ai123.869hr.uk/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AI123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">图文详解Transformer为什么如此强大</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://ai123.869hr.uk/about>AI123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              April 17, 2024 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHicVZXtcAzAEV8Z7p0LL18rRxHAVBlz8iawkbR0biaFdBkHqyv6VT4m486muGJZklyxAabGVZRBTnwPKdwQBOqmA/640?wx_fmt=webp&amp;from=appmsg" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <p>作者： AI大模型实验室  来源： <a href="https://mp.weixin.qq.com/s/5nxxLYE037mBqY9Uacbwkg">AI大模型实验室</a></p>
<p>在过去几年中，Transformer 在自然语言处理（NLP）领域引起了巨大关注。现在，它们在 NLP 之外的领域也得到了成功使用。</p>
<p><strong>Transformer 之所以如此强大，关键在于它的 “注意力（Attention）模块”。这个模块能够理解文本序列中的每个词与其他词之间的关系。</strong></p>
<p>但大家最关心的问题是，Transformer 究竟是如何做到这一点的？</p>
<p>在本文中，我们将尝试解答这个问题，并理解为什么 Transformer 会进行这样的计算过程。</p>
<p>在我之前的一系列关于 Transformer 的文章中，我们已经深入探讨了其<a href="http://mp.weixin.qq.com/s?__biz=Mzg5Mjc3MjIyMA==&amp;mid=2247569440&amp;idx=1&amp;sn=c43d997e267168b5e7b838fe470e9c78&amp;chksm=c03a9a33f74d1325ed906e795d04e9ee8b4c51f40f7e3d4346d41c8f96a98d84b6115778fc8b&amp;scene=21#wechat_redirect">架构</a>，并逐步了解了<a href="http://mp.weixin.qq.com/s?__biz=Mzg5Mjc3MjIyMA==&amp;mid=2247569596&amp;idx=1&amp;sn=5e53a8a0e1b41e354e65581806487274&amp;chksm=c03a9aaff74d13b905a93eacef1157891b6c39fd2b38ae95331b7fe779ad060422ab79d0f48f&amp;scene=21#wechat_redirect">它们在训练和推理阶段的工作原理</a>。我们还<a href="http://mp.weixin.qq.com/s?__biz=Mzg5Mjc3MjIyMA==&amp;mid=2247569633&amp;idx=1&amp;sn=621d572809c0df94b10fa7c20a1dba80&amp;chksm=c03a9af2f74d13e4593291ec1add82d4f4b2a9573b69934157a242f43fb14f5f7708a48079d0&amp;scene=21#wechat_redirect">深入探索了它们的内部机制，以详细了解它们是如何运作的</a>。</p>
<p>我们追求的目标，不仅是理解事物的工作原理，更要理解它为何以这种方式运作。</p>
<p>要了解 Transformer 的运行原理，我们需要重点关注它的注意力（Attention）机制。我们从探究输入到注意力模块的数据开始，然后分析它是如何处理这些输入的。</p>
<p><strong>#01</strong></p>
<p><strong>输入序列是怎样传送到注意力模块的</strong></p>
<p>注意力模块存在于每个编码器（Encoder）和每个解码器（Decoder）之中。我们先来仔细看看编码器中的注意力机制。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHicVZXtcAzAEV8Z7p0LL18rRxHAVBlz8DZJwzntEk9icxbYvHq9g1QBC2RZALmLXw4PlKVS098fdiazhg7daicicqQ/640?wx_fmt=webp&amp;from=appmsg" alt=""></p>
<p>编码器中的注意力机制</p>
<p>以一个例子来说明，假设我们正在进行一项从英语到西班牙语的翻译任务，其中一个样本的源序列是 “The ball is blue”，目标序列是 “La bola es azul”。</p>
<p>源序列首先经过一个嵌入和位置编码层，这个层会为序列中的每个词创建一个嵌入向量。这些嵌入向量随后被送入编码器，首先到达的就是注意力模块。</p>
<p>在注意力模块里，嵌入的序列会通过三个线性层，生成三个不同的矩阵 —— 分别称为查询（Query）、键（Key）和值（Value）。这三个矩阵是用来计算注意力分数的关键。</p>
<p>我们需要明确的是，这些矩阵中的每一行都对应着源序列中的一个词。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHicVZXtcAzAEV8Z7p0LL18rRxHAVBlz8Iqm52RehBFMhdrauPE2VsGdb7iaHwtv99sawVTuHlk2pRmH1VIq6AQQ/640?wx_fmt=webp&amp;from=appmsg" alt=""></p>
<p>源序列的流程</p>
<p><strong>#02</strong></p>
<p><strong>每个输入行都是源序列中的一个词</strong></p>
<p>要深入了解驱动 Transformer 的核心机制，我们需要专注于其注意力（Attention）机制。这涉及从源序列中的每个单词出发，追踪它们在 Transformer 体系中的流转。我们特别关注的是，注意力模块内部发生了什么。</p>
<p>这有助于我们清楚地了解源序列和目标序列中的每个单词是如何与其他单词进行交互的。</p>
<p>在解释过程中，请专注于对每个单词进行的操作，以及每个向量是如何与原始输入单词相映射的。如果某些细节，比如矩阵的形状、算术运算的细节、多个注意力头等，与单词的具体运算路径无直接关联，我们就可以先不考虑它们。</p>
<p>为了简化解释和可视化，我们先忽略嵌入维度，只关注每个单词的行。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHicVZXtcAzAEV8Z7p0LL18rRxHAVBlz8p5kFDCPtBXibPuE6QVAMicOlLmvSyiadiamicsiaU6J02Ac5Yya8HPhn5v6Q/640?wx_fmt=webp&amp;from=appmsg" alt=""></p>
<p>源序列中每个单词的流程</p>
<p><strong>#03</strong></p>
<p><strong>每个单词都经过了一系列可学习的变换</strong></p>
<p>每一行都是由一系列变换生成的，这些变换包括嵌入、位置编码和线性层。</p>
<p>所有这些变换都是可训练的操作。这意味着这些操作中使用的权重并非预设的，而是通过模型学习得到的，以便产生期望的输出预测。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHicVZXtcAzAEV8Z7p0LL18rRxHAVBlz8icZuGWK1wlPrCxuynRcJdjqWRUbbSELhlhWDsQxSXIbLZvw33gqGTRA/640?wx_fmt=webp&amp;from=appmsg" alt=""></p>
<p>学习线性和嵌入权重</p>
<p>一个关键问题是，Transformer 是如何确定哪一套权重能够获得最佳结果的？这是一个我们稍后需要回过头来深入讨论的问题。</p>
<p><strong>#04</strong></p>
<p><strong>注意力分数：查询（Query）和键（Key）单词之间的点积</strong></p>
<p>注意力机制包含几个步骤，但我们这里主要关注线性层和注意力分数。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHicVZXtcAzAEV8Z7p0LL18rRxHAVBlz8LBfR1tgmFOCAKqcuahvHvJjppXwo8BEg4dtJXlIpTpmic4eZLib1JHkg/640?wx_fmt=webp&amp;from=appmsg" alt=""></p>
<p>多头注意力</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHicVZXtcAzAEV8Z7p0LL18rRxHAVBlz8ykOHbaRA7ndNqicIeIT6LBzfrUWwKljLnUIawAvESY1zmgjz5WubCFw/640?wx_fmt=webp&amp;from=appmsg" alt=""></p>
<p>注意力分数计算</p>
<p>如公式所示，注意力机制的第一步是在查询（Q）矩阵和键（K）矩阵的转置之间进行矩阵乘法（即点积）。观察每个单词的变化。</p>
<p>我们得到了一个中间矩阵（可以称之为 “因子” 矩阵），其中每个单元是两个单词间的矩阵乘法结果。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHicVZXtcAzAEV8Z7p0LL18rRxHAVBlz8mDbgMCGzoSQDzjAtZzbdqJQy3k3ubCP7Frsbx6NcuiaEZdct6tgtMZA/640?wx_fmt=webp&amp;from=appmsg" alt=""></p>
<p>查询矩阵和关键矩阵之间的点积</p>
<p>比如说，第四行中的每一列代表了第四个查询单词与每个键单词之间的点积结果。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHicVZXtcAzAEV8Z7p0LL18rRxHAVBlz83r29QNMzzQRw9D3P6cNiac3retTuQZHGCqN8J1drZ2RPDRUamxLOPKw/640?wx_fmt=webp&amp;from=appmsg" alt=""></p>
<p>查询矩阵和关键矩阵之间的点积</p>
<p><strong>#05</strong></p>
<p><strong>注意力分数：查询 - 键（Query-Key）和值（Value）单词之间的点积</strong></p>
<p>接下来的步骤是在这个中间 “因子” 矩阵和值（V）矩阵之间进行矩阵乘法，从而产生由注意力模块输出的注意力分数。这里我们可以看到，第四行是第四个查询单词矩阵与所有其它键和值单词的乘积结果。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHicVZXtcAzAEV8Z7p0LL18rRxHAVBlz8iawkbR0biaFdBkHqyv6VT4m486muGJZklyxAabGVZRBTnwPKdwQBOqmA/640?wx_fmt=webp&amp;from=appmsg" alt=""></p>
<p>查询键和值矩阵之间的点积</p>
<p>这样就产生了注意力模块输出的注意力分数向量（Z）。</p>
<p>我们可以这样来理解输出分数：对于每个单词，它是 “值（Value）” 矩阵中每个单词的编码值，经过 “因子” 矩阵加权处理。这个因子矩阵是针对特定单词的查询（Query）值和所有单词的键（Key）值的点积。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHicVZXtcAzAEV8Z7p0LL18rRxHAVBlz8WpGKe0Yo6j0E2X4pInicZQTUVzW3WTUA4jAg2xakdQqPgpWfy4Ry9jw/640?wx_fmt=webp&amp;from=appmsg" alt=""></p>
<p>注意力分数是值词的加权总和</p>
<p><strong>#06</strong></p>
<p><strong>查询（Query）、键（Key）和值（Value）单词的作用是什么？</strong></p>
<p>查询单词可以被理解为我们正在计算注意力的那个单词。键和值单词是我们关注的对象，即这些单词对查询单词有多大的相关性。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHicVZXtcAzAEV8Z7p0LL18rRxHAVBlz8wA0FoDiboBpbFpS0FQmLrr3NcicKSjXWn7LYBLZlGQjDVQJemeMap1rw/640?wx_fmt=webp&amp;from=appmsg" alt=""></p>
<p>“blue” 一词的注意力分数会关注所有其他单词</p>
<p>举个例子，对于句子 “The ball is blue”，“blue” 这个词的行将包含它与其他每个单词的注意力分数。这里，“blue” 是查询单词，其他单词则是 “键 / 值”。</p>
<p>尽管还有其他操作，如除法和 softmax，但在本文中我们可以暂时忽略它们。它们只是改变矩阵中的数值，但并不影响每个单词行在矩阵中的位置，也不涉及单词之间的互动。</p>
<p><strong>#07</strong></p>
<p><strong>点积揭示了单词间的相似度</strong></p>
<p>我们已经看到，注意力分数捕捉了一个特定单词与句子中其他每个单词之间的交互，通过点积运算后再求和。但矩阵乘法如何帮助 Transformer 判断两个单词之间的相关性呢？</p>
<p>要理解这一点，记住查询、键和值的行实际上是具有嵌入维度的向量。让我们更详细地看看这些向量之间的矩阵乘法是如何计算的。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHicVZXtcAzAEV8Z7p0LL18rRxHAVBlz8SsUZM8VpiaAlc1wBZNicBbGsCZXgx14GDJ781WvAQDZODy4SzpnQIdVA/640?wx_fmt=webp&amp;from=appmsg" alt=""></p>
<p>每个单元格都是两个词向量之间的点积</p>
<p>当我们对两个向量进行点积时，我们会将数对相乘，然后将结果相加。</p>
<ul>
<li>
<p>如果两个配对数字（例如‘a’和‘d’）都是正数或都是负数，那么乘积会是正的，从而增加最终总和。</p>
</li>
<li>
<p>如果一个数字是正数而另一个是负数，则乘积会是负的，从而减少最终总和。</p>
</li>
<li>
<p>如果乘积是正数，这两个数字越大，它们对最终总和的贡献越大。</p>
</li>
</ul>
<p>这意味着，如果两个向量中对应的数字的符号相同，那么最终的总和会更大。</p>
<p><strong>#08</strong></p>
<p><strong>Transformer 如何学习单词间的相关性？</strong></p>
<p>点积的原理同样适用于注意力分数。如果两个单词的向量更加对齐，它们的注意力分数就会更高。</p>
<p>那么，我们希望 Transformer 呈现出什么样的行为呢？</p>
<p>我们希望对于句子中彼此相关的两个单词，注意力分数较高。而对于彼此无关的两个单词，则希望分数较低。</p>
<p>比如，在句子 “The black cat drank the milk” 中，单词 “milk” 与 “drank” 非常相关，与 “cat” 稍微不那么相关，而与 “black” 无关。我们希望 “milk” 和 “drank” 之间产生高分数，“milk” 和 “cat” 之间产生略低的分数，而 “milk” 和 “black” 之间的分数则接近于零。</p>
<p>这就是我们希望模型学会输出的结果。</p>
<p>为了做到这一点，“milk” 和 “drank” 的向量必须对齐。“milk” 和 “cat” 的向量将略有差异。而 “milk” 和 “black” 的向量则会相差甚远。</p>
<p>让我们回到之前提到的问题 ——Transformer 如何确定哪一组权重能带来最佳效果？</p>
<p>单词向量是基于单词嵌入和线性层的权重生成的。因此，Transformer 可以通过学习这些嵌入和线性层的权重，来产生所需的单词向量。</p>
<p>换句话说，它会以这样的方式学习这些嵌入和权重：如果句子中的两个单词彼此相关，那么它们的向量就会对齐，从而产生较高的注意力分数。而对于彼此不相关的单词，它们的向量就不会对齐，从而产生较低的注意力分数。</p>
<p>因此，“milk” 和 “drank” 之间的嵌入将非常对齐，产生较高的分数。而 “milk” 和 “cat” 之间的嵌入会有所差异，产生略低的分数；“milk” 和 “black” 之间的嵌入则会相差甚远，产生较低的分数。</p>
<p>这就是注意力模块背后的原理。</p>
<p><strong>#09</strong></p>
<p><strong>总结：是什么让 Transformer 动起来的？</strong></p>
<p>查询（Query）和键（Key）之间的点积计算出每对单词之间的相关性。然后，这种相关性被用作一个 “因子”，以计算所有值（Value）单词的加权总和。这个加权总和就是作为注意力分数输出的。</p>
<p>Transformer 以这样一种方式学习嵌入等，即让彼此相关的单词更加对齐。</p>
<p>这正是引入三个线性层并为查询、键和值生成输入序列的三个版本的原因之一。这为注意力模块提供了更多可以学习的参数，以优化单词向量的创建。</p>
<p><strong>#10</strong></p>
<p><strong>Transformer 中的编码器自注意力</strong></p>
<p>在 Transformer 中，注意力被用于三个地方：</p>
<ul>
<li>
<p>编码器中的自注意力 —— 源序列关注自身</p>
</li>
<li>
<p>解码器中的自注意力 —— 目标序列关注自身</p>
</li>
<li>
<p>解码器中的编码器 - 解码器注意力 —— 目标序列关注源序列</p>
</li>
</ul>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHicVZXtcAzAEV8Z7p0LL18rRxHAVBlz8aUF5SnZKmDdLmyAdkQurNKbEPDrAo4RPfkiavRYGpopaj45TvgEOibog/640?wx_fmt=webp&amp;from=appmsg" alt=""></p>
<p>Transformer 中的注意力</p>
<p>在编码器自注意力中，我们计算源句中每个单词与源句中其他单词的相关性。这在所有编码器的堆栈中都会发生。</p>
<p><strong>#11</strong></p>
<p><strong>Transformer 中的解码器自注意力</strong></p>
<p>我们刚才在编码器自注意力中所看到的大部分内容也同样适用于解码器中的注意力，但存在一些小的、但重要的差异。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHicVZXtcAzAEV8Z7p0LL18rRxHAVBlz8xvFNIHNxFFhiaxgHnJoWEv3mx4yDhic9HibNOoXTiaGm4jh7nnM0SDEH1g/640?wx_fmt=webp&amp;from=appmsg" alt=""></p>
<p>解码器中的注意力</p>
<p>在解码器自注意力中，我们计算目标句中每个单词与目标句中其他单词的相关性。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHicVZXtcAzAEV8Z7p0LL18rRxHAVBlz87nkjSEw60C64h4UAaDlImjG3GJ5FxOoMLs5o78ictAleJ8VnEicibAndQ/640?wx_fmt=webp&amp;from=appmsg" alt=""></p>
<p>解码器自注意力</p>
<p><strong>#12</strong></p>
<p><strong>Transformer 中的编码器 - 解码器注意力</strong></p>
<p>在编码器 - 解码器注意力中，查询来自目标句，而键 / 值来自源句。因此，它计算了目标句中每个单词与源句中每个单词的相关性。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHicVZXtcAzAEV8Z7p0LL18rRxHAVBlz8bPS9gSGtKktpwZA6sLJe8OZft2BjdR10DCD2rYiawsf0r6GyAt815VQ/640?wx_fmt=webp&amp;from=appmsg" alt=""></p>
<p>编码器 - 解码器注意力</p>
<p><strong>#13</strong></p>
<p><strong>结论</strong></p>
<p>希望这篇文章能让你对 Transformer 设计的巧妙之处有一个清晰的理解。也请阅读本系列的其他三篇文章：</p>
<ul>
<li>
<p>《<a href="http://mp.weixin.qq.com/s?__biz=Mzg5Mjc3MjIyMA==&amp;mid=2247569440&amp;idx=1&amp;sn=c43d997e267168b5e7b838fe470e9c78&amp;chksm=c03a9a33f74d1325ed906e795d04e9ee8b4c51f40f7e3d4346d41c8f96a98d84b6115778fc8b&amp;scene=21#wechat_redirect">图解 Transformer 架构设计</a>》</p>
</li>
<li>
<p>《<a href="http://mp.weixin.qq.com/s?__biz=Mzg5Mjc3MjIyMA==&amp;mid=2247569596&amp;idx=1&amp;sn=5e53a8a0e1b41e354e65581806487274&amp;chksm=c03a9aaff74d13b905a93eacef1157891b6c39fd2b38ae95331b7fe779ad060422ab79d0f48f&amp;scene=21#wechat_redirect">图解 Transformer 工作原理</a>》</p>
</li>
<li>
<p>《<a href="http://mp.weixin.qq.com/s?__biz=Mzg5Mjc3MjIyMA==&amp;mid=2247569633&amp;idx=1&amp;sn=621d572809c0df94b10fa7c20a1dba80&amp;chksm=c03a9af2f74d13e4593291ec1add82d4f4b2a9573b69934157a242f43fb14f5f7708a48079d0&amp;scene=21#wechat_redirect">图解 Transformer 多头注意力机制</a>》</p>
</li>
</ul>
<p>以深入了解为什么 Transformer 成为了如此多深度学习应用的首选架构。</p>
<p>原文链接：https://towardsdatascience.com/transformers-explained-visually-not-just-how-but-why-they-work-so-well-d840bd61a9d3</p>
<h4 id="heading"></h4>
<p>现在大模型都是基于 Transformer 构建的，要了解大模型必须要了解 Transformer，欢迎进入 AI 大模型实验室微信群一起学习 Transformer。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/vHicVZXtcAzDVAT8GUjG7bcB3WjV552MYTNxDSwExocZKoLJLCJzKFL2Iic1jSibkoRKzO0Xgx2tUUVib35pgR3YXg/640?wx_fmt=other&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1&amp;tp=webp" alt=""></p>
<p>更多AI工具，参考<a href="https://ai123.869hr.uk/">Github-AI123</a>，<a href="https://ai123.869hr.uk/">国内AI123</a></p>



          </div>



<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


