

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>欢迎Mixtral-当前HuggingFace上最先进的MoE模型 作者： Hugging Face 来源： Hugging Face 最近，Mistral 发布了一个激动人心的大语言模型: Mixtral 8x7b，该模型把开放模型的性能带到了一个新高度，并在许多基准测试上表现优于 GPT-3.5。我们很高兴能够在 Hugging Face 生态系统中全面集成 Mixtral 以对其提供全方位的支持 🔥！ Hugging Face 对 Mixtral  | AI123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AI123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-cCAOSG8MBO" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2073588164294660"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://ai123.869hr.uk/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://ai123.869hr.uk/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AI123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">欢迎Mixtral-当前HuggingFace上最先进的MoE模型</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://ai123.869hr.uk/about>AI123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              January 4, 2024 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://869hr.uk/images/blog/aibar123.jpg" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <p>作者： Hugging Face  来源： <a href="https://mp.weixin.qq.com/s/GvGQiFQuszvrl7rLDRTxcw">Hugging Face</a></p>
<p>最近，Mistral 发布了一个激动人心的大语言模型: Mixtral 8x7b，该模型把开放模型的性能带到了一个新高度，并在许多基准测试上表现优于 GPT-3.5。我们很高兴能够在 Hugging Face 生态系统中全面集成 Mixtral 以对其提供全方位的支持 🔥！</p>
<p>Hugging Face 对 Mixtral 的全方位支持包括:</p>
<ul>
<li>
<p>Hub 上的模型，包括模型卡以及相应的许可证 (Apache 2.0)</p>
</li>
<li>
<p>🤗 transformers 的集成</p>
</li>
<li>
<p>推理终端的集成</p>
</li>
<li>
<p>TGI 的集成，以支持快速高效的生产级推理</p>
</li>
<li>
<p>使用 🤗 TRL 在单卡上对 Mixtral 进行微调的示例</p>
</li>
</ul>
<h4 id="目录">目录</h4>
<h4 id="mixtral-8x7b-是什么">Mixtral 8x7b 是什么？</h4>
<p>Mixtral 的架构与 Mistral 7B 类似，但有一点不同: 它实际上内含了 8 个“专家”模型，这要归功于一种称为“混合专家”(Mixture of Experts，MoE) 的技术。当 MoE 与 transformer 模型相结合时，我们会用稀疏 MoE 层替换掉某些前馈层。MoE 层包含一个路由网络，用于选择将输入词元分派给哪些专家处理。Mixtral 模型为每个词元选择两名专家，因此，尽管其有效参数量是 12B 稠密模型的 4 倍，但其解码速度却能做到与 12B 的稠密模型相当！</p>
<p>欲了解更多有关 MoE 的知识，请参阅我们之前的博文: hf.co/blog/zh/moe。</p>
<p><strong>本次发布的 Mixtral 模型的主要特点:</strong></p>
<ul>
<li>
<p>模型包括基础版和指令版</p>
</li>
<li>
<p>支持高达 32k 词元的上下文</p>
</li>
<li>
<p>性能优于 Llama 2 70B，在大多数基准测试上表现不逊于 GPT3.5</p>
</li>
<li>
<p>支持英语、法语、德语、西班牙语及意大利语</p>
</li>
<li>
<p>擅长编码，HumanEval 得分为 40.2%</p>
</li>
<li>
<p>可商用，Apache 2.0 许可证</p>
</li>
</ul>
<p>那么，Mixtral 模型效果到底有多好呢？下面列出了 Mixtral 基础模型与其他先进的开放模型在 LLM 排行榜 上表现 (分数越高越好):</p>
<p>模型许可证是否可商用预训练词元数排行榜得分 ⬇️</p>
<p>mistralai/Mixtral-8x7B-v0.1
Apache 2.0
✅
不详
68.42</p>
<p>meta-llama/Llama-2-70b-hf
Llama 2 许可证
✅
2,000B
67.87</p>
<p>tiiuae/falcon-40b
Apache 2.0
✅
1,000B
61.5</p>
<p>mistralai/Mistral-7B-v0.1
Apache 2.0
✅
不详
60.97</p>
<p>meta-llama/Llama-2-7b-hf
Llama 2 许可证
✅
2,000B
54.32</p>
<p>我们还用 MT-Bench 及 AlpacaEval 等基准对指令版和其它聊天模型进行了对比。下表列出了 Mixtral Instruct 与顶级闭源或开放模型相比的表现 (分数越高越好):</p>
<p>模型可得性上下文窗口（词元数）MT-Bench 得分 ⬇️</p>
<p>GPT-4 Turbo
私有
128k
9.32</p>
<p>GPT-3.5-turbo-0613
私有
16k
8.32</p>
<p>mistralai/Mixtral-8x7B-Instruct-v0.1
Apache 2.0
32k
8.30</p>
<p>Claude 2.1
私有
200k
8.18</p>
<p>openchat/openchat_3.5
Apache 2.0
8k
7.81</p>
<p>HuggingFaceH4/zephyr-7b-beta
MIT
8k
7.34</p>
<p>meta-llama/Llama-2-70b-chat-hf
Llama 2 许可证
4k
6.86</p>
<p>令人印象深刻的是，Mixtral Instruct 的性能优于 MT-Bench 上的所有其他开放模型，且是第一个与 GPT-3.5 性能相当的开放模型！</p>
<h4 id="关于命名">关于命名</h4>
<p>Mixtral MoE 模型虽然名字是<strong>Mixtral-8x7B</strong> ，但它其实并没有 56B 参数。发布后不久，我们就发现不少人被名字误导了，认为该模型的行为类似于 8 个模型的集合，其中每个模型有 7B 个参数，但这种想法其实与 MoE 模型的工作原理不符。实情是，该模型中只有某些层 (前馈层) 是各专家独有的，其余参数与稠密 7B 模型情况相同，是各专家共享的。所以，参数总量并不是 56B，而是 45B 左右。所以可能叫它 Mixtral-45-8e
更贴切，更能符合其架构。更多有关 MoE 如何运行的详细信息，请参阅我们之前发表的 《MoE 详解》 一文。</p>
<h4 id="提示格式">提示格式</h4>
<p>基础模型 没有提示格式，与其他基础模型一样，它可用于序列补全或零样本/少样本推理。你可以对基础模型进行微调，将其适配至自己的应用场景。指令模型 有一个非常简单的对话格式。</p>
<pre><code>&lt;s&gt; [INST] User Instruction 1 [/INST] Model answer 1&lt;/s&gt; [INST] User instruction 2[/INST]  
</code></pre>
<p>你必须准确遵循此格式才能有效使用指令模型。稍后我们将展示，使用 transformers
的聊天模板能很轻易地支持这类自定义指令提示格式。</p>
<h4 id="我们不知道的事">我们不知道的事</h4>
<p>与之前的 Mistral 7B 版本一样，对这一新的模型家族，我们也有几个待澄清的问题。比如，我们不知道用于预训练的数据集大小，也不知道它的组成信息以及预处理方式信息。</p>
<p>同样，对于 Mixtral 指令模型，我们对微调数据集或 SFT 和 DPO 使用的超参也知之甚少。</p>
<h4 id="演示">演示</h4>
<p>你可以在 Hugging Face Chat 上与 Mixtral Instruct 模型聊天！点击 此处 开始体验吧。</p>
<h4 id="推理">推理</h4>
<p>我们主要提供两种对 Mixtral 模型进行推理的方法:</p>
<ul>
<li>
<p>通过 🤗 transformers 的 pipeline()
接口。</p>
</li>
<li>
<p>通过 TGI，其支持连续组批、张量并行等高级功能，推理速度极快。</p>
</li>
</ul>
<p>以上两种方法均支持半精度 (float16) 及量化权重。由于 Mixtral 模型的参数量大致相当于 45B 参数的稠密模型，因此我们可以对所需的最低显存量作一个估计，如下:</p>
<p>精度显存需求</p>
<p>float16</p>
<blockquote>
<p>90 GB</p>
</blockquote>
<p>8-bit</p>
<blockquote>
<p>45 GB</p>
</blockquote>
<p>4-bit</p>
<blockquote>
<p>23 GB</p>
</blockquote>
<h4 id="使用--transformers">使用 🤗 transformers</h4>
<p>从 transformers 4.36 版 开始，用户就可以用 Hugging Face 生态系统中的所有工具处理 Mixtral 模型，如:</p>
<ul>
<li>
<p>训练和推理脚本及示例</p>
</li>
<li>
<p>安全文件格式 (safetensors
)</p>
</li>
<li>
<p>与 bitsandbytes (4 比特量化) 、PEFT (参数高效微调) 和 Flash Attention 2 等工具的集成</p>
</li>
<li>
<p>使用文本生成任务所提供的工具及辅助方法</p>
</li>
<li>
<p>导出模型以进行部署</p>
</li>
</ul>
<p>用户唯一需要做的是确保 transformers
的版本是最新的:</p>
<pre><code>pip install -U &quot;transformers==4.36.0&quot; --upgrade  
</code></pre>
<p>下面的代码片段展示了如何使用 🤗 transformers 及 4 比特量化来运行推理。由于模型尺寸较大，你需要一张显存至少为 30GB 的卡才能运行，符合要求的卡有 A100 (80 或 40GB 版本) 、A6000 (48GB) 等。</p>
<pre><code>from transformers import AutoTokenizer  
import transformers  
import torch  
  
model = &quot;mistralai/Mixtral-8x7B-Instruct-v0.1&quot;  
  
tokenizer = AutoTokenizer.from_pretrained(model)  
pipeline = transformers.pipeline(  
    &quot;text-generation&quot;,  
    model=model,  
    model_kwargs={&quot;torch_dtype&quot;: torch.float16, &quot;load_in_4bit&quot;: True},  
)  
  
messages = [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Explain what a Mixture of Experts is in less than 100 words.&quot;}]  
prompt = pipeline.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)  
outputs = pipeline(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)  
print(outputs[0][&quot;generated_text&quot;])  
</code></pre>
<blockquote>
<p><s>[INST] Explain what a Mixture of Experts is in less than 100 words. [/INST] A Mixture of Experts is an ensemble learning method that combines multiple models, or &ldquo;experts,&rdquo; to make more accurate predictions. Each expert specializes in a different subset of the data, and a gating network determines the appropriate expert to use for a given input. This approach allows the model to adapt to complex, non-linear relationships in the data and improve overall performance.</p>
</blockquote>
<h4 id="使用-tgi">使用 TGI</h4>
<p><strong>TGI</strong>  是 Hugging Face 开发的生产级推理容器，可用于轻松部署大语言模型。其功能主要有: 连续组批、流式词元输出、多 GPU 张量并行以及生产级的日志记录和跟踪等。</p>
<p>你可在 Hugging Face 的 推理终端 上部署 Mixtral，其使用 TGI 作为后端。要部署 Mixtral 模型，可至 模型页面，然后单击 Deploy -&gt; Inference Endpoints 按钮即可。</p>
<p><em>注意: 如你的账号 A100 配额不足，可发送邮件至<strong><a href="mailto:api-enterprise@huggingface.co">api-enterprise@huggingface.co</a></strong>  申请升级。</em></p>
<p>你还可以阅读我们的博文<strong>用 Hugging Face 推理终端部署 LLM</strong>  以深入了解如何部署 LLM，该文包含了推理终端支持的超参以及如何使用 Python 和 Javascript 接口来流式生成文本等信息。</p>
<p>你还可以使用 Docker 在 2 张 A100 (80GB) 上本地运行 TGI，如下所示:</p>
<pre><code>docker run --gpus all --shm-size 1g -p 3000:80 -v /data:/data ghcr.io/huggingface/text-generation-inference:1.3.0 \  
 --model-id mistralai/Mixtral-8x7B-Instruct-v0.1 \  
 --num-shard 2 \  
 --max-batch-total-tokens 1024000 \  
 --max-total-tokens 32000  
</code></pre>
<h4 id="用--trl-微调">用 🤗 TRL 微调</h4>
<p>训练 LLM 在技术和算力上都有较大挑战。本节我们将了解在 Hugging Face 生态系统中如何在单张 A100 GPU 上高效训练 Mixtral。</p>
<p>下面是在 OpenAssistant 的 聊天数据集 上微调 Mixtral 的示例命令。为了节省内存，我们对注意力块中的所有线性层执行 4 比特量化和 QLoRA。请注意，与稠密 transformer 模型不同，我们不对专家网络中的 MLP 层进行量化，因为它们很稀疏并且量化后 PEFT 效果不好。</p>
<p>首先，安装 🤗 TRL 的每日构建版并下载代码库以获取 训练脚本:</p>
<pre><code>pip install -U transformers  
pip install git+https://github.com/huggingface/trl  
git clone https://github.com/huggingface/trl  
cd trl  
</code></pre>
<p>然后，运行脚本:</p>
<pre><code>accelerate launch --config_file examples/accelerate_configs/multi_gpu.yaml --num_processes=1 \  
 examples/scripts/sft.py \  
 --model_name mistralai/Mixtral-8x7B-v0.1 \  
 --dataset_name trl-lib/ultrachat_200k_chatml \  
 --batch_size 2 \  
 --gradient_accumulation_steps 1 \  
 --learning_rate 2e-4 \  
 --save_steps 200_000 \  
 --use_peft \  
 --peft_lora_r 16 --peft_lora_alpha 32 \  
 --target_modules q_proj k_proj v_proj o_proj \  
 --load_in_4bit  
</code></pre>
<p>在单张 A100 上训练大约需要 48 小时，但我们可以通过 &ndash;num_processes
来调整 GPU 的数量以实现并行。</p>
<h4 id="量化-mixtral">量化 Mixtral</h4>
<p>如上所见，该模型最大的挑战是如何实现普惠，即如何让它能够在消费级硬件上运行。因为即使以半精度 ( torch.float16
) 加载，它也需要 90GB 显存。</p>
<p>借助 🤗 transformers 库，我们支持用户开箱即用地使用 QLoRA 和 GPTQ 等最先进的量化方法进行推理。你可以阅读 相应的文档 以获取有关我们支持的量化方法的更多信息。</p>
<h4 id="使用-4-比特量化加载-mixtral">使用 4 比特量化加载 Mixtral</h4>
<p>用户还可以通过安装 bitsandbytes
库 ( pip install -U bitsandbytes
) 并将参数 load_in_4bit=True
传给 from_pretrained
方法来加载 4 比特量化的 Mixtral。为了获得更好的性能，我们建议用户使用 bnb_4bit_compute_dtype=torch.float16
来加载模型。请注意，你的 GPU 显存至少得有 30GB 才能正确运行下面的代码片段。</p>
<pre><code>import torch  
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig  
  
model_id = &quot;mistralai/Mixtral-8x7B-Instruct-v0.1&quot;  
tokenizer = AutoTokenizer.from_pretrained(model_id)  
  
quantization_config = BitsAndBytesConfig(  
    load_in_4bit=True,  
    bnb_4bit_compute_dtype=torch.float16  
)  
model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=quantization_config)  
  
prompt = &quot;[INST] Explain what a Mixture of Experts is in less than 100 words. [/INST]&quot;  
inputs = tokenizer(prompt, return_tensors=&quot;pt&quot;).to(0)  
  
output = model.generate(**inputs, max_new_tokens=50)  
print(tokenizer.decode(output[0], skip_special_tokens=True))  
</code></pre>
<p>该 4 比特量化技术由 QLoRA 论文 提出，你可以通过 相应的 Hugging Face 文档 或 这篇博文 获取更多相关信息。</p>
<h4 id="使用-gptq-加载-mixtral">使用 GPTQ 加载 Mixtral</h4>
<p>GPTQ 算法是一种训后量化技术，其中权重矩阵的每一行都是独立量化的，以获取误差最小的量化权重。这些权重被量化为 int4，但在推理过程中会即时恢复为 fp16。与 4 比特 QLoRA 相比，GPTQ 的量化模型是通过对某个数据集进行校准而得的。TheBloke 在 🤗 Hub 上分享了很多量化后的 GPTQ 模型，这样大家无需亲自执行校准就可直接使用量化模型。</p>
<p>对于 Mixtral，为了获得更好的性能，我们必须调整一下校准方法，以确保我们<strong>不会</strong>  量化那些专家门控层。量化模型的最终困惑度 (越低越好) 为 4.40
，而半精度模型为 4.25
。你可在 此处 找到量化模型，要使用 🤗 transformers 运行它，你首先需要更新 auto-gptq
和 optimum
库:</p>
<pre><code>pip install -U optimum auto-gptq  
</code></pre>
<p>然后是从源代码安装 transformers:</p>
<pre><code>pip install -U git+https://github.com/huggingface/transformers.git  
</code></pre>
<p>安装好后，只需使用 from_pretrained
方法加载 GPTQ 模型即可:</p>
<pre><code>import torch  
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig  
  
model_id = &quot;TheBloke/Mixtral-8x7B-v0.1-GPTQ&quot;  
tokenizer = AutoTokenizer.from_pretrained(model_id)  
  
model = AutoModelForCausalLM.from_pretrained(model_id, device_map=&quot;auto&quot;)  
  
prompt = &quot;[INST] Explain what a Mixture of Experts is in less than 100 words. [/INST]&quot;  
inputs = tokenizer(prompt, return_tensors=&quot;pt&quot;).to(0)  
  
output = model.generate(**inputs, max_new_tokens=50)  
print(tokenizer.decode(output[0], skip_special_tokens=True))  
</code></pre>
<p>请注意，你的 GPU 显存至少得有 30GB 才能运行 Mixtral 模型的 QLoRA 和 GPTQ 版本。如果你如上例一样使用了 device_map=&ldquo;auto&rdquo;
，则其在 24GB 显存时也可以运行，因此会有一些层被自动卸载到 CPU。</p>
<h4 id="免责声明及正在做的工作">免责声明及正在做的工作</h4>
<p>*<strong>量化</strong> : 围绕 MoE 的量化还有许多研究正如火如荼地展开。上文展示了我们基于 TheBloke 所做的一些初步实验，但我们预计随着对该架构研究的深入，会涌现出更多进展！这一领域的进展将会是日新月异的，我们翘首以盼。此外，最近的工作，如 QMoE，实现了 MoE 的亚 1 比特量化，也是值得尝试的方案。</p>
<p>*<strong>高显存占用</strong> : MoE 运行推理速度较快，但对显存的要求也相对较高 (因此需要昂贵的 GPU)。这对本地推理提出了挑战，因为本地推理所拥有的设备显存一般较小。MoE 非常适合多设备大显存的基础设施。对 Mixtral 进行半精度推理需要 90GB 显存 🤯。</p>
<h4 id="更多资源">更多资源</h4>
<ul>
<li>
<p>MoE 详解</p>
</li>
<li>
<p>Mistral 的 Mixtral 博文</p>
</li>
<li>
<p>Hub 上的模型</p>
</li>
<li>
<p>开放 LLM 排行榜</p>
</li>
<li>
<p>基于 Mixtral 的 Hugging Chat 聊天演示应用</p>
</li>
</ul>
<h4 id="总结">总结</h4>
<p>我们对 Mixtral 的发布感到欢欣鼓舞！我们正围绕 Mixtral 准备更多关于微调和部署文章，尽请期待。</p>
<blockquote>
<p>🤗 宝子们可以戳<strong>阅读原文</strong>  查看文中所有的外部链接哟！</p>
</blockquote>
<h4 id="heading"></h4>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<p>英文原文: <a href="https://hf.co/blog/mixtral">https://hf.co/blog/mixtral</a></p>
<p>原文作者: Lewis Tunstall，Philipp Schmid，Omar Sanseviero，Pedro Cuenca，Olivier Dehaene，Leandro von Werra，Younes Belkada</p>
<p>译者: Matrix Yao (姚伟峰)，英特尔深度学习工程师，工作方向为 transformer-family 模型在各模态数据上的应用及大规模模型的训练推理。</p>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
<p>更多AI工具，参考<a href="https://ai123.869hr.uk/">Github-AI123</a>，<a href="https://ai123.869hr.uk/">国内AI123</a></p>



          </div>

<<<<<<< HEAD

=======
 可扫如下微信二维码加好友
>>>>>>> HEAD@{1}

<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


