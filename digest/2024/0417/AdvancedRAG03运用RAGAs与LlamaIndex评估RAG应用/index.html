

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>AdvancedRAG03：运用RAGAs与LlamaIndex评估RAG应用 作者： Baihai IDP 来源： Baihai IDP 编者按 ：目前，检索增强生成（Retrieval Augmented Generation，RAG）技术已经广泛使用于各种大模型应用场景。然而，如何准确评估 RAG 系统的性能和效果，一直是业界和学界共同关注的重点问题。若无法对 RAG 系统进行全面、客观的  | AI123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AI123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-cCAOSG8MBO" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2073588164294660"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://ai123.869hr.uk/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://ai123.869hr.uk/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AI123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">AdvancedRAG03：运用RAGAs与LlamaIndex评估RAG应用</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://ai123.869hr.uk/about>AI123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              April 17, 2024 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/3FmD9EKJYf673m6UgInZBrx1bdWrvJnJWm6zqOAicPz1fDxdypKcryq6GjPIkBs94l51B5blnlG3N8T0qvZxS5Q/640?wx_fmt=png&amp;from=appmsg" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <p>作者： Baihai IDP  来源： <a href="https://mp.weixin.qq.com/s/L5w8aybENRfRomFLCLSE9Q">Baihai IDP</a></p>
<p><strong>编者按</strong> ：目前，检索增强生成（Retrieval Augmented Generation，RAG）技术已经广泛使用于各种大模型应用场景。然而，如何准确评估 RAG 系统的性能和效果，一直是业界和学界共同关注的重点问题。若无法对 RAG 系统进行全面、客观的评估，也难以针对性地优化和改进它。因此，开发一套科学、可靠的 RAG 系统评估指标体系，对于推动RAG技术的进一步发展具有重要意义。</p>
<p>本文是Advanced RAG系列的第三篇，介绍了由 RAGAs（Retrieval Augmented Generation Assessment） 提出的 RAG 评估指标框架，并阐述了如何使用 RAGAs 与 LlamaIndex 实现整个评估流程。</p>
<p>**作者 |**<strong>Florian June</strong></p>
<p><strong>编译 | 岳扬</strong></p>
<p>如果你已经为某个真实业务系统开发了检索增强生成（RAG）应用程序，可能会想了解该 RAG 应用的效果如何。换句话说，您可能想评估该 RAG App 的性能。</p>
<p>另外，如果发现现有的 RAG 应用效果不佳，可能还需要验证使用的 RAG 性能优化方法是否有效。换句话说，需要进行评估，确定这些性能优化方法是否起了作用。</p>
<p>在本文，我们首先介绍了由 RAGAs（Retrieval Augmented Generation Assessment）[1] 提出的 RAG 评估指标，RAGAs 是一个用于评估 RAG pipelines 的框架。然后，我们将解释如何使用 RAGAs + LlamaIndex 实现整个评估流程。</p>
<p>01</p>
<p>####<strong>RAG 评估指标</strong></p>
<p>####****</p>
<p>简单来说，RAG 流程涉及三个步骤：<strong>输入用户提供给系统的问题或者需要解决的任务</strong> （input query）<strong>、检索上下文</strong> （retrieved context）<strong>和根据用户提供的问题和检索到的上下文，由语言模型生成回答或者解决方案</strong> （the response generated by the LLM）。这三个步骤构成了 RAG 过程中最重要的三要素，并且相互依存。</p>
<p>因此，如图 1 所示，可以通过衡量这三者之间的相关程度来评估 RAG 的效果如何。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/3FmD9EKJYf673m6UgInZBrx1bdWrvJnJWcibRqalPeGDViaULJpHhcL07rZicwzsdnXqt3xCmIf0touIiaO2Qr6OfA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>图 1：可以通过衡量这些三要素之间的相关程度来评估 RAG 的效果如何。Image by author。</p>
<p>这篇论文[1]提到了 3 个指标：Faithfulness（译者注：生成的内容是否忠实于用户输入的问题和检索到的上下文）、Answer Relevance（译者注：生成的回答是否与用户提出的问题相关）和 Context Relevance（译者注：生成的回答是否与用户提供的背景信息相符），这些指标无需访问人工标注的数据集或参考答案。</p>
<p>此外，RAGAs 网站[2]还介绍了另外两个指标：Context Precision（译者注：上下文精确度，即生成的模型响应中有多少是与上下文相关的）和 Context Recall（译者注：上下文召回率，生成的模型响应中有多少能够涵盖上下文相关的信息）。</p>
<p><strong>1.1****Faithfulness/Groundedness</strong></p>
<p>Faithfulness 指标用于评估模型回答是否基于给定的上下文，有助于开发人员判断、避免 RAG 系统产生错觉，并确保检索到的上下文可以有效地用于 RAG 系统输出的生成。</p>
<p><strong>如果该指标分数较低，则表示 LLM 的响应不符合检索到的知识，提供带有幻觉的答案可能性就会增加。</strong> 例如：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/3FmD9EKJYf673m6UgInZBrx1bdWrvJnJdO6T267x1j8icDzibnnmdGZYX5tp866Cv0ZfH83TP3kB3H61avyaL8KA/640?wx_fmt=png&amp;from=appmsg" alt="">****</p>
<p>图 2：Faithfulness 分数高和 Faithfulness 分数低的模型回答对比示例</p>
<p>资料来源：https://docs.ragas.io/en/latest/concepts/metrics/faithfulness.html</p>
<p>为了预估 Faithfulness 的数值大小，我们首先使用 LLM 提取一组语句 S(a(q))。具体方法如下：</p>
<pre><code>Given a question and answer, create one or more statements from each sentence in the given answer.  
question: [question]  
answer: [answer]
</code></pre>
<p>生成 S(a(q)) 后，LLM 会判断每条语句 Si 是否都能从 c(q) 中推理出来。这一验证步骤通过以下 prompt 进行：</p>
<pre><code>Consider the given context and following statements, then determine whether they are supported by the information present in the context. Provide a brief explan ation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format.  
  
statement: [statement 1]  
...  
statement: [statement n]


考虑给定的上下文和以下陈述，然后确定它们是否得到上下文中存在的信息的支持。在做出结论（是/否）之前，为每个陈述提供一个简短的解释。最后，按照给定的格式对每个陈述做出最终的判决。请不要偏离指定的格式。

  


陈述：[陈述1]

...

陈述：[陈述n]。
</code></pre>
<p>最终的 Faithfulness 指标分数 F 计算公式为 F = |V| / |S|，其中 |V| 表示在验证过程中，LLM（大语言模型）认为能够根据输入的问题和检索到的上下文推导出来的语句数量，而 |S| 表示总语句数量。</p>
<p><strong>1.2 Answer Relevance</strong></p>
<p><strong>该指标衡量生成的答案与用户输入的 query 之间的相关程度。分数越高，相关程度越高。</strong> 例如：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/3FmD9EKJYf673m6UgInZBrx1bdWrvJnJUEJhgBubR2KZicDIEQJjLWBZz3ibcvPOZ50WZGVwh4eb5JhVzpfCyMoQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>图 3：相关程度高的答案和相关程度低的模型回答对比示例</p>
<p>资料来源：https://docs.ragas.io/en/latest/concepts/metrics/answer_relevance.html</p>
<p>为了估计模型回答与用户输入的 query 之间的相关程度，我们让 LLM 根据给定的答案 a(q)，生成 n 个潜在问题 qi，如下所示：</p>
<pre><code>Generate a question for the given answer.  
  
answer: [answer]  
</code></pre>
<p>然后，我们使用文本嵌入模型（text embedding model）获取所有问题的嵌入（embeddings）。</p>
<p>对于每个 qi，都要计算与问题 q 的相似度 sim(q,qi)，对应于嵌入之间的余弦相似度。问题 q 的答案相关程度得分 AR 计算如下：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/3FmD9EKJYf673m6UgInZBrx1bdWrvJnJ3MkFIOyEYWth2qp6wDSVichJQs70Wqe72Apj89iaYUHP3JaGSJIjPV5g/640?wx_fmt=png&amp;from=appmsg" alt="">****</p>
<p>####<strong>1.3 Context Relevance</strong></p>
<p><strong>这是一个用于衡量检索质量的指标，主要评估检索到的上下文对用户提供给系统的问题的支持程度。</strong> 得分低表示检索到的内容中存在大量不相关的内容，可能会影响 LLM 生成的最终答案。例如：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/3FmD9EKJYf673m6UgInZBrx1bdWrvJnJ5pfC5V5E5tMAFDsKItmdoR5RDKI49w49T0gfGovfgpUF2owibyo16fA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>图 4：高上下文相关性和低上下文相关性</p>
<p>资料来源：https://docs.ragas.io/en/latest/concepts/metrics/context_relevancy.html</p>
<p>为了评估上下文的相关性，我们需要使用 LLM 从上下文 (c(q)) 中提取一组关键句子 (Sext) 。这些句子对于帮助 LLM 正确回答问题至关重要。prompt 如下：</p>
<pre><code>Please extract relevant sentences from the provided context that can potentially help answer the following question.   
If no relevant sentences are found, or if you believe the question cannot be answered from the given context,   
return the phrase &quot;Insufficient Information&quot;.   



While extracting candidate sentences you’re not allowed to make any changes to sentences from given context.


请从提供的上下文中提取与以下问题潜在相关的句子。如果找不到相关的句子，或者您认为该问题无法从给定的上下文中得到答案，请返回短语“信息不足”。在提取候选句子时，不得对给定上下文中的句子进行任何更改。
</code></pre>
<p>在 RAGAs 中，对于上下文中的每个句子，可以使用以下公式在句子层面计算其与 query 的相关性：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/3FmD9EKJYf673m6UgInZBrx1bdWrvJnJGbUrOIrpUHibpcDVe7DK36E37b2GWhhZBP3vRIxicdBq7T0g9SouGqug/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p><strong>1.4 Context Recall</strong></p>
<p><strong>该指标衡量的是检索到的上下文与标注的答案之间的一致性程度。</strong> 它使用基准答案和检索到的上下文进行计算，数值越高，表示性能越强。例如：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/3FmD9EKJYf673m6UgInZBrx1bdWrvJnJWm6zqOAicPz1fDxdypKcryq6GjPIkBs94l51B5blnlG3N8T0qvZxS5Q/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>图 5：高上下文召回率和低上下文召回率</p>
<p>资料来源：https://docs.ragas.io/en/latest/concepts/metrics/context_recall.html</p>
<p>在实施评估流程时，需要提供人工标注的基准数据。</p>
<p>计算公式如下：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/3FmD9EKJYf673m6UgInZBrx1bdWrvJnJeXtKUwQhSpPJgf8BdeQEWpibdSueF4iaSLxFsaMFZP9FZ79HvyLxWRag/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>####<strong>1.5 Context Precision</strong></p>
<p><strong>这一指标相对复杂，它用于衡量检索到的包含真实信息的所有相关上下文是否都排在前列。得分越高，表示精确度越高。</strong></p>
<p>该指标的计算公式如下：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/3FmD9EKJYf673m6UgInZBrx1bdWrvJnJuKWLdkRCkpCTEFEBAbUFWH2M3ib8GQ3gHu15QyaLUtv1EHb5JBTuhpA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>上下文精确度（Context Precision）的优点在于其能够感知 ranking effect （译者注：指的是在检索结果中，相关的内容是否能够在排名中被正确地放置在顶部）。但它的缺点是，如果相关的检索结果很少，但排名都很靠前，得分也会很高。因此，有必要通过结合其他几个指标来考虑整体效果。</p>
<p>02</p>
<p>####<strong>使用 RAGAs + LlamaIndex 对 RAG App 进行评估</strong></p>
<p>主要流程如图 6 所示：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/3FmD9EKJYf673m6UgInZBrx1bdWrvJnJV97LMFJze9AGAz6licPcEFibv2NCbxMoY1VvAcSY0t0RH0ywfvUkeDtQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>图 6：Main process. Image by author.</p>
<p><strong>2.1 评估系统运行环境配置</strong></p>
<p>安装 ragas：使用以下命令通过 pip 安装 ragas。</p>
<pre><code>pip install ragas
</code></pre>
<p>然后，检查 ragas 的当前版本。</p>
<pre><code>(py) Florian:~ Florian$ pip list | grep ragas  
ragas                        0.0.22  
</code></pre>
<p>值得一提的是，</p>
<p>使用<code>pip install git+https://github.com/explodinggradients/ragas.git</code>安装最新版本（v0.1.0rc1）的ragas，则不支持 LlamaIndex。</p>
<p>然后，导入相关库，设置环境变量和全局变量。</p>
<pre><code>import os  
os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;YOUR_OPENAI_KEY&quot;  
dir_path = &quot;YOUR_DIR_PATH&quot;  
  
from llama_index import VectorStoreIndex, SimpleDirectoryReader  
  
from ragas.metrics import (  
    faithfulness,  
    answer_relevancy,  
    context_relevancy,  
    context_recall,  
    context_precision  
)  
  
from ragas.llama_index import evaluate  
</code></pre>
<p>目录中只有一个 PDF 文件，即 &ldquo;TinyLlama: An Open Source Small Language Model&rdquo;[3]。</p>
<pre><code>(py) Florian:~ Florian$ ls /Users/Florian/Downloads/pdf_test/  
tinyllama.pdf
</code></pre>
<p>####<strong>2.2****用 LlamaIndex 构建简单的 RAG 查询引擎</strong></p>
<pre><code>documents = SimpleDirectoryReader(dir_path).load_data()  
index = VectorStoreIndex.from_documents(documents)  
query_engine = index.as_query_engine()
</code></pre>
<p>默认情况下，LlamaIndex 使用 OpenAI 模型，但可以使用 ServiceContext 轻松配置 LLM 和嵌入模型（embedding model）。</p>
<p>####<strong>2.3 构建评估数据集</strong></p>
<p>由于有些评估指标需要使用人工标注数据集，我自己编写了一些问题，并标注有相应的答案。</p>
<pre><code>eval_questions = [  
 &quot;Can you provide a concise description of the TinyLlama model?&quot;,  
 &quot;I would like to know the speed optimizations that TinyLlama has made.&quot;,  
 &quot;Why TinyLlama uses Grouped-query Attention?&quot;,  
 &quot;Is the TinyLlama model open source?&quot;,  
 &quot;Tell me about starcoderdata dataset&quot;,  
]  
eval_answers = [  
 &quot;TinyLlama is a compact 1.1B language model pretrained on around 1 trillion tokens for approximately 3 epochs. Building on the architecture and tokenizer of Llama 2, TinyLlama leverages various advances contributed by the open-source community (e.g., FlashAttention), achieving better computational efficiency. Despite its relatively small size, TinyLlama demonstrates remarkable performance in a series of downstream tasks. It significantly outperforms existing open-source language models with comparable sizes.&quot;,  
 &quot;During training, our codebase has integrated FSDP to leverage multi-GPU and multi-node setups efficiently. Another critical improvement is the integration of Flash Attention, an optimized attention mechanism. We have replaced the fused SwiGLU module from the xFormers (Lefaudeux et al., 2022) repository with the original SwiGLU module, further enhancing the efficiency of our codebase. With these features, we can reduce the memory footprint, enabling the 1.1B model to fit within 40GB of GPU RAM.&quot;,   
 &quot;To reduce memory bandwidth overhead and speed up inference, we use grouped-query attention in our model. We have 32 heads for query attention and use 4 groups of key-value heads. With this technique, the model can share key and value representations across multiple heads without sacrificing much performance&quot;,  
 &quot;Yes, TinyLlama is open-source&quot;,  
 &quot;This dataset was collected to train StarCoder (Li et al., 2023), a powerful opensource large code language model. It comprises approximately 250 billion tokens across 86 programming languages. In addition to code, it also includes GitHub issues and text-code pairs that involve natural languages.&quot;,  
]  
eval_answers = [[a] for a in eval_answers]  
</code></pre>
<p><strong>2.4 评估指标的选择和使用 RAGAs 进行评估</strong></p>
<pre><code>metrics = [  
    faithfulness,  
    answer_relevancy,  
    context_relevancy,  
    context_precision,  
    context_recall,  
]  
  
result = evaluate(query_engine, metrics, eval_questions, eval_answers)  
result.to_pandas().to_csv('YOUR_CSV_PATH', sep=',')  
</code></pre>
<p>请注意，默认情况下，在 RAGAs 中使用的是 OpenAI 模型。</p>
<p>在 RAGAs 中，如果想要使用其他 LLM（如 Gemini）与 LlamaIndex 一起对 RAG 系统进行评估，我在 RAGAs 0.0.22 版本中没有找到任何能够实现这个想法的方法，即便在调试了 RAGAs 的源代码后也没有找到。</p>
<p>####<strong>2.5 Final code</strong></p>
<pre><code>import os  
os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;YOUR_OPENAI_KEY&quot;  
dir_path = &quot;YOUR_DIR_PATH&quot;  
  
from llama_index import VectorStoreIndex, SimpleDirectoryReader  
  
from ragas.metrics import (  
    faithfulness,  
    answer_relevancy,  
    context_relevancy,  
    context_recall,  
    context_precision  
)  
  
from ragas.llama_index import evaluate  
  
documents = SimpleDirectoryReader(dir_path).load_data()  
index = VectorStoreIndex.from_documents(documents)  
query_engine = index.as_query_engine()  
  
eval_questions = [  
 &quot;Can you provide a concise description of the TinyLlama model?&quot;,  
 &quot;I would like to know the speed optimizations that TinyLlama has made.&quot;,  
 &quot;Why TinyLlama uses Grouped-query Attention?&quot;,  
 &quot;Is the TinyLlama model open source?&quot;,  
 &quot;Tell me about starcoderdata dataset&quot;,  
]  
eval_answers = [  
 &quot;TinyLlama is a compact 1.1B language model pretrained on around 1 trillion tokens for approximately 3 epochs. Building on the architecture and tokenizer of Llama 2, TinyLlama leverages various advances contributed by the open-source community (e.g., FlashAttention), achieving better computational efficiency. Despite its relatively small size, TinyLlama demonstrates remarkable performance in a series of downstream tasks. It significantly outperforms existing open-source language models with comparable sizes.&quot;,  
 &quot;During training, our codebase has integrated FSDP to leverage multi-GPU and multi-node setups efficiently. Another critical improvement is the integration of Flash Attention, an optimized attention mechanism. We have replaced the fused SwiGLU module from the xFormers (Lefaudeux et al., 2022) repository with the original SwiGLU module, further enhancing the efficiency of our codebase. With these features, we can reduce the memory footprint, enabling the 1.1B model to fit within 40GB of GPU RAM.&quot;,   
 &quot;To reduce memory bandwidth overhead and speed up inference, we use grouped-query attention in our model. We have 32 heads for query attention and use 4 groups of key-value heads. With this technique, the model can share key and value representations across multiple heads without sacrificing much performance&quot;,  
 &quot;Yes, TinyLlama is open-source&quot;,  
 &quot;This dataset was collected to train StarCoder (Li et al., 2023), a powerful opensource large code language model. It comprises approximately 250 billion tokens across 86 programming languages. In addition to code, it also includes GitHub issues and text-code pairs that involve natural languages.&quot;,  
]  
eval_answers = [[a] for a in eval_answers]  
  
metrics = [  
    faithfulness,  
    answer_relevancy,  
    context_relevancy,  
    context_precision,  
    context_recall,  
]  
  
result = evaluate(query_engine, metrics, eval_questions, eval_answers)  
result.to_pandas().to_csv('YOUR_CSV_PATH', sep=',')  
</code></pre>
<p>请注意，在终端（terminal）运行程序时，pandas 数据框可能无法完全显示。如图 6 所示，我们可以将其导出为 CSV 文件来查看。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/3FmD9EKJYf673m6UgInZBrx1bdWrvJnJ4QXib8ekMrmDMPpcRY1XIs6REBNhiaaM0rwQPiaO6UhibCmLDXcogCEGibg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>图 6：Final result. Image by author.</p>
<p>从图 6 中可以明显看出，第四个问题 “ Tell me about starcoderdata dataset, ” 所有指标全部是 0 。这是因为 LLM 无法为这个问题提供回答。第二和第三个问题的上下文精确率（context precision）为0，这表明检索到的上下文中相关的上下文没有排在最前面。第二个问题的上下文召回率（context recall）为 0，表明检索到的上下文与人工标注的答案不匹配。</p>
<p>现在，再来看看 0 到 3 号问题的相关评估情况。模型对这些问题的回答相关性得分都很高，表明模型回答与问题之间相关程度很高。此外，Faithfulness 指标的分数并不低，这表明答案主要是从上下文中得出或总结出来的，因此可以得出结论，这些答案并非由 LLM 产生的幻觉。</p>
<p>此外，我们发现，尽管上下文相关程度（Context Relevance）得分较低，但 gpt-3.5-turbo-16k（RAGAs 使用的默认模型）仍然能够从中推导出答案。</p>
<p>从这些结果来看，显然这个基础的 RAG 系统还有很大的改进空间。</p>
<p>03</p>
<p>####<strong>Conclusion</strong></p>
<p>RAGAs 能够提供多样、全面的评估指标帮助开发者评估 RAG App，并且调用方便。目前，市场上的 RAG 评估框架都还不够完善，RAGAs 是一个效果比较好的 RAG App 评估工具。</p>
<p>在调试 RAGAs 的内部源代码时，我们发现 RAGAs 仍处于早期开发阶段。我们对其未来的更新和进一步改进持乐观态度。</p>
<p>最后，如果您对本文有任何疑问，请在评论区留言指出！</p>
<p><strong>Thanks for reading!</strong></p>
<p>——</p>
<p><strong>Florian June</strong></p>
<p>An artificial intelligence researcher, mainly write articles about Large Language Models, data structures and algorithms, and NLP.</p>
<h4 id="heading"></h4>
<h4 id="heading-1"></h4>
<h4 id="heading-2"></h4>
<p><strong>END</strong></p>
<p><strong>参考资料</strong></p>
<p>[1]https://arxiv.org/pdf/2309.15217.pdf</p>
<p>[2]https://docs.ragas.io/en/latest/concepts/metrics/index.html</p>
<p>[3]https://arxiv.org/pdf/2401.02385.pdf</p>
<p><strong>本文经原作者授权，由 Baihai IDP 编译。如需转载译文，请联系获取授权。</strong></p>
<p><strong>原文链接：</strong></p>
<p><a href="https://ai.plainenglish.io/advanced-rag-03-using-ragas-llamaindex-for-rag-evaluation-84756b82dca7">https://ai.plainenglish.io/advanced-rag-03-using-ragas-llamaindex-for-rag-evaluation-84756b82dca7</a></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/3FmD9EKJYf673m6UgInZBrx1bdWrvJnJ0TibsP2iacibc8cRkK7mHwGPYicohUSY6sTUxPoZEJyr10kqXbibTiaBRwAg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p><strong>AI及大模型技术分享交流群</strong></p>
<p><strong>干货分享，联系小助手入群</strong></p>
<p><em><strong>IDP-Inspiration</strong> <em>是IDP常设专栏</em></em>。** 在这里，我们会分享国内外数据科学家和算法工程师在实战中总结的宝贵经验，为想要从事数据科学和AI开发生产相关工作的小伙伴提供借鉴！</p>
<p>AI相关技术投稿，请联系Alex@baihaiai.com</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/7QRTvkK2qC6hzicPF91rs9ItM18PtNACZC9d2iaU2HnFrgwg1ibIUXSzMpOYK3w9icBdywvBkk95Ccvwrn9UMIjp9g/640?wx_fmt=png" alt=""></p>
<p>如果觉得有帮助，就点点**『在看』** 哦！</p>
<p>更多AI工具，参考<a href="https://ai123.869hr.uk/">Github-AI123</a>，<a href="https://ai123.869hr.uk/">国内AI123</a></p>



          </div>

<<<<<<< HEAD

=======
 可扫如下微信二维码加好友
>>>>>>> HEAD@{1}

<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


