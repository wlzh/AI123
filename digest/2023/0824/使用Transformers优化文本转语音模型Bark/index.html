

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>使用🤗Transformers优化文本转语音模型Bark 作者： Hugging Face 来源： Hugging Face 🤗 Transformers 提供了许多最新最先进 (state-of-the-art, SoTA) 的模型，这些模型横跨多个领域及任务。为了使这些模型能以最佳性能运行，我们需要优化其推理速度及内存使用。 🤗 Hugging Face 生态系统为满足上述需求提供了现成且易于使用的优化工具，这些工具可应用于库中的所有模型  | AI123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AI123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-cCAOSG8MBO" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2073588164294660"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://ai123.869hr.uk/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://ai123.869hr.uk/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AI123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">使用🤗Transformers优化文本转语音模型Bark</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://ai123.869hr.uk/about>AI123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              August 24, 2023 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://869hr.uk/images/blog/aibar123.jpg" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <p>作者： Hugging Face  来源： <a href="https://mp.weixin.qq.com/s/aGQc9KMG3W8NyQI2VzrH4g">Hugging Face</a></p>
<p>🤗 Transformers 提供了许多最新最先进 (state-of-the-art, SoTA) 的模型，这些模型横跨多个领域及任务。为了使这些模型能以最佳性能运行，我们需要优化其推理速度及内存使用。</p>
<p>🤗 Hugging Face 生态系统为满足上述需求提供了现成且易于使用的优化工具，这些工具可应用于库中的所有模型。用户只需添加几行代码就可以轻松<strong>减少内存占用</strong>  并<strong>提高推理速度</strong> 。</p>
<p>在本实战教程中，我将演示如何用三个简单的优化技巧来优化 Bark 模型。Bark 是🤗 Transformers 支持的一个文本转语音 (Text-To-Speech, TTS) 模型。所有优化仅依赖于 Transformers、Optimum 以及 Accelerate 这三个 🤗 生态系统库。</p>
<p>本教程还演示了如何对模型及其不同的优化方案进行性能基准测试。</p>
<p>本文对应的 Google Colab 在:https://colab.research.google.com/github/ylacombe/notebooks/blob/main/Benchmark_Bark_HuggingFace.ipynb</p>
<p>本文结构如下:</p>
<h4 id="目录">目录</h4>
<ol>
<li>
<p>Bark 模型简介</p>
</li>
<li>
<p>不同优化技巧及其优点概述</p>
</li>
<li>
<p>基准测试结果展示</p>
</li>
</ol>
<h4 id="bark-模型架构">Bark 模型架构</h4>
<p><strong>Bark</strong>  是 Suno AI 提出的基于 transformer 的 TTS 模型，其原始代码库为 suno-ai/bark。该模型能够生成各种音频输出，包括语音、音乐、背景噪音以及简单的音效。此外，它还可以产生非语言语音，如笑声、叹息声和抽泣声等。</p>
<p>自 v4.31.0 起，Bark 已集成入 🤗 Transformers！</p>
<p>你可以通过 这个 notebook 试试 Bark 并探索其功能。</p>
<p>Bark 主要由 4 个模型组成:</p>
<ul>
<li>
<p>BarkSemanticModel
(也称为<strong>文本</strong>  模型): 一个因果自回归 transformer 模型，其输入为分词后的词元序列，并输出能捕获文义的语义词元。</p>
</li>
<li>
<p>BarkCoarseModel
(也称为<strong>粗声学</strong>  模型): 一个因果自回归 transformer 模型，其接收 BarkSemanticModel
模型的输出，并据此预测 EnCodec 所需的前两个音频码本。</p>
</li>
<li>
<p>BarkFineModel
(也称为<strong>细声学</strong>  模型)，这次是个非因果自编码器 transformer 模型，它对 <em>先前码本的嵌入和</em> 进行迭代，从而生成最后一个码本。</p>
</li>
<li>
<p>在 EncodecModel
的编码器部分预测出所有码本通道后，Bark 继续用其解码器来解码并输出音频序列。</p>
</li>
</ul>
<p>截至本文撰写时，共有两个 Bark checkpoint 可用，其中一个是 小版，一个是 大版。</p>
<h4 id="加载模型及其处理器">加载模型及其处理器</h4>
<p>预训练的 Bark 小 checkpoint 和 大 checkpoint 均可从 Hugging Face Hub 上加载。你可根据实际需要加载相应的 repo-id。</p>
<p>为了使实验运行起来快点，我们默认使用小 checkpoint，即 “suno/bark-small”
。但你可以随意改成 “suno/bark”
来尝试大 checkpoint。</p>
<pre><code>from transformers import BarkModel  
  
model = BarkModel.from_pretrained(&quot;suno/bark-small&quot;)  
</code></pre>
<p>将模型放到加速器上以优化其速度:</p>
<pre><code>import torch  
  
device = &quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;  
model = model.to(device)  
</code></pre>
<p>加载处理器，它主要处理分词以及说话人嵌入 (若有)。</p>
<pre><code>from transformers import AutoProcessor  
  
processor = AutoProcessor.from_pretrained(&quot;suno/bark-small&quot;)  
</code></pre>
<h4 id="优化技巧">优化技巧</h4>
<p>本节，我们将探索如何使用 🤗 Optimum 和 🤗 Accelerate 库中的现成功能来以最少的代码改动达到优化 Bark 模型的目的。</p>
<h4 id="设置实验环境">设置实验环境</h4>
<p>首先，我们准备一个输入文本并定义一个函数来测量 Bark 生成过程的延迟及其 GPU 显存占用情况。</p>
<pre><code>text_prompt = &quot;Let's try generating speech, with Bark, a text-to-speech model&quot;  
inputs = processor(text_prompt).to(device)  
</code></pre>
<p>测量延迟和 GPU 内存占用需要使用特定的 CUDA 函数。我们实现了一个工具函数，用于测量模型的推理延迟及 GPU 内存占用。为了确保结果的准确性，每次测量我们会运行 nb_loops
次求均值:</p>
<pre><code>import torch  
from transformers import set_seed  
  
def measure_latency_and_memory_use(model, inputs, nb_loops = 5):  
  
  # define Events that measure start and end of the generate pass  
  start_event = torch.cuda.Event(enable_timing=True)  
  end_event = torch.cuda.Event(enable_timing=True)  
  
  # reset cuda memory stats and empty cache  
  torch.cuda.reset_peak_memory_stats(device)  
  torch.cuda.empty_cache()  
  torch.cuda.synchronize()  
  
  # get the start time  
  start_event.record()  
  
  # actually generate  
  for _ in range(nb_loops):  
        # set seed for reproducibility  
        set_seed(0)  
        output = model.generate(**inputs, do_sample = True, fine_temperature = 0.4, coarse_temperature = 0.8)  
  
  # get the end time  
  end_event.record()  
  torch.cuda.synchronize()  
  
  # measure memory footprint and elapsed time  
  max_memory = torch.cuda.max_memory_allocated(device)  
  elapsed_time = start_event.elapsed_time(end_event)* 1.0e-3  
  
  print('Execution time:', elapsed_time/nb_loops, 'seconds')  
  print('Max memory footprint', max_memory*1e-9, ' GB')  
  
  return output  
</code></pre>
<h4 id="基线">基线</h4>
<p>在优化之前，我们先测量下模型的基线性能并听一下生成的音频，我们测量五次并求均值:</p>
<pre><code>with torch.inference_mode():  
  speech_output = measure_latency_and_memory_use(model, inputs, nb_loops = 5)  
</code></pre>
<p><strong>输出:</strong></p>
<pre><code>Execution time: 9.3841625 seconds  
Max memory footprint 1.914612224 GB  
</code></pre>
<p>现在，我们可以播放一下输出音频:</p>
<pre><code>from IPython.display import Audio  
  
# now, listen to the output  
sampling_rate = model.generation_config.sample_rate  
Audio(speech_output[0].cpu().numpy(), rate=sampling_rate)  
</code></pre>
<p>访问<strong>阅读原文</strong>  试听或下载该音频文件。</p>
<h4 id="重要说明">重要说明</h4>
<p>上例中运行次数较少。为了测量和后续对比的准确性，运行次数需要增加到至少 100。</p>
<p>增加 nb_loops
一个主要原因是，同一输入的多次运行所生成的语音长度差异也很大。因此当运行次数较少时，有可能通过 measure_latency_and_memory_use
测出的延迟并不能反映出优化方法的实际性能！文末的基准测试取的是 100 次运行的均值，用以逼近模型的真实性能。</p>
<h4 id="1--better-transformer">1. 🤗 Better Transformer</h4>
<p>Better Transformer 是 🤗 Optimum 的一个功能，它可以帮助在后台执行算子融合。这意味着模型的某些操作在 GPU 上的性能将会得到进一步优化，从而加速模型的最终运行速度。</p>
<p>再具体一点，🤗 Transformers 支持的大多数模型都依赖于注意力，这使得模型在生成输出时可以选择性地关注输入的某些部分，因而能够有效地处理远程依赖关系并捕获数据中复杂的上下文关系。</p>
<p>Dao 等人于 2022 年提出了一项名为 Flash Attention 的技术，极大地优化了朴素注意力的性能。</p>
<p>Flash Attention 是一种更快、更高效的注意力算法，它巧妙地结合了一些传统方法 (如平铺和重计算)，以最大限度地减少内存使用并提高速度。与之前的算法不同，Flash Attention 将内存使用量从与序列长度呈平方关系降低到线性关系，这对关注内存效率的应用尤其重要。</p>
<p>🤗 Better Transformer 可以开箱即用地支持 Flash Attention！只需一行代码即可将模型导出到 🤗 Better Transformer 并启用 Flash Attention:</p>
<pre><code>model =  model.to_bettertransformer()  
  
with torch.inference_mode():  
  speech_output = measure_latency_and_memory_use(model, inputs, nb_loops = 5)  
</code></pre>
<p><strong>输出:</strong></p>
<pre><code>Execution time: 5.43284375 seconds  
Max memory footprint 1.9151841280000002 GB  
</code></pre>
<p>访问<strong>阅读原文</strong>  试听或下载该音频文件。</p>
<p><strong>利弊</strong></p>
<p>效果不会下降，这意味着你可以获得与基线版本完全相同的结果，同时提速 20% 到 30%！想要了解更多有关 Better Transformer 的详细信息，请参阅此 博文。</p>
<h4 id="2-半精度">2. 半精度</h4>
<p>大多数人工智能模型通常使用称为单精度浮点的存储格式，即 fp32
，这在实践中意味着每个数都用 32 比特来存储。</p>
<p>你也可以选择使用 16 比特对每个数进行编码，即所谓的半精度浮点，即 fp16
(译者注: 或 bf16
)，这时每个数占用的存储空间就变成了原来的一半！除此以外，你还可以获得计算上的加速！</p>
<p>但天下没有免费的午餐，半精度会带来较小的效果下降，因为模型内部的操作不如 fp32
精确了。</p>
<p>你可以通过简单地在 BarkModel.from_pretrained(&hellip;)
的入参中添加 torch_dtype=torch.float16
来将 Transformers 模型加载为半精度！</p>
<p>代码如下:</p>
<pre><code>model = BarkModel.from_pretrained(&quot;suno/bark-small&quot;, torch_dtype=torch.float16).to(device)  
  
with torch.inference_mode():  
  speech_output = measure_latency_and_memory_use(model, inputs, nb_loops = 5)  
</code></pre>
<p><strong>输出:</strong></p>
<pre><code>Execution time: 7.00045390625 seconds  
Max memory footprint 2.7436124160000004 GB  
</code></pre>
<p>访问<strong>阅读原文</strong>  试听或下载该音频文件。</p>
<p><strong>利弊</strong></p>
<p>虽然效果略有下降，但内存占用量减少了 50%，速度提高了 5%。</p>
<h4 id="3-cpu-卸载">3. CPU 卸载</h4>
<p>正如本文第一部分所述，Bark 包含 4 个子模型，这些子模型在音频生成过程中按序调用。<strong>换句话说，当一个子模型正在使用时，其他子模型处于空闲状态。</strong></p>
<p>为什么要讨论这个问题呢？因为 GPU 显存在 AI 工作负载中非常宝贵，显存中的运算速度是最快的，而很多情况下显存不足是推理速度的瓶颈。</p>
<p>一个简单的解决方案是将空闲子模型从 GPU 显存中卸载至 CPU 内存，该操作称为 CPU 卸载。</p>
<p><strong>好消息:</strong> Bark 的 CPU 卸载已集成至 🤗 Transformers 中，只需一行代码即可使能。唯一条件是，仅需确保安装了 🤗 Accelerate 即可！</p>
<pre><code>model = BarkModel.from_pretrained(&quot;suno/bark-small&quot;)  
  
# Enable CPU offload  
model.enable_cpu_offload()  
  
with torch.inference_mode():  
  speech_output = measure_latency_and_memory_use(model, inputs, nb_loops = 5)  
</code></pre>
<p><strong>输出:</strong></p>
<pre><code>Execution time: 8.97633828125 seconds  
Max memory footprint 1.3231160320000002 GB  
</code></pre>
<p>访问<strong>阅读原文</strong>  试听或下载该音频文件。</p>
<p><strong>利弊</strong></p>
<p>速度略有下降 (10%)，换得内存占用的巨大降低 (60% 🤯)。</p>
<p>启用此功能后， bark-large
占用空间从原先的 5GB 降至 2GB，与 bark-small
的内存占用相同！</p>
<p>如果你还想要降更多的话，可以试试启用 fp16
，内存占用甚至可以降至 1GB。具体可以参见下一节的数据。</p>
<h4 id="4-组合优化">4. 组合优化</h4>
<p>我们把上述所有优化组合到一起，这意味着你可以合并 CPU 卸载、半精度以及 🤗 Better Transformer 带来的收益！</p>
<pre><code># load in fp16  
model = BarkModel.from_pretrained(&quot;suno/bark-small&quot;, torch_dtype=torch.float16).to(device)  
  
# convert to bettertransformer  
model = BetterTransformer.transform(model, keep_original_model=False)  
  
# enable CPU offload  
model.enable_cpu_offload()  
  
with torch.inference_mode():  
  speech_output = measure_latency_and_memory_use(model, inputs, nb_loops = 5)  
</code></pre>
<p><strong>输出:</strong></p>
<pre><code>Execution time: 7.4496484375000005 seconds  
Max memory footprint 0.46871091200000004 GB  
</code></pre>
<p>访问<strong>阅读原文</strong>  试听或下载该音频文件。</p>
<p><strong>利弊</strong></p>
<p>最终，你将获得 23% 的加速并节约 80% 的内存！</p>
<h4 id="批处理">批处理</h4>
<p>得陇望蜀？</p>
<p>加个批处理吧，上述 3 种优化技巧加上批处理可以进一步提升速度。批处理即将多个样本组合起来一起推理，这样会使这些样本的总生成时间低于逐样本生成时的总生成时间。</p>
<p>下面给出了一个批处理的简单代码:</p>
<pre><code>text_prompt = [  
    &quot;Let's try generating speech, with Bark, a text-to-speech model&quot;,  
    &quot;Wow, batching is so great!&quot;,  
    &quot;I love Hugging Face, it's so cool.&quot;]  
  
inputs = processor(text_prompt).to(device)  
  
with torch.inference_mode():  
  # samples are generated all at once  
  speech_output = model.generate(**inputs, do_sample = True, fine_temperature = 0.4, coarse_temperature = 0.8)  
</code></pre>
<p>访问<strong>阅读原文</strong>  试听或下载上述三个音频文件。</p>
<h4 id="基准测试结果">基准测试结果</h4>
<p>上文我们进行的这些小实验更多是想法验证，我们需要将其扩展以更准确地衡量性能。另外，在每次正式测量性能之前，还需要先跑几轮以预热 GPU。</p>
<p>以下是扩展至 100 个样本的基准测量的结果，使用的模型为<strong>大 Bark</strong> 。</p>
<p>该基准测试在 NVIDIA TITAN RTX 24GB 上运行，最大词元数为 256。</p>
<h4 id="如何解读结果">如何解读结果？</h4>
<h4 id="延迟">延迟</h4>
<p>该指标主要测量每次调用生成函数的平均时间，无论 batch size 如何。</p>
<p>换句话说，它等于 。</p>
<p><strong>延迟越小越好。</strong></p>
<h4 id="最大内存占用">最大内存占用</h4>
<p>它主要测量生成函数在每次调用期间使用的最大内存。</p>
<p><strong>内存占用越小越好。</strong></p>
<h4 id="吞吐量">吞吐量</h4>
<p>它测量每秒生成的样本数。这次，batch size 的因素已被考虑在内。</p>
<p>换句话说，它等于 。</p>
<p><strong>吞吐量越高越好。</strong></p>
<h4 id="单样本推理">单样本推理</h4>
<p>下表为 batch_size=1
的结果。</p>
<p>绝对性能延迟内存占用</p>
<p>无优化
10.48
5025.0M</p>
<p>仅 bettertransformer
7.70
4974.3M</p>
<p>CPU 卸载 + bettertransformer
8.90
2040.7M</p>
<p>CPU 卸载 + bettertransformer + fp16
8.10
1010.4M</p>
<p>相对性能延迟内存占用</p>
<p>无优化
0%
0%</p>
<p>仅 bettertransformer
-27%
-1%</p>
<p>CPU 卸载 + bettertransformer
-15%
-59%</p>
<p>CPU 卸载 + bettertransformer + fp16
-23%
-80%</p>
<h4 id="点评">点评</h4>
<p>不出所料，CPU 卸载极大地减少了内存占用，同时略微增加了延迟。</p>
<p>然而，结合 bettertransformer 和 fp16
，我们得到了两全其美的效果，巨大的延迟和内存降低！</p>
<h4 id="batch-size-为-8">batch size 为 8</h4>
<p>以下是 batch_size=8
时的吞吐量基准测试结果。</p>
<p>请注意，由于 bettertransformer
是一种免费优化，它执行与非优化模型完全相同的操作并具有相同的内存占用，同时速度更快，因此所有的基准测试均<strong>默认开启此优化</strong> 。</p>
<p>绝对性能延迟内存占用吞吐量</p>
<p>基线 (bettertransformer)
19.26
8329.2M
0.42</p>
<ul>
<li>
<p>fp16
10.32
4198.8M
0.78</p>
</li>
<li>
<p>CPU 卸载
20.46
5172.1M
0.39</p>
</li>
<li>
<p>CPU 卸载 + fp16
10.91
2619.5M
0.73</p>
</li>
</ul>
<p>相对性能延迟内存占用吞吐量</p>
<ul>
<li>
<p>基线 (bettertransformer)
0%
0%
0%</p>
</li>
<li>
<p>fp16
-46%
-50%
87%</p>
</li>
<li>
<p>CPU 卸载
6%
-38%
-6%</p>
</li>
<li>
<p>CPU 卸载 + fp16
-43%
-69%
77%</p>
</li>
</ul>
<h4 id="点评-1">点评</h4>
<p>这里，我们看到了组合所有三个优化技巧后的性能潜力！</p>
<p>fp16
对延迟的影响在 batch_size = 1
时不太明显，但在 batch_size = 1
时的表现非常有趣，它可以将延迟减少近一半，吞吐量几乎翻倍！</p>
<h4 id="结束语">结束语</h4>
<p>本文展示了 🤗 生态系统中的一些现成的、简单的优化技巧。使用这些技巧中的任何一种或全部三种都可以极大地改善 Bark 的推理速度和内存占用。</p>
<p>*<strong>使用🤗 Better Transformer 和 CPU 卸载</strong> ，你可以对大 Bark 模型进行推理，而不会出现任何性能下降，占用空间仅为 2GB (而不是 5GB)，同时速度提高 15%。</p>
<ul>
<li>
<p>如果你钟情于高吞吐，可以<strong>把 batch size 打到 8，并利用 🤗 Better Transformer 和 fp16</strong> 。</p>
</li>
<li>
<p>如果你“既要，又要，还要”，试试<strong>fp16、🤗 Better Transformer 加 CPU 卸载</strong>  组合优化吧！</p>
</li>
</ul>
<blockquote>
<p>🤗 宝子们可以戳<strong>阅读原文</strong>  查看文中所有的外部链接哟！</p>
</blockquote>
<h4 id="heading"></h4>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<p>英文原文: <a href="https://hf.co/blog/optimizing-bark">https://hf.co/blog/optimizing-bark</a></p>
<p>原文作者: Yoach Lacombe</p>
<p>译者: Matrix Yao (姚伟峰)，英特尔深度学习工程师，工作方向为 transformer-family 模型在各模态数据上的应用及大规模模型的训练推理。</p>
<p>审校/排版: zhongdongy (阿东)</p>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
<p>更多AI工具，参考<a href="https://ai123.869hr.uk/">Github-AI123</a>，<a href="https://ai123.869hr.uk/">国内AI123</a></p>



          </div>

 可扫如下微信二维码加好友

<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


