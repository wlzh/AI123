

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>全新注意力算法PagedAttention：LLM吞吐量提高2-4倍，模型越大效果越好 作者： PaperWeekly 来源： PaperWeekly ©作者 | LRS 来源 | 新智元 吞吐量上不去有可能是内存背锅！无需修改模型架构，减少内存浪费就能提高吞吐量！ ‍ 虽然大型语言模型（LLM）的性能表现足够惊艳，但每次接收用户请求时都需要耗费大量显存和计算资源，一旦请求数量超出预期，就极有  | AI123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AI123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-cCAOSG8MBO" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2073588164294660"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://ai123.869hr.uk/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://ai123.869hr.uk/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AI123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">全新注意力算法PagedAttention：LLM吞吐量提高2-4倍，模型越大效果越好</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://ai123.869hr.uk/about>AI123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              October 9, 2023 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb278jdtnJMibBHA5JdN9NR3rshia9lzJO3DMuibiaVKZehkxbiaKfTeNKYUmb177iccQl565J0ksTTJEYww/640?wx_fmt=png" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <p>作者： PaperWeekly  来源： <a href="https://mp.weixin.qq.com/s/l60Pn4E0taPJuq2IFHcufg">PaperWeekly</a></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_gif/Psho9dm7oDHKVtfYDubjKdZRUjAfBQQicXjoZWJ3qnK42ooD4eeJUfJBM4SSZVa2RE5lO0j6rWwzliby0j9u4bDg/640?wx_fmt=gif&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p><strong>©作者 |</strong> LRS</p>
<p><strong>来源 |</strong> 新智元</p>
<p>吞吐量上不去有可能是内存背锅！无需修改模型架构，减少内存浪费就能提高吞吐量！</p>
<p>‍</p>
<p>虽然大型语言模型（LLM）的性能表现足够惊艳，但每次接收用户请求时都需要耗费大量显存和计算资源，一旦请求数量超出预期，就极有可能面临ChatGPT刚发布时的宕机、排队、高延迟等窘境。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnT0pwZ7ddianTSaP5cmzd3ZkTLPaOImXF7mpwnu7IJJxWUuw7KeeOEicjynWbWgBsqXE43AgbgCkMQ/640?wx_fmt=png" alt=""></p>
<p>想要打造一个高吞吐量的LLM服务，就需要模型在一个批次内处理尽可能多的请求，不过现有的系统大多在每次处理请求时申请大量的key-value（KV）缓存，如果管理效率不高，大量内存都会在碎片和冗余复制中被浪费掉，限制了batch size的增长。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnT0pwZ7ddianTSaP5cmzd3ZiaD6yrL42XD4Okb9SlIY29lICwuMMUw9yv3scCVGmZEZKbKGcOUibcpA/640?wx_fmt=png" alt=""></p>
<p>最近，来自加州大学伯克利分校、斯坦福大学、加州大学圣迭戈分校的研究人员基于操作系统中经典的虚拟内存和分页技术，提出了一个新的注意力算法PagedAttention，并打造了一个LLM服务系统vLLM。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnT0pwZ7ddianTSaP5cmzd3ZIHC00giciadMw6hOJc6ykIbLLyuCZs33iaRp1uBibjpbD90kk5PvuOLZQA/640?wx_fmt=png" alt=""></p>
<p><strong>论文链接：</strong></p>
<p><a href="https://arxiv.org/pdf/2309.06180.pdf">https://arxiv.org/pdf/2309.06180.pdf</a></p>
<p><strong>代码链接：</strong></p>
<p><a href="https://github.com/vllm-project/vllm">https://github.com/vllm-project/vllm</a></p>
<p>vLLM在KV缓存上实现了几乎零浪费，并且可以在「请求内部」和「请求之间」灵活共享KV高速缓存，进一步减少了内存的使用量。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnT0pwZ7ddianTSaP5cmzd3Z056SJW0w6nTZyxkGd7bWyTjkLtDFtFdmw9sUSXhCtpsw1UZdoG5Brg/640?wx_fmt=png" alt=""></p>
<p>评估结果表明，vLLM可以将常用的LLM吞吐量提高了2-4倍 ，在延迟水平上与最先进的系统（如FasterTransformer和Orca）相当，并且在更长序列、更大模型和更复杂的解码算法时，提升更明显。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGhKg9nnSz5qQrwKvXibt3wulOVRfC18yCkd6xXqGq22h6QUk8chptF0fnQ4uXeZtAktYMrWwG2SyQ/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p><strong>PagedAttention</strong></p>
<p>为了解决注意力机制的内存管理问题，研究人员开发了一种全新的注意力算法PagedAttention，并构建了一个LLM服务引擎vLLM，采用集中式调度器来协调分布式GPU工作线程的执行。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnT0pwZ7ddianTSaP5cmzd3Z4g6icuP04Jvy8splxLI349EkdLTNWUxRaOWV9ryhqDoTmzPzOLibuPsQ/640?wx_fmt=png" alt=""></p>
<p><strong>1. 算法</strong></p>
<p>受操作系统中分页（paging）算法启发，PagedAttention将序列中KV缓存划分为KV块，其中每个块包含固定数量tokens的键（K）和值（V）向量，从而将注意力计算转换为块级运算：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnT0pwZ7ddianTSaP5cmzd3Z4ZUx38L1IqgicibGaoRoJlUhlCpTbH69ibg7s7p4JAiacyAzf3RrYarDaA/640?wx_fmt=png" alt=""></p>
<p>在注意力计算期间，PagedAttention内核分别识别和获取不同的KV块，比如下面的例子中，键和值向量分布在三个块上，并且三个块在物理内存上是不连续的，然后将查询向量与块中的键向量相乘得到部分注意力得分，再乘以块中的值向量得到最终注意力输出。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnT0pwZ7ddianTSaP5cmzd3ZkpoIBttvQSuabAHdYlNgNCLibUlh6D2nDYq5YdaQDWlUdRiambzcnI0w/640?wx_fmt=png" alt=""></p>
<p>这种设计使得KV块存储在非连续物理内存中，从而让vLLM中的分页内存管理更加灵活。</p>
<p><strong>2. KV缓存管理器</strong></p>
<p>操作系统会将内存划分为多个固定大小的页，并将用户程序的逻辑页映射到物理页，连续的逻辑页可以对应于非连续的物理内存页，所以用户在访问内存时看起来就像连续的一样。</p>
<p>此外，物理内存空间不需要提前完全预留，使操作系统能够根据需求动态分配物理页。</p>
<p>通过PageAttention划分出的KV块，vLLM利用虚拟内存机制将KV缓存表示为一系列逻辑KV块，并在生成新token及KV缓存时，从左到右进行填充；最后一个KV块的未填充位置预留给后续生成操作。</p>
<p>KV块管理器还负责维护块表（block table），即每个请求的逻辑和物理KV块之间的映射。</p>
<p>将逻辑和物理KV块分离使得vLLM能够动态地增长KV高速缓存存储器，而无需预先将其保留给所有位置，消除了现有系统中的大多数内存浪费。</p>
<p><strong>3. 解码</strong></p>
<p>从下面的例子中可以看出vLLM如何在单个输入序列的解码过程中执行PagedAttention并管理内存。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnT0pwZ7ddianTSaP5cmzd3Za0ticUzPFof4UKCrliaTzMicGlDEuEfskicb9DJmt0LtjmCus0yQxjZJfw/640?wx_fmt=png" alt=""></p>
<p>① 与操作系统的虚拟内存一样，vLLM最初不需要为最大可能生成的序列长度保留内存，只保留必要的KV块，以容纳在即时计算期间生成的KV缓存。</p>
<p>提示词中包含7个tokens，所以vLLM将前两个逻辑KV块（0和1）映射到2个物理KV块（7和1）；在预填充（prefill）步骤中，vLLM使用自注意算法生成提示和首个输出token的KV缓存；然后将前4个token的KV缓存存储在逻辑块0中，后面3个token存储在逻辑块1中；剩余的slot被保留用于后续自回归生成。</p>
<p>② 在首个自回归解码步骤中，vLLM在物理块7和1上使用PagedAttention算法生成新token</p>
<p>由于最后一个逻辑块中仍有一个slot可用，所以将新生成的KV缓存存储在该slot，更新块表的#filled记录。</p>
<p>③ 在第二次解码步骤中，当最后一个逻辑块已满时，vLLM将新生成的KV缓存存储在新的逻辑块中，为其分配一个新的物理块（物理块3），并映射存储在块表中。</p>
<p>在LLM的计算过程中，vLLM使用PagedAttention内核访问以前以逻辑KV块形式存储的KV缓存，并将新生成的KV缓存保存到物理KV块中。</p>
<p>在一个KV块（块大小&gt;1）中存储多个token使PagedAttention内核能够跨更多位置并行处理KV缓存，从而提高硬件利用率并减少延迟，但较大的块大小也会增加内存碎片。</p>
<p>随着生成越来越多的token及其KV缓存，vLLM会动态地将新的物理块分配给逻辑块，从左到右地填充所有块，并且只有当所有先前的块都满时才分配新的物理块，即请求的所有内存浪费限制在一个块内，可以有效地利用所有内存，从而允许更多的请求放入内存进行批处理，提高了吞吐量；一旦请求完成生成，就可以释放其KV块来存储其他请求的KV缓存。</p>
<p><strong>4. 通用解码</strong></p>
<p>除了贪婪解码和采样，支持单个用户提示输入生成单个输出序列等基本场景外，该算法还可以支持更复杂的解码场景，如并行采样（Parallel sampling）、集束搜索（Beam Search）、共享前缀等。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnT0pwZ7ddianTSaP5cmzd3ZjMQnIf85tvJP6jjvThz6fRvNWKibvKCwoReulgIllyG4bN4Unz3cLqw/640?wx_fmt=png" alt=""></p>
<p><strong>5. 调度和抢占（Scheduling and P****reemption）</strong></p>
<p>当请求流量超过系统容量时，vLLM必须对请求子集进行优先级排序，具体采用「先来先服务」（FCFS）的调度策略，可以确保公平性并防止饥饿。</p>
<p>不过LLM的输入提示在长度上可能变化很大，并且输出长度是先验未知的，具体取决于输入提示和模型；随着请求及其输出数量的增长，vLLM可能会耗尽GPU的物理块来存储新生成的KV缓存。</p>
<p><strong>交换（Swapping）</strong> 是大多数虚拟内存算法使用的经典技术，将被释放的页复制到磁盘上的交换空间。</p>
<p>除了GPU块分配器之外，vLLM还包括CPU块分配器，以管理交换到CPU RAM的物理块；当vLLM耗尽新令牌的空闲物理块时，会选择一组序列来释放KV缓存并将其传输到CPU。</p>
<p>在这种设计中，交换到CPU RAM的块数永远不会超过GPU RAM中的物理块总数，因此CPU RAM上的交换空间受到分配给KV缓存的GPU内存的限制。</p>
<p><strong>重新计算（Recomputation）</strong> ，当被抢占的序列被重新调度时，可以简单地重新计算KV缓存，其延迟可以显著低于原始延迟，因为解码时生成的token可以与原始用户提示连接起来作为新的提示，所有位置的KV缓存可以在一次提示阶段迭代中生成。</p>
<p>交换和重计算的性能取决于CPU、RAM和GPU内存之间的带宽以及GPU的计算能力。</p>
<p><strong>6. 分布式执行（Distributed Execution）</strong></p>
<p>vLLM支持Megatron-LM风格的张量模型并行策略，遵循SPMD（单程序多数据）执行调度，其中线性层被划分以执行逐块矩阵乘法，并且GPU通过allreduce操作不断同步中间结果。</p>
<p>具体来说，注意算子在注意头维度上被分割，每个SPMD过程负责多头注意中的注意头子集，不过每个模型分片仍然处理相同的输入token集合，即在同一位置需要KV缓存。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb278jdtnJMibBHA5JdN9NR3rshia9lzJO3DMuibiaVKZehkxbiaKfTeNKYUmb177iccQl565J0ksTTJEYww/640?wx_fmt=png" alt=""></p>
<p>不同的GPU worker共享管理器，以及从逻辑块到物理块的映射，使用调度程序为每个输入请求提供的物理块来执行模型；尽管每个GPU工作线程具有相同的物理块id，但是一个工作线程仅为其相应的注意头存储KV缓存的一部分。</p>
<p>在每一步中，调度程序首先为批处理中的每个请求准备带有输入token id的消息，以及每个请求的块表；</p>
<p>然后调度程序将该控制消息广播给GPU worker，使用输入token id执行模型；在注意力层，根据控制消息中的块表读取KV缓存；在执行过程中，将中间结果与all-reduce通信原语同步，而无需调度程序的协调。</p>
<p>最后，GPU worker将该迭代的采样token发送回调度器。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGhKg9nnSz5qQrwKvXibt3wuhfgUpIfdPSqH8YjjHbCUiaaKsMA36bIMsMtGNKoBcus5py06M0fvx3A/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p><strong>评估结果</strong></p>
<p><strong>基础采样</strong></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnT0pwZ7ddianTSaP5cmzd3Z5Y4EjicZFicEUMHAs0S6BibsnoJxLmsicGLAQ8TsHV9qB4XGhHns2MR45Q/640?wx_fmt=png" alt=""></p>
<p>在ShareGPT数据集上，随着请求速率的增加，延迟最初缓慢增加，之后会突然激增，可能是因为当请求速率超过服务系统的容量时，导致队列长度无限增长。</p>
<p>vLLM可以承受比Orca高1.7倍-2.7倍的请求速率，比Orca（Max）高2.7倍-8倍的请求速率，同时保持相似的延迟，因为PagedAttention可以有效地管理内存使用，从而能够比Orca在一个批次内处理更多的请求。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnT0pwZ7ddianTSaP5cmzd3ZmNXE9SfkgJOGMN5pn89iaT2gib8lDkzxa5KaBhllJKexAXUvMGz5icZOg/640?wx_fmt=png" alt=""></p>
<p>对于OPT-13B模型，vLLM同时处理的请求比Orca多2.2倍，比Orca（Max）多4.3倍。</p>
<p>与FasterTransformer相比，vLLM实现高达22倍的请求速率，可能是因为没有利用细粒度的调度机制，并且与Orca（Max）一样在内存管理方面很低效。</p>
<p><strong>多序列</strong></p>
<p>在并行采样中，请求中的所有并行序列可以共享提示符的KV缓存，随着采样序列数量的增加，vLLM实现了比Orca基线更大的提升。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnT0pwZ7ddianTSaP5cmzd3ZJsRwR6HreW6BUzEajH6nk9wmSx7hVht4S0kbFkqYtia2yYiaJrWftGgQ/640?wx_fmt=png" alt=""></p>
<p>由于集束搜索中共享内容更多，vLLM展示出了更大的性能优势。</p>
<p>在OPT-13B和Alpaca数据集上，vLLM相对于Orca（Oracle）的改进从基本采样的1.3倍增加到宽度为6的集束搜索的2.3倍。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnT0pwZ7ddianTSaP5cmzd3ZoRg5IMq1JMEe6AksChrRg4xVpliblDvudTojnollslyPb0DZ0by4jwg/640?wx_fmt=png" alt=""></p>
<p>通过计算共享保存的块数除以未共享的总块数计算的存储器节省量，结果显示并行采样节省了6.1%-9.8%的内存，集束搜索节省了37.6%-55.2%的内存。</p>
<p>在使用ShareGPT数据集的相同实验中，可以看到并行采样节省了16.2%-30.5%的内存，集束搜索节省了44.3%-66.3%的内存。</p>
<p>参考资料：</p>
<p><a href="https://arxiv.org/abs/2309.06180">https://arxiv.org/abs/2309.06180</a></p>
<p><strong>更多阅读</strong></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGM3N7wlnkuGBWP0K5LQF1HD1crabSXws2KZWwl3GjZ0RCVTCiaa6Y5AkhkFrIk5DD2iaeUicUicUepxA/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGM3N7wlnkuGBWP0K5LQF1HRn7Xu6KALqiboMuzUulhQc5B2cu17iaNzHljWNcvaF4qtUvvcfb2xkYw/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/Psho9dm7oDGM3N7wlnkuGBWP0K5LQF1H2yeYGc2I6uicH2LsWHQd9fKNzibjicX6nYF4DhINU0QnHeAag0gmKM4qw/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_gif/Psho9dm7oDHHMXQ2IicFvJwssWxgWhKuK7ulQVyw7gPTxZia00vCxia2vzhRH6pGq8t1FN1zY48ibULAEZpic41k6eg/640?wx_fmt=gif&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p><strong>#投 稿 通 道#</strong></p>
<p>** 让你的文字被更多人看到**</p>
<p>如何才能让更多的优质内容以更短路径到达读者群体，缩短读者寻找优质内容的成本呢？<strong>答案就是：你不认识的人。</strong></p>
<p>总有一些你不认识的人，知道你想知道的东西。PaperWeekly 或许可以成为一座桥梁，促使不同背景、不同方向的学者和学术灵感相互碰撞，迸发出更多的可能性。</p>
<p>PaperWeekly 鼓励高校实验室或个人，在我们的平台上分享各类优质内容，可以是<strong>最新论文解读</strong> ，也可以是<strong>学术热点剖析</strong> 、<strong>科研心得</strong> 或<strong>竞赛经验讲解</strong> 等。我们的目的只有一个，让知识真正流动起来。</p>
<p>📝<strong>稿件基本要求：</strong></p>
<p>• 文章确系个人<strong>原创作品</strong> ，未曾在公开渠道发表，如为其他平台已发表或待发表的文章，请明确标注</p>
<p>• 稿件建议以<strong>markdown</strong>  格式撰写，文中配图以附件形式发送，要求图片清晰，无版权问题</p>
<p>• PaperWeekly 尊重原作者署名权，并将为每篇被采纳的原创首发稿件，提供<strong>业内具有竞争力稿酬</strong> ，具体依据文章阅读量和文章质量阶梯制结算</p>
<p>📬<strong>投稿通道：</strong></p>
<p>• 投稿邮箱：hr@paperweekly.site</p>
<p>• 来稿请备注即时联系方式（微信），以便我们在稿件选用的第一时间联系作者</p>
<p>• 您也可以直接添加小编微信（<strong>pwbot02</strong> ）快速投稿，备注：姓名-投稿</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmic1CRCSOKfDibC3dZ4BaJuYyYTWJyw8gFxqon34STk3icf9aJbY4rqMpmhNjTGJXIGGFsCdTBHy3Tw/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p><strong>△长按添加PaperWeekly小编</strong></p>
<p>🔍</p>
<p>现在，在**「知乎」** 也能找到我们了</p>
<p>进入知乎首页搜索**「PaperWeekly」**</p>
<p>点击**「关注」** 订阅我们的专栏吧</p>
<p>·</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgnZ3nlEAOI3MyTd7jqeD6cq8uTbkM2xZNpribyNr9liaPJ722zaHxd0YpQvib2nxOYmWibydCVY7W94ew/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<p>更多AI工具，参考<a href="https://ai123.869hr.uk/">Github-AI123</a>，<a href="https://ai123.869hr.uk/">国内AI123</a></p>



          </div>

<<<<<<< HEAD

=======
 可扫如下微信二维码加好友
>>>>>>> HEAD@{1}

<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


