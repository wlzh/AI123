

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>百川智能发布53B大模型，今年追上GPT-35，并将更新开源模型 作者： Founder Park 来源： Founder Park 8 月 8 日，百川智能发布新一代大模型Baichuan-53B 。 不同于此前发布的 7B 和 13B 模型，Baichuan-53B 并没有走开源路线。 Baichuan-53B 支持中英双语，在知识性上表现优异，相对此前两款模型有更好的表现，擅长知识问答、文本创作等  | AI123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AI123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-LoCoq3KOzQ" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2634092855285462"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://ai123.869hr.uk/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://ai123.869hr.uk/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AI123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">百川智能发布53B大模型，今年追上GPT-35，并将更新开源模型</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://ai123.869hr.uk/about>AI123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              August 9, 2023 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/qpAK9iaV2O3sCIMDROPkrGkScyPUqXMoNGLnGM3P16tRX1icow8CLN22XrhKoXbReexXibybH4Afnjw3HfnscrjXA/640?wx_fmt=jpeg" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <p>作者： Founder Park  来源： <a href="https://mp.weixin.qq.com/s/gkom1eKDnXHzYf7JHG_gSQ">Founder Park</a></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/qpAK9iaV2O3vL5iaecClyfkwfCBoxqGe5z3FWycfjGBudWRfH7DMfWThic2AVvKmjaSBDibX5oA1af3IaFibAFWky3A/640?wx_fmt=png" alt=""></p>
<p>8 月 8 日，百川智能发布新一代大模型<strong>Baichuan-53B</strong> 。</p>
<p>不同于此前发布的 7B 和 13B 模型，Baichuan-53B 并没有走开源路线。</p>
<p>Baichuan-53B 支持中英双语，在知识性上表现优异，相对此前两款模型有更好的表现，<strong>擅长知识问答、文本创作等领域</strong> 。</p>
<p>目前 Baichuan-53B 已在官网开放内测申请，并将在<strong>下个月开放 AP****I</strong> 。</p>
<p>按照计划，今年四季度，百川智能将发布千亿参数的大模型，预计将追上 GPT-3.5 的水平。</p>
<p>此外，王小川对 Founder Park 透露，百川智能的开源模型也将在今年内发布升级版本。</p>
<p>百川强调了 Baichuan-53B 的三个技术优势：<strong>预训练数据</strong> 、<strong>搜索增强</strong> 和<strong>对齐</strong> 能力，其中前两者与百川团队中丰富的搜索引擎经验有较强相关性。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/qpAK9iaV2O3sIAAYwApRhRP93nkEYXrJG6PibicEmWv6md3a3fhy5WulvUFMIZRb6udAuiaq8FVc4f1rtaMD8xQDuw/640?wx_fmt=png" alt=""></p>
<p>####<strong>预训练数据</strong></p>
<p>预训练阶段，王小川表示，此前团队做搜索引擎的经验，让百川能够又快又好地完成前期数据积累，这也是百川此前两款开源模型能够迅速推出的原因之一。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/qpAK9iaV2O3sCIMDROPkrGkScyPUqXMoNGLnGM3P16tRX1icow8CLN22XrhKoXbReexXibybH4Afnjw3HfnscrjXA/640?wx_fmt=jpeg" alt=""></p>
<p>「团队背景做了很多年的搜索，所以<strong>整个中文互联网里哪里有好的数据，我们团队是最清楚的</strong> ，怎么把这些数据收集回来，质量做好，识别出来，我们以前有很强的积累和方法论。」<strong>百川智能联合创始人、大语言模型技术负责人陈炜鹏</strong> 说道。</p>
<ul>
<li>
<p>百川希望构建一个全面的世界知识体系，覆盖各个领域和学科的知识，通过整合各类信息源，确保文化、科学、技术等方面广泛的知识覆盖。</p>
</li>
<li>
<p>目前百川已经建立了一套系统的数据质量体系，包括低质、优质、类别等，确保整个预训练过程中维持高标准的数据质量，以让数据为最终模型训练的目标服务。</p>
</li>
<li>
<p>为保证数据的多样性并有效处理重复信息，百川设计了一个多粒度的大规模聚类系统。通过使用先进的聚类算法和方法，识别和整合相似或相关的数据，为去重、采样提供支撑。</p>
</li>
<li>
<p>百川还开发了一种细粒度的自动化匹配算法，自动配比各类任务，例如课程学习。从而实现个性化的模型学习，使预训练数据能够更精确地匹配用户需求。</p>
</li>
</ul>
<p>####**</p>
<p>####<strong>搜索增强</strong></p>
<p>王小川始终认为，<strong>过去 20 年搜索技术的积累是百川在大模型领域的优势</strong> 。初期，这样的观点在行业里是一种<a href="http://mp.weixin.qq.com/s?__biz=Mzg5NTc0MjgwMw==&amp;mid=2247489626&amp;idx=1&amp;sn=df80af6aec6523cbf8c7b7173b170cdb&amp;chksm=c00afe66f77d7770dd8e78523001563f79ec50bc613940b28b895617715c2e87b35201d65fec&amp;scene=21#wechat_redirect">「非共识」</a>。</p>
<p>这次 Baichuan-53B 的开发过程中，百川应用了更多搜索相关的技术，实现模型优化与改进。</p>
<ul>
<li>
<p>动态响应策略，依赖 Prompt，将指令任务细化为 16 个独立类别，覆盖各种用户指令的场景。</p>
</li>
<li>
<p>智能化搜索词生成，通过对问答样本进行精细化的人工标注，捕捉和理解用户多元化的志林需求。</p>
</li>
<li>
<p>高质量搜索结果筛选，百川构建了一个搜索结果相关性模型，对从搜索内容和知识库中获取的信息进行相关性频分，从而筛选出高质量的搜索引用内容，减少在知识抽取阶段引入的无关、低质量的信息。</p>
</li>
<li>
<p>回答结果的搜索增强，RLHF，让 Baichuan 大模型参照搜索结果，针对用户请求生成高价值且具有实时性的回答。</p>
</li>
</ul>
<p>在采访中，陈炜鹏表示，不同于 ChatGPT 和 Bing 用插件将搜索和模型连接的方式，百川希望<strong>大模型和搜索引擎在模型层面有更强的交互</strong> 。</p>
<p>「搜索和模型的结合从非常底层的地方就开始了。」王小川总结说。</p>
<p>以下是 Baichuan-53B 大模型发布当日，王小川与陈炜鹏同媒体的访谈内容，经极客公园整理编辑。</p>
<p><strong>问：搜索增强是此次发布的 53B 大模型的一个亮点。能具体讲讲百川智能的搜索技术与大****模型的结合吗？</strong></p>
<p><strong>答：</strong> 百川智能在搜索增强系统中融合了多个模块，包括指令意图理解、智能搜索和结果增强等关键组件，通过搜索结合大语言模型技术来优化模型结果生成的可靠性。</p>
<p>OpenAI 跟微软是两个独立的实体，对于搜索这块，它是把搜索当做一个黑盒去使用的这种方式。我们的搜索跟模型的结合是从非常底层的地方就开始融合了。</p>
<p>我们 53B 的模型，用户当有 query 进来之后，它不只是调模型去回答，如果发现这些模型里面没有内在信息的时候，它最后就会去调用搜索。具体调用哪家的搜索，我们目前先不公开。</p>
<p><strong>问：搜索是一个长期的技术思路，还是现在预训练大模型方面没法经常做更新，找一个来补充现在当下能力问题的办法？</strong></p>
<p><strong>答：</strong> 所有的大模型，只要搭建在 Transformer 在这个架构上，就是有幻觉的，就是有非时效性的问题。</p>
<p>我认为，大模型未来变成一个好的服务，需要有多个技术栈在一块，而不是从一个模型直接变成一个服务。你刚刚提的问题背后，含义是模型够好，只是需要一些东西来做补丁。</p>
<p>我认为可以换个角度，最后的服务，大模型只是其中一种技术。模型它天然就有它的瓶颈，它可能会有提升，但是我认为它本质的地方没有变。</p>
<p>模型和搜索会以新的形式融合在一块，而不是模型替代搜索，类似的问题就是一个坑。</p>
<p><strong>问：为什么没有继续开源？</strong></p>
<p><strong>答：</strong> 模型变大之后没有走开源的这样一种方式，因为大家部署起来成本也会非常的高，就是使用闭源让大家网上调用的方式。在我们的官网，大家已经可以申请内测试用了。在我们的计划里，我们后续 53B 也不会开源。</p>
<p><strong>问：闭源有代表商业模式的变化吗？</strong></p>
<p><strong>答：</strong> 开源和闭源不是矛盾的。不管是 7B 还是 13B，还是 53B，都是为 ToB 的行业服务做准备的，往下的话，下个月我们就能开放 API，甚至后面会开始开放一些其他的组件，帮助大家更好地去做后面的对齐，甚至做强化，也有向量数据库等等。把这些 TOB 的一些独立的服务优先给做起来。</p>
<p><strong>问：闭源的好处是什么？</strong></p>
<p><strong>答：</strong> 就对于企业和客户来说，闭源的话对于我们来讲，首先是能够做更大的模型，而更大的模型推理部署的要求很高，开源给企业自己部署使用，企业部署难度也很大。我们认为闭源其实可以提供更简单的接口，做这样的一个调用。它的这个指令的精准度方面会更好，能解决更复杂的问题会多一些。</p>
<p><strong>问：闭源大模型的成本很高，怎么保证竞争力？</strong></p>
<p><strong>答：</strong> 我认为这中间有两件事情，一个是模型效果足够好，拼的是你的这样一个模型的能力。第二个，你得把你的这个推理的成本给降下来，这是世界性的难题。我觉得这里面还有很多功课要去做。</p>
<p><strong>问：闭源大模型的算力如何解决？</strong></p>
<p><strong>答：</strong> 通过云厂商实现。包括腾讯云、阿里云都有提供算力。</p>
<p><strong>问：OpenAI 也经历过从开源到闭源，百川闭源和开源的标准是什么？</strong></p>
<p><strong>答：</strong> 我觉得和大小相关，参数大的部署成本已经开始增加，这种情况下我们就选择走闭源的这样一个服务。但这个开闭的话我觉得不是同一个意思。原来「开」说的是把你的这个论文也开放了，代码也开放了让别人去复刻你，我们这个开源的目的是能够提供给大家更好的去用的，本身它就不是同一个词。</p>
<p>OpenAI 之前是开代码的，它的 GPT-1 和 GPT-2 是有论文、有代码看的。所以我们其实从来没说要开个论文，开个代码，我们这边只是开放模型的能力，让 B 端都能够用到，不管是开源还闭源都能用到你的模型能力。这是和 OpenAI 不一样的模式。</p>
<p><strong>问：有人认为今天在国内做开源是有一些营销的目的，你怎么看？</strong></p>
<p><strong>答：</strong> 我觉得一定程度上是对的，我认为今天说开源应该有几层意义。</p>
<p>第一层的话我觉得就是一个营销行为。要告诉我行不行，有用没用，所以我觉得对于一个后发者开源是挺好的一个选择。这种开源的道路在 OpenAI、LLaMA 面前，也叫后发制人，开源之后是更容易使朋友多多，能够让大家迅速去评测了解，所以营销行为肯定是有的。</p>
<p>第二层的话，开源有时是为了商业化做储备的，本身你有了各种用途之后，有了生态之后，那么其他有更高要求，比如对可靠性的要求，可能需要更好的参数的模型，更大的窗口的时候，我手上有能够能接得上的这种东西，就有了从开源到收费。我认为这件事情在国外是有探索的，在中国虽然之前不成功，但依然是可以借鉴这样的一个思路。</p>
<p><strong>问：百川智能在模型训练方面接下来是如何计划的？</strong></p>
<p><strong>答：</strong> 我觉得现在是个爬坡的状态。对于模型来说，我们认为有三点很重要：一个是大模型本身的能力，尤其指的是预训练的能力，一个是搜索的能力，一个是强化的能力，这三个事情就是共同推动大模型的进步。</p>
<p>从实操角度讲，搜索其实效果是最明显的。强化这件事，是比较有难度的。预训练其实是在提高模型的综合能力。</p>
<p>我们最早讲要发布500亿参数，做到中国最好的对标 GPT 的模型，这意味着对于预训练模型的追求是没法停下来的，未来还会继续去做更大的模型。</p>
<p>但是除此之外，意味着我们对于搜索和强化的技术追求，也会有自己的高度。让我们既能做500亿参数，后面还有自己的差异化。</p>
<p><strong>问：百川智能在 B 端和 C 的战略是什么？</strong></p>
<p><strong>答：</strong> 一家公司不可能把所有赛道都做完。在 B 端，我们选择先做开源模型，B 端企业和中间层的公司，比如做模型二次开发的公司，可以基于这个模型去适用场景。我们的逻辑是我们不去一步做到底，保持足够开放。</p>
<p>C 端的话，今年内部团队开始部署 C 端的超级应用。我们在思考如何追上 GPT-4，思考大模型到底能给 C 端带来哪些应用，同时我们了解到网信办发牌照放行的工作今年一定会被放开。</p>
<p>我们比 OpenAI 在两头都走的更远一点，OpenAI 目前 B 端就是 API 调用，C 端就是 ChatGPT，我们在 B 端更开放，C 端对超级应用有更多的产品定义。</p>
<p><strong>问：在 C 端的超级应用方面，有什么可以透露的吗？</strong></p>
<p><strong>答：</strong> 在这方面我们有很多自己的思考。</p>
<p>在这种创业公司里面，我们从搜狗过来，在几个主流创业公司里面是<strong>唯一一家做过超级应用的公司</strong> 。我们做过两个，一个是搜索，一个是输入法，而且这两个还都是把语言 AI 用到极致。这些语言 AI 和交互式探索里面的各种经验教训也都能够在百川里面能够继续去发扬光大。</p>
<p><strong>问：百川智能为什么能够做到跑的这么快？</strong></p>
<p><strong>答：</strong> 大模型这个事情是相对综合的事情，涉及到几个环节。</p>
<p>第一个环节你的<strong>数据****从哪儿来</strong> ，大家都知道互联网的网页可能是万亿量级的，但是实际是用到模型去训练大概也就是百亿的量级。我们之前这个团队背景是做了很多年的搜索，所以我们对整个中国互联网里面哪里有好的数据，我们这个团队肯定是最清楚的，怎么把这些数据收集回来，并且把它的质量做好，识别出来，这些我们其实以前有一个很强的积累和方法论。大家现在关注到现在大量的语言模型除了中文的数据也好，英文的数据，我们以前在翻译这块也有很强的积累，怎么样能整合中英文的数据，这块我们以前做过很多相关工作，有一些积累。</p>
<p>第二个问题，对于这个<strong>模型本身的训练</strong> ，我们之前在 7B 也发布过，我们整个并行策略调校的水平非常好，在国内也是比较领先的水平。</p>
<p>刚才提到整个模型的训练其实是一个相对复杂的系统，涉及到数据、训练框架、模型本身，需要对整个复杂系统系统有很强的经验，这些我们之前都会有一些积累。</p>
<p>我们做这个事情本身有很强的号召力，除了以前来自搜狗的人才储备以外，也有很多来自头部企业厉害的同学加入我们团队，这个可能是构成了我们为什么能跑得很快的最主要的原因。</p>
<p><strong>问：百川智能打算开始进行商业化吗？</strong></p>
<p><strong>答：</strong> 我们并没有将我们发的头两款大模型商业化。像智谱、MiniMax 这样的公司，更早参与了大模型创业，在我们之前已经干了几个月甚至一年的时间，有他们市场的影响力。我们作为后发者进入到市场，所以开源对我们来讲的话，我们首先是能够先给中国的商业生态做一些贡献，填补一个空白，也是展现我们的一个技术实力。我们相信后面的技术会发展非常快，虽然我们开源了，只要持续不断有后面的这种技术迭代，就会有自己的商业模式出现。</p>
<p><strong>7 月 28 日，洪涛入职百川智能负责商业化方向，我们商业化的工作也会开始开展起来。</strong> 一方面会借助现在的开源引擎，但也有一些更大参数的模型。除此之外，背后的一套组件也在研发当中，能够统一的去做提供部署。</p>
<p>今天在这个体量的公司在今天这个时代里面，我们认为多条线里面都有很多机会，我们对自己团队过往的能力也好，经验也好，是有信心的，能同时打好几场仗：首先模型方面，我们到现在发了三款模型，感觉立住了。其次团队也是在不断的这样的一个扩充过程当中。到了我们成立的第 100 天 我们有 100 个人。到今天是 113 个人，基本就一天招一个人的速度往下走，速度可能还会再抬头。</p>
<p>在这个中间我会很重视，你这个组织是否有足够多优秀的人才，有良好的这种组织能力和分工。有这个能力，哪场仗都能打。</p>
<p><strong>问：百川智能现在的人员构成是什么样的？</strong></p>
<p><strong>答：</strong> 技术人员大概占总人数 70% 到 80% 吧，来自搜狗的旧部大概占到 30%-40%。</p>
<p><strong>问：百川智能更喜欢什么样的大模型人才？</strong></p>
<p><strong>答：</strong> 比较倾向于两种类型的，一种是本身对于<strong>解决复杂问题</strong> ，有很强的<strong>问题拆解能力</strong> 。然后是对于算法或对技术有很好的<strong>技术审美</strong> ，也就是他本身要有很强的<strong>判断力</strong> ，这确实是一个非常重要的点。尤其在算法这个领域，我们每天都会有很多新的 idea 出来，那对于整个算法的思考是有体系的，有没有一个很好的技术审美，其实是一个非常重要的事情。</p>
<p>第二种，对于我们要做的这个事情，ta 听到后<strong>两眼放光</strong> ，觉得是非常向往、非常渴望这种状态。那我觉得这样的人对我们来说，是能够非常好的融入我们的团队，一看就知道和我们是一路人。</p>
<p><strong>问：大厂出身的人，为什么会选择百川智能这样的创业公司？</strong></p>
<p><strong>答：</strong> 我觉得大厂小厂的人，他们都是技术人员。他们选择百川智能有各种原因，首先第一个是有<strong>技术理想</strong> 的，<strong>留在大厂里可能没有机会实现</strong> ，比如做的东西没被选中。其中也有一些是因为组织架构的原因，给他的岗位和工作能力不能匹配。</p>
<p>大厂其实是有人才的，但是甄别人才的能力因为各种各样的原因总是会有欠缺，甚至有动作的走形。所以一些人才就会觉得创业公司里可能会有更好发挥自己能力的机会。</p>
<p>而之前创业公司的问题，是有些工作是创业公司做不来的，你的规模不够，空间不够大。但这件事（大模型），有足够的吸引力，空间也足够大，那么这个工作机会对大厂人才也就有足够的吸引力。</p>
<p><strong>问：今天我们的成本中，算力要占到多大的比例？</strong></p>
<p><strong>答：</strong> 训练阶段算力成本是挺贵的，不同厂商情况可能不一样，行业里 40% 以上可能都得给算力了。我大概猜一下，百川可能到在 40% 到 70% 之间，最后算进来，是包括了 GPU 网络联通。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_jpg/qpAK9iaV2O3sCIMDROPkrGkScyPUqXMoNsat3s3TXia6ibjs7jzqIJQgvWSFZO3tpuq9EnicZ2pibg88kTg3g1BJkbA/640?wx_fmt=jpeg" alt=""></p>
<p><strong>问：百川现在自己做模型也打算做应用，既做运动员也做裁判，会不会造成一些机会的丧失？</strong></p>
<p><strong>答：</strong> 现在我觉得不严重。</p>
<p>我觉得现在还算不上是一个裁判员的身份，我觉得这个例子还没法完整复制过来。今天我觉得还没到那样一个状态，就是 ToB 的话你是足够开放去做，然后 C 端你就选一两款自己进行。</p>
<p>实际上英伟达也是各层都有，你看它既在里面去做底层的 GPU，也会做一体的云服务。所以我认为在各层里你分开去做会有自己的竞争力，今天（大模型）商业上讲还不是这个裁判员的问题。</p>
<p><strong>问：百川智能的融资状况如何？</strong></p>
<p><strong>答：</strong> 融资非常顺利，但现在还不能公布情况。</p>
<p><strong>问：如何看待现在中国的大模型行业整体的状态？</strong></p>
<p><strong>答：</strong> 现在中国的大模型行业，从现象上看，确实大家都在下场在做，每个有技术理想的企业都一定要自己试一下这件事情。所以其实这样就卡的资源不够用。</p>
<p>今天不管是十家、百家、千家，最后一定要看两件事，第一个是否能拿出足够好的 AGI 来，像 GPT3.5、GPT4 去比肩，这件事情大家有相应的距离，我们现在也没做到，往下看今年内有哪些企业能达到 3.5 甚至逼近 4 的能力，现在没有看到之前你很难去判断。二，是否能做出超级应用来，大模型很烧钱，是否能够存在一个超级应用。这两个事情目前还都还看不清。</p>
<p>阶段性能看清的地方就是开源这件事情，大家能够自己做评测，在这个领域里面的话，中国这方面是可能优先达到一个国际水准的。第二的话就是我们的这种超级应用有可能会比美国快，中国做这种科学问题会差一点，但做应用问题确实是我们的强项。</p>
<p>我到美国去之后发现他们这边做技术确实得不错，但是做应用能力实在不怎么样。很多工程师并没有应用的经验。我去之前，我当时提到的是在理想上比 OpenAI 慢半步，在落地上快半步。我回来之后改了，「理想上慢一步，落地上快三步」。</p>
<p>他们满眼放光跟我讲，他们在设计怎么把 1000 万颗 GPU 联在一块做模型架构。我们知道今天训 GPT-4 大概是 2 万颗 GPU，GPT-5 可能是 5 万颗。他们考虑设计 1000 万颗 GPU 做连接结构，你跟他们拼理想这个是没完没了的。你说解决幻觉问题，他们说模型大 10 倍幻觉就下来一些，他们走的不是往落地方向，OpenAI 就是这样的情况。你跟着它走是不够的，因此理想上确实拼不过，但是落地上我们跑得快。</p>
<p><strong>问：创业型公司在这场这个里面该怎么玩？钱在这里面有多重要？</strong></p>
<p><strong>答：</strong> 今天我们看到一个情况，大家一起步公司就几亿美金，今天就 5 亿多美金。第二轮可能就是 10 亿美金的状态，其他几家大公司都是这种状态，所以这种竞争不是小清新，三两个优秀的小同学坐在一块，给你 3 年、5 年的时间。你要迅速进入到大的战役里面。一方面创业公司拿到很多钱去互相卷，还有大厂之间的竞争，大厂有更多的钱，更多的人，更多的算力进来，这种情况下迅速形成一个战斗力。</p>
<p>中国跟美国不太一样，美国通用大模型闭源模型其实头部几家已经定下来了，OpenAI，Google 都有一张门票，在美国做开源大模型做通用已经没有悬念，投资也不会再去投。但是在中国不是，中国谁做最好的大模型现在并没有结论，有一个大家争取的机会，而且还不一定落在大厂里面。</p>
<p>决定胜负的话，我觉得钱是非常重要的一件事情，但最终决定能力的还是人才团队，尤其包括人的能力和组织能力。大厂钱多，人多，算力多，但组织效率不一定够好。创业公司组织效率可能好，也可能不好。</p>
<p>像我们，管理过 3000 人的公司，现在变成 100、300 人，非常容易把效率提上去。因此组织能力对我们来讲不是挑战性的事情，同时也有大厂相对完整的经验，如果在钱上能保证的话，我们的能力还是很强的。</p>
<p><strong>问：现在大模型有同质化的趋势，我们怎么看待这个问题，有没有一些规避的措施？过去说有五张船票，现在还有几张？</strong></p>
<p><strong>答：</strong> 我觉得现在阶段性的会有同质化的问题，目前还是在一个叫做分型复刻的阶段。在这种情况下，你对标的东西就只有一个，就是 OpenAI，那么不可避免的行业会出现同质化。这个阶段过了之后，就开始看你的技术里是否有独有的能力。像我们对搜索的理解，对强化的理解，我们的模型会逐步走出差异化来，这需要一个时间，那更多地方就是在应用里面，那大家就千差万别了。</p>
<p>所以同质化这个事情，今天还是蛮正常的一个现象。才刚开始，那你肯定是向别人先学习，然后才能发挥自己的东西。人生就叫以正和以奇胜，对吧？</p>
<p>船票的话现在依然还是有 5 张，如果只有 2 张我们也会在这个船上。这 5 张并不扣除大公司，<strong>创业公司是没有 5 张船票的</strong> 。</p>
<p><strong>问：现在很多应用开发者都是同时使用多个大模型，这个会是长期趋势还是短期现象？</strong></p>
<p><strong>答：</strong> 现在我倒是觉得这种现象是中国特有的比较好的、比较开放的状态，互相之间没有原来的「二选一」这样互相排挤，这是一个好的状态。</p>
<p>第二是大家现在对于模型的理解都还不是很多。这种情况下，多试几家的也有；非要自己下场试一下的也有。现在行业还没有到一个这个大家形成基础共识的状态，而到未来的时候我觉得慢慢会分层，就各自专注的自己的事情，现在还是一个叫做「群魔乱舞」的状态当中。</p>
<p><strong>问：怎么看大模型在 B 端市场的前景？</strong></p>
<p><strong>答：</strong> 我认为 B 端天花板不高，但确定性是挺清楚的，就是确实很多企业都有这样的一个需求，只是它的对接门槛很高，每个企业有自己的私有数据跟你怎么连。所以如果你没一个好的合作模式的话，最后可能把双方都拖垮掉。一个是信任的问题，一个是 ToB 到后面的一个研发成本会非常高。</p>
<p>我们是需要有中间层的企业来做服务的，既有 B 端的真实场景，也有中间层做服务的，也有后面是做模型的，应该是三层这样一个结构。因为 B 端公司很多技术能力不强，所以中间有各种集成商，有后面的大模型服务商。在银行行业，在保险行业，都有大量中间的公司在给提供服务，这不是个技术问题，而是要能够去衔接行业客户的需求和客户的销售。</p>
<p><strong>问：如何看待开源和闭源？</strong></p>
<p><strong>答：</strong> 今天大家讨论开源闭源的话，它不像是安卓或者 iOS 一样的，是二选一的，手机里要么装安卓，要么装 iOS。而今天的话，这个从 ToB 的角度里面是开源、闭源都需要，不是这样的竞争关系。</p>
<p>我们认为，未来 80% 企业会用开源的模型，在自己的数据里去优化。因为你闭源的话，这个东西没法对产品做特别好的适配。而且开源模型可以做的非常的小巧，因为在很多产品里面并不需要大模型去做数学题。实操里面的话，其实开源模型在很多地方是非常好用的。</p>
<p>我们刚刚提到本身在做 7B、 13B 的时候，收到过一些企业的反馈，他们认为它们已经比闭源的 GPT 更好用了。可以看出，不同产品需要不同的储备，但我们觉得不是一个竞争关系，而是在不同场景有互补的关系。</p>
<p>我们更多地关注是 B 端怎么做，C 端怎么做的问题，而不是把问题停留在开源和闭源上。我甚至认为这个问题也不是现在大家想不明白，难以形成共识的地方了，这个问题的共识已经在形成当中了。</p>
<h4 id="heading"></h4>
<p>如果你关注大模型领域，欢迎扫码加入我们的大模型交流群，来一起探讨大模型时代的共识和认知，跟上大模型时代的这股浪潮。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/qpAK9iaV2O3v5InVrKF4tu5tI9eMgYjRwQhpMGlKpvlzYyiboWYPKDlXVqGqicCsEoTs4y00Rq4b1Y0NPmibKqTBRw/640?wx_fmt=jpeg&amp;tp=wxpic&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p>
<h4 id="heading-1"></h4>
<p><strong>更多阅读</strong></p>
<p><a href="http://mp.weixin.qq.com/s?__biz=Mzg5NTc0MjgwMw==&amp;mid=2247489908&amp;idx=1&amp;sn=10535a664d11e912214dfee785c4d5e3&amp;chksm=c00aff48f77d765eed17b1b7b0b1dff4e3751adf85854808be2c4d87bb00dcd362737701ff6c&amp;scene=21#wechat_redirect">卷起来了！中文 LLaMA2 的一些工作</a>**</p>
<p><a href="http://mp.weixin.qq.com/s?__biz=Mzg5NTc0MjgwMw==&amp;mid=2247489796&amp;idx=1&amp;sn=174d2df91c371554972a83def1a61aaa&amp;chksm=c00aff38f77d762e57549e58d08a2afc9943604b5d2750c3c5093a2a98e7d6e1987092f54a91&amp;scene=21#wechat_redirect">无法想象全闭源的世界：AGI 大会上的开源讨论</a></p>
<p><a href="http://mp.weixin.qq.com/s?__biz=Mzg5NTc0MjgwMw==&amp;mid=2247489778&amp;idx=1&amp;sn=faa5f8da32876f113714985c55d08ad5&amp;chksm=c00afecef77d77d8bb207a607050e4246053c4898438e94527a4554b7b03c39cc7e9e3bc5cc1&amp;scene=21#wechat_redirect">周鸿祎的大模型产品方法论：企业的5个痛点和垂直大模型的6个趋势</a></p>
<p><a href="http://mp.weixin.qq.com/s?__biz=Mzg5NTc0MjgwMw==&amp;mid=2247489714&amp;idx=1&amp;sn=334060502db053c35541f85ca262e2cb&amp;chksm=c00afe8ef77d77986ee764be1eba20114037d7f8ccfe0d48f8dabc4de539dd088f0b7b8c8623&amp;scene=21#wechat_redirect">傅盛的AI-Native创业思考：所有创业者都要相信，这就是最好的时代</a></p>
<p><a href="http://mp.weixin.qq.com/s?__biz=Mzg5NTc0MjgwMw==&amp;mid=2247489626&amp;idx=1&amp;sn=df80af6aec6523cbf8c7b7173b170cdb&amp;chksm=c00afe66f77d7770dd8e78523001563f79ec50bc613940b28b895617715c2e87b35201d65fec&amp;scene=21#wechat_redirect">百川智能王小川：大模型创业100天，我确认找到了属于我的「无人区」</a></p>
<p><a href="http://mp.weixin.qq.com/s?__biz=Mzg5NTc0MjgwMw==&amp;mid=2247489326&amp;idx=1&amp;sn=5e43732bbae4d6d8b6b69866cb5d7bea&amp;chksm=c00af112f77d7804fad2b7c192ad63266f311abf2930b0c50bf18391ef9d688784a5488a6847&amp;scene=21#wechat_redirect">深度解读AI Agents：OpenAI研究多年，可能会改变互联网的软件终极形态</a></p>
<p><a href="http://mp.weixin.qq.com/s?__biz=Mzg5NTc0MjgwMw==&amp;mid=2247488161&amp;idx=1&amp;sn=856a8b40f1941d5d58d95d48ec0e35ce&amp;chksm=c00af49df77d7d8b307232348eee061351d39c103948e2795cc1a4efb345dd22c12e22765cc3&amp;scene=21#wechat_redirect">闭门交流纪要：大模型在机器人领域的应用探讨</a></p>
<p>转载原创文章请添加微信：geekparker</p>
<p>更多AI工具，参考<a href="https://ai123.869hr.uk/">Github-AI123</a>，<a href="https://ai123.869hr.uk/">国内AI123</a></p>



          </div>

<<<<<<< HEAD

=======
 可扫如下微信二维码加好友
>>>>>>> HEAD@{1}

<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


