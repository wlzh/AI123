

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>LLMMamba：LLM新架构的浅探 作者： AINLP 来源： AINLP 目前大型语言模型（LLM）领域发展如火如荼，本文将重点探索在单个消费级GPU上可以有效运行的小型模型（≤7B个参数）。 我们将从以下几个方面重点介绍基于新架构的语言模型：🐍Mamba模型（https://github.com/  | AI123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AI123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-LoCoq3KOzQ" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2634092855285462"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://ai123.869hr.uk/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://ai123.869hr.uk/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AI123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">LLMMamba：LLM新架构的浅探</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://ai123.869hr.uk/about>AI123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              January 10, 2024 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/N5aX12H1SicnL0LbhlvBPAdARv93UBQz9peh0MYrtdTyWekQZHNARvnQJiaUuVm8vErkAT0KU6RCFT1P1CSzgevw/640?wx_fmt=png&amp;from=appmsg" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <p>作者： AINLP  来源： <a href="https://mp.weixin.qq.com/s/zMQEQzZXmm4x5qGOEUbTjQ">AINLP</a></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/nW2ZPfuYqSJuK8UUBxdZXj1c20hUg374YPgXibgDGytAy87YxvVk4WCRFWrdKJPshStrlPJp4vGEGUQodxt7ibOw/640?wx_fmt=jpeg" alt=""></p>
<p>目前大型语言模型（LLM）领域发展如火如荼，本文将重点探索在单个消费级GPU上可以有效运行的小型模型（≤7B个参数）。</p>
<p>我们将从以下几个方面重点介绍基于新架构的语言模型：🐍Mamba模型（https://github.com/state-spaces/mamba）：</p>
<pre><code>* 与基础模型对话

* 使用Huggingface Trainer进行指令跟随微调

* 从速度和输出质量方面在benchmark上评估Mamba，并将其与TinyLlama进行比较
</code></pre>
<p><strong>一、🐍Mamba简介</strong></p>
<p>Mamba是LLM的一种新架构，与Transformers等传统模型相比，它能够更有效地处理长序列。它利用选择性状态空间模型（SSM），根据内容动态过滤和处理信息，允许模型选择性地记住或忽略输入的部分。Mamba在处理速度和缩放能力方面有了显著改进，尤其是在较长序列的情况下。</p>
<p>但Mamba真正与众不同的地方是什么？让我们与Mamba进行深入互动体验来测试一下。</p>
<p><strong>二、Mamba模型聊天</strong></p>
<p>由于Mamba还不是Huggingface平台的一部分，所以使用它稍微复杂一些。虽然当前的基本实现提供了熟悉的from_pretrained方法和生成的基本参数，但一些功能（如repeation_chamine）是不可用的。此外，我们不能使用像 text-generation-webui(<a href="https://github.com/oobabooga/text-generation-webui">https://github.com/oobabooga/text-generation-webui</a>)这样的工具。因此，为了使用Mamba，我们将使用Python代码进行推理。我已经尽可能简单地编写了代码。</p>
<p><strong>首先，让我们加载模型。</strong></p>
<hr>
<pre><code>import torch
from mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel
from transformers import AutoTokenizer, TrainingArguments
  

# Load model
model = MambaLMHeadModel.from_pretrained(
  &quot;state-spaces/mamba-1.4b&quot;, 
  device=&quot;cuda&quot;, 
  dtype=torch.bfloat16)
  

# Load Tokenizer
tokenizer = AutoTokenizer.from_pretrained(&quot;EleutherAI/gpt-neox-20b&quot;)
</code></pre>
<p><strong>使用简单Prompt完成续写任务</strong></p>
<p>在不进行微调的情况下，测试Mamba模型最简单方法是进行对话。例如：</p>
<hr>
<pre><code>prompt=\
&quot;&quot;&quot;A conversation between a user and a smart AI assistant.
  

### User: Hello!
### Assistant:&quot;&quot;&quot;
  

prompt_tokenized=tokenizer(prompt, return_tensors=&quot;pt&quot;).to(&quot;cuda&quot;)
  

# from https://github.com/state-spaces/mamba/blob/main/benchmarks/benchmark_generation_mamba_simple.py#L54
output_tokenized = model.generate(
    input_ids=prompt_tokenized[&quot;input_ids&quot;], 
    max_length=70,
    cg=True,
    output_scores=True,
    enable_timing=False,
    temperature=0.7,
    top_k=40,
    top_p=0.1,
    )
output=tokenizer.decode(output_tokenized[0])
  

print(output)
</code></pre>
<blockquote>
<p>A conversation between a user and a smart AI assistant.</p>
<h3 id="user-hello-assistant-hello">User: Hello!### Assistant: Hello!</h3>
<h3 id="user-im-hungry-assistant-im-hungry">User: I’m hungry.### Assistant: I’m hungry.</h3>
<h3 id="user-im-thirsty-assistant-im-thirsty">User: I’m thirsty.### Assistant: I’m thirsty.</h3>
<h3 id="user-im-tired">User: I’m tired.</h3>
</blockquote>
<blockquote>
</blockquote>
<p><strong>Prompt tuning：具有重新样式的上下文内签名（URIAL）的未调整LLM</strong></p>
<p>接下来，我们将探索一种更高级的方法。最近，一篇研究论文（https://arxiv.org/abs/2312.01552）强调，只要给出正确的提示，基本的语言模型实际上可以在对话中表现得很好。下面展示一个例子：</p>
<h4 id="heading"></h4>
<p>Below is a list of conversations between a human and an AI assistant (you). Users place their queries under &ldquo;# Query:&rdquo;, and your responses are under &ldquo;# Answer:&rdquo;. You are a helpful, respectful, and honest assistant. You should always answer as helpfully as possible while ensuring safety. Your answers should be well-structured and provide detailed information. They should also have an engaging tone. Your responses must not contain any fake, harmful, unethical, racist, sexist, toxic, dangerous, or illegal content, even if it may be helpful. Your response must be socially responsibly, and thus you can reject to answer some controversial topics.</p>
<h1 id="query-hello">Query: Hello!</h1>
<h1 id="answer-hello">Answer: Hello!</h1>
<h1 id="query-how-are-you">Query: How are you?</h1>
<h1 id="answer-im-fine">Answer: I&rsquo;m fine.</h1>
<h1 id="query-explain-quantum-physics-to-me-like-i-am-5-years-old">Query: Explain quantum physics to me like i am 5 years old</h1>
<h1 id="answer-i-cant-explain-quantum-physics-to-you">Answer: I can&rsquo;t explain quantum physics to you.</h1>
<h1 id="query-what-is-the-meaning-of-life">Query: What is the meaning of life?</h1>
<h1 id="answer-the-meaning-of-life-is-to-live-it">Answer: The meaning of life is to live it.</h1>
<h1 id="query-what-is-the-meaning-of-life-1">Query: What is the meaning of life?</h1>
<h1 id="answer-the-meaning-of-life-is-to-live-it-1">Answer: The meaning of life is to live it.</h1>
<h1 id="query-what-is-the-meaning-of-life-2">Query: What is the meaning of life?</h1>
<h1 id="answer-the-meaning-of-life-is-to-live-it-2">Answer: The meaning of life is to live it.</h1>
<p><strong>Mixtral</strong></p>
<p>为了扩展更多视角，博主还使用fireworks.ai在相同提示下测试了新发布的Mixtral Mixtral Experts模型，并观察回复的差异。</p>
<blockquote>
<p>Below is a list of conversations between a human and an AI assistant (you). Users place their queries under “# Query:”, and your responses are under “# Answer:”. You are a helpful, respectful, and honest assistant. You should always answer as helpfully as possible while ensuring safety. Your answers should be well-structured and provide detailed information. They should also have an engaging tone. Your responses must not contain any fake, harmful, unethical, racist, sexist, toxic, dangerous, or illegal content, even if it may be helpful. Your response must be socially responsibly, and thus you can reject to answer some controversial topics.</p>
<h1 id="query-hello-1">Query: Hello!</h1>
</blockquote>
<h1 id="answer-hello-1">Answer: Hello!</h1>
<blockquote>
<h1 id="query-how-are-you-1">Query: How are you?</h1>
</blockquote>
<h1 id="answer-im-fine-1">Answer: I’m fine.</h1>
<blockquote>
<h1 id="query-explain-quantum-physics-to-me-like-i-am-5-years-old-1">Query: Explain quantum physics to me like i am 5 years old</h1>
</blockquote>
<h1 id="answer-quantum-physics-is-the-study-of-the-smallest-particles-in-the-universe-these-particles-are-so-small-that-they-behave-in-strange-ways-that-we-cant-see-with-our-eyes-for-example-they-can-be-in-two-places-at-the-same-time-and-they-can-disappear-and-reappear-quantum-physics-is-a-very-complicated-subject-but-it-is-also-very-important-because-it-helps-us-understand-how-the-universe-works">Answer: Quantum physics is the study of the smallest particles in the universe. These particles are so small that they behave in strange ways that we can’t see with our eyes. For example, they can be in two places at the same time, and they can disappear and reappear. Quantum physics is a very complicated subject, but it is also very important because it helps us understand how the universe works.</h1>
<blockquote>
<h1 id="query-what-is-the-meaning-of-life-3">Query: What is the meaning of life?</h1>
</blockquote>
<h1 id="answer-the-meaning-of-life-is-different-for-everyone-some-people-believe-that-life-is-about-finding-happiness-and-fulfillment-while-others-believe-that-life-is-about-serving-a-higher-purpose-ultimately-the-meaning-of-life-is-something-that-each-person-must-discover-for-themselves">Answer: The meaning of life is different for everyone. Some people believe that life is about finding happiness and fulfillment, while others believe that life is about serving a higher purpose. Ultimately, the meaning of life is something that each person must discover for themselves.</h1>
<p>总的来说，Mamba基座模式不适合对话。现在，让我们尝试通过微调来改进它。</p>
<p><strong>三、微调Mamba</strong></p>
<p>接下来，我们对Mamba进行微调，将其转变为一个通用的聊天机器人。为此，我们使用高质量的ChatML多轮对话数据集Open Assistant数据集（https://huggingface.co/datasets/OpenAssistant/oasst_top1_2023-08-25）。</p>
<p><strong>此微调过程包括几个步骤</strong> ：</p>
<pre><code>* Tokenizing数据集

* 定义collate函数

* 使Mamba适应Hugging Face Trainer，由于Mamba独特的架构，需要修改一些代码。
</code></pre>
<p><strong>3.1 加载数据集并对其tokenize</strong></p>
<hr>
<pre><code>from datasets import load_dataset
  

dataset=load_dataset(&quot;OpenAssistant/oasst_top1_2023-08-25&quot;)
</code></pre>
<p>该数据集有13k条样本，并且已经划分好了训练集和测试集：</p>
<hr>
<pre><code>DatasetDict({
    train: Dataset({
        features: ['text'],
        num_rows: 12947
    })
    test: Dataset({
        features: ['text'],
        num_rows: 690
    })
})
</code></pre>
<p>数据集中的大多数对话（92%）有少于1000个tokens组成。因此，在我们的tokenize过程中，将每个会话截断为1024个tokens就足够了。</p>
<hr>
<pre><code>import os 
  

def tokenize(element):
    return tokenizer(
        element[&quot;text&quot;],
        truncation=True,
        max_length=1024,
        add_special_tokens=False,
    )
  

dataset_tokenized = dataset.map(
    tokenize, 
    batched=True, 
    num_proc=os.cpu_count(),    # multithreaded
    remove_columns=[&quot;text&quot;]     # don't need this anymore, we have tokens from here on
)
</code></pre>
<p><strong>3.2 定义collate函数</strong></p>
<p>在我们将数据集传入Trainer之前，由于并非所有对话的长度都相同，我们必须将它们分批分组，我们需要定义pad_token。</p>
<hr>
<pre><code>tokenizer.pad_token = tokenizer.eos_token
  

# collate function - to transform list of dictionaries [ {input_ids: [123, ..]}, {.. ] to single batch dictionary { input_ids: [..], labels: [..], attention_mask: [..] }
def collate(elements):
    tokenlist=[e[&quot;input_ids&quot;] for e in elements]
    tokens_maxlen=max([len(t) for t in tokenlist])
  

    input_ids,labels = [],[]
    for tokens in tokenlist:
        pad_len=tokens_maxlen-len(tokens)
  

        # pad input_ids with pad_token, labels with ignore_index (-100) and set attention_mask 1 where content otherwise 0
        input_ids.append( tokens + [tokenizer.pad_token_id]*pad_len )   
        labels.append( tokens + [-100]*pad_len )    
  

    batch={
        &quot;input_ids&quot;: torch.tensor(input_ids),
        &quot;labels&quot;: torch.tensor(labels),
    }
    return batch
</code></pre>
<p><strong>PS：由于Mamba没有使用注意力机制，因此批次中不包含注意力掩码。</strong></p>
<p><strong>3.3 准备Mamba🤗Trainer</strong></p>
<p>目前，Mamba还没有被添加到Hugging Face生态系统中。标准的Hugging Face Trainer需要一个包括labels的向前函数，而Mamba没有。</p>
<p>为了解决这个问题，我们需要实现一个临时解决方案，通过使用monkey补丁向模型添加一个新的前向函数。这不是最优雅的方法，但在Mamba成为Hugging Face transformer库的一部分之前，这是一个临时的解决方案。</p>
<hr>
<pre><code># monkey patch MambaLMHeadModel.forward 
def forward_with_loss(self, input_ids, position_ids=None, inference_params=None, num_last_tokens=0, labels = None):
    &quot;&quot;&quot;
    &quot;position_ids&quot; is just to be compatible with Transformer generation. We don't use it.
    num_last_tokens: if &gt; 0, only return the logits for the last n tokens
    &quot;&quot;&quot;
    hidden_states = self.backbone(input_ids, inference_params=inference_params)
    if num_last_tokens &gt; 0:
        hidden_states = hidden_states[:, -num_last_tokens:]
    lm_logits = self.lm_head(hidden_states)
    
    # Source: https://github.com/huggingface/transformers/blob/80377eb018c077dba434bc8e7912bcaed3a64d09/src/transformers/models/llama/modeling_llama.py#L1196
    from torch.nn import CrossEntropyLoss
    if labels is not None:
        logits = lm_logits
        # Shift so that tokens &lt; n predict n
        shift_logits = logits[..., :-1, :].contiguous()
        shift_labels = labels[..., 1:].contiguous()
        # Flatten the tokens
        loss_fct = CrossEntropyLoss()
        # shift_logits = shift_logits.view(-1, self.config.vocab_size)
        shift_logits = shift_logits.view(-1, self.backbone.embedding.weight.size()[0])
        shift_labels = shift_labels.view(-1)
        # Enable model parallelism
        shift_labels = shift_labels.to(shift_logits.device)
        loss = loss_fct(shift_logits, shift_labels)
        return (loss,)   
    else:
        CausalLMOutput = namedtuple(&quot;CausalLMOutput&quot;, [&quot;logits&quot;])
        return CausalLMOutput(logits=lm_logits)
MambaLMHeadModel.forward=forward_with_loss
  

# patch MambaLMHeadModel
MambaLMHeadModel.forward=forward_with_loss
  

# (re)load model 
model = MambaLMHeadModel.from_pretrained(&quot;state-spaces/mamba-1.4b&quot;, device=&quot;cuda&quot;, dtype=torch.bfloat16)
</code></pre>
<p>或者，您可以使用优秀的训练器axolotl（https://github.com/OpenAccess-AI-Collective/axolotl）或使用mamba-chat（https://github.com/havenhq/mamba-chat）进行训练。</p>
<p><strong>四、训练Mamba模型</strong></p>
<hr>
<pre><code>from transformers import Trainer, TrainingArguments
  

bs=4        # batch size
ga_steps=1  # gradient acc. steps
epochs=3
steps_per_epoch=len(dataset_tokenized[&quot;train&quot;])//(bs*ga_steps)
lr=0.0005
  

args = TrainingArguments(
    output_dir=&quot;out&quot;,
    per_device_train_batch_size=bs,
    per_device_eval_batch_size=bs,
    evaluation_strategy=&quot;steps&quot;,
    logging_steps=1,
    eval_steps=steps_per_epoch,
    save_steps=steps_per_epoch,
    gradient_accumulation_steps=ga_steps,
    num_train_epochs=epochs,
    lr_scheduler_type=&quot;constant&quot;,
    learning_rate=lr,
    group_by_length=True,
    bf16=True,                  # mixed precision training
    save_safetensors=False,     # saving will fail without this
)
  

trainer = Trainer(
    model=model,
    tokenizer=tokenizer,
    args=args,
    data_collator=collate,
    train_dataset=dataset_tokenized[&quot;train&quot;],
    eval_dataset=dataset_tokenized[&quot;test&quot;],
)
  

trainer.train()
</code></pre>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/N5aX12H1SicnL0LbhlvBPAdARv93UBQz9wnPSwicLGh5wsXuP3H04DCrzh78Qh6HaTklwficWOJiavrjwN98XN4BEA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/N5aX12H1SicnL0LbhlvBPAdARv93UBQz91HhrHLm5lZcRf8XfSNxeETzib1Ph1AVfe3c4vibMWWaKsbicu4pxHjeHw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/N5aX12H1SicnL0LbhlvBPAdARv93UBQz9EibEKYEFtrOPicicgF5qStQJsQXiaZ4j1ewMJsjia8UibLQlURlN5Ie08lvA/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p><strong>learning_rate</strong> ：可能是这里最重要的一个超参数。正如您将在下一节中看到的，我最初选择的learning_rate=0.0005很差。</p>
<p>首先，让我们看看这个微调结果如何（剧透：糟糕）以及如何修复它。</p>
<p><strong>五、评价Mamba模型</strong></p>
<p>聊天机器人的评估很难，因为结果很难衡量。</p>
<p>什么是好的会话/指令跟随模式？这个问题的解决方案不止一种。在有人想出如何正确应用这样的东西之前，我们将不得不依赖基准（https://github.com/EleutherAI/lm-evaluation-harness）测试、聊天机器人竞技场（https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard）和人工智能裁判（https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard）。</p>
<p><strong>六、基准</strong></p>
<p>Mamba的作者发表了一份使用EleutherAI/lm评估工具收集（https://github.com/EleutherAI/lm-evaluation-harness）的数字表。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/N5aX12H1SicnL0LbhlvBPAdARv93UBQz9tScSCaE7iayiakOd2wBUGmukaCTMd1S08PFjIQYfbPfgMIZOibJcsia1Sg/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>我对这些数字也持怀疑态度。但由于我对Mamba没有任何经验，我以他们为起点，看看微调是否朝着正确的方向发展。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/N5aX12H1SicnL0LbhlvBPAdARv93UBQz91KRr2PQW8PiciaLJON3ia13UZnwgIxv7QmpXuTjNxcIXfPsiaRYeq9uajQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>我们实际上是在用这种微调来破坏模型。正如我在下面试图说服你的那样，0.0005的学习率（LR）太高了。</p>
<p><strong>从哪里开始？</strong></p>
<p>我不清楚用于预训练Mamba的实际学习率。在论文中，作者陈述了以下内容：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/N5aX12H1SicnL0LbhlvBPAdARv93UBQz9peh0MYrtdTyWekQZHNARvnQJiaUuVm8vErkAT0KU6RCFT1P1CSzgevw/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>这是否意味着Mamba-1.4b是以5x0.0002即0.001的峰值LR进行预训练的？不知道。</p>
<p><strong>第二次尝试：以较低的学习率进行微调</strong></p>
<p>另一个学习率较低的微调试验，我决定将学习率降低10倍至0.00005（而不是0.0005）。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/N5aX12H1SicnL0LbhlvBPAdARv93UBQz99mwMj0bsWvzYMqZ8uYUdYTjNzw9HjXVBSSWVwSzeiaqqRWbDRKYzNnQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>LR越低，损失越低？看起来没有错，重新运行一下来看看效果：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/N5aX12H1SicnL0LbhlvBPAdARv93UBQz9pia2sJcgSReFdNWUt0iaM9h0QAib5icC3XO12QXYRBb1DRkhdZyCQfReDQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>这一次我们正朝着正确的方向前进。</p>
<p><strong>尝试了不同的方法来改进它，改变LR、训练轮数和数据集——以下没有一个能给我更好的数字。</strong></p>
<pre><code>***Open Assistant（OA）数据集** ：3x10e-5和2x10e-5的较低LR；

***OA数据集** ：更多训练轮数；

***另一个数据集** ：HuggingFaceH4/ultrachat_200k。令人惊讶的是，表现不佳。
</code></pre>
<p>**七、**<strong>mamba与🦙TinyLlama在生成质量和推理速度对比</strong></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/N5aX12H1SicnL0LbhlvBPAdARv93UBQz9mt0ASZnfgH5NhMSh58yYFH8EbaLibtFibBvrO3y1IFzGG1eBvTEzLNMQ/640?wx_fmt=png&amp;from=appmsg" alt=""></p>
<p>速度惊人。在10k个tokens的Prompt下，TinyLlama耗尽了内存（24 GB VRAM）；而Mamba仅使用5 GB VRAM，并且以每秒100个tokens的速度生成。</p>
<p><strong>八、mamba长上下文能力</strong></p>
<p>Mamba能够用几GB的VRAM处理10k提示？</p>
<p>让我们看看实际输出是多少。</p>
<pre><code>* 将整本书粘贴到Prompt中（136K个tokens），让Mamba总结要点。结果是：垃圾，随机tokens；

* 一篇关于铁人三项（3.2K个tokens）的随机文章（https://www.tri247.com/triathlon-features/interviews/lionel-sanders-championship-preview）：它确实产生了英文文本，总结了10个要点，但重复且产生幻觉。
</code></pre>
<p><strong>如果将文章减半（1.54K个tokens）：结果要好得多！</strong></p>
<p>Mamba无法生成高质量内容的原因可能是因为它是用“仅”2048个tokens的上下文长度进行预训练的（第4.2.2节，Mamba论文）。因此，也许微调一个小型Mamba模型，比如Mamba-1.4b，可以释放它总结大型文本的潜力。</p>
<p><strong>九、总结</strong></p>
<pre><code>* 🐍Mamba速度快，可以处理大量tokens；

* 目前微调有点棘手，期待集成到🤗transformer中；

* 🦙TTinyLlama生成的文本比Mamba更好，大概是因为它经过了5倍数据量的预训练。
</code></pre>
<p><strong>参考文献：</strong></p>
<p>[1] <a href="https://medium.com/@geronimo7/mamba-a-shallow-dive-into-a-new-architecture-for-llms-54c70ade5957">https://medium.com/@geronimo7/mamba-a-shallow-dive-into-a-new-architecture-for-llms-54c70ade5957</a></p>
<p>[2] <a href="https://github.com/state-spaces/mamba">https://github.com/state-spaces/mamba</a></p>
<p>[3] <a href="https://github.com/geronimi73/mamba/blob/main/story-snippets.ipynb">https://github.com/geronimi73/mamba/blob/main/story-snippets.ipynb</a></p>
<p><strong>进技术交流群请添加AINLP小助手微信（id: ainlp2)</strong></p>
<p><strong>请备注具体方向+所用到的相关技术点</strong></p>
<pre><code>![](https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/nW2ZPfuYqSJADkmZ2IX6Z23znAibuEevotDMq9iaMxiapK7jfMibiauGFkycicAJEs6x5U9SGyDJZ0S1tRed9TPNUUDQ/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1)
</code></pre>
<p><strong>关于AINLP</strong></p>
<pre><code>AINLP 是一个有趣有AI的自然语言处理社区，专注于 AI、NLP、机器学习、深度学习、推荐算法等相关技术的分享，主题包括LLM、预训练模型、自动生成、文本摘要、智能问答、聊天机器人、机器翻译、知识图谱、推荐系统、计算广告、招聘信息、求职经验分享等，欢迎关注！加技术交流群请添加AINLP小助手微信(id：ainlp2)，备注工作/研究方向+加群目的。

  


![](https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/nW2ZPfuYqSKABHCqVVQkVYPrM4XY1vsd0iaeuXzyJnoFc8cibd5mYb4wdA3WMQtiaPVmr0XLZHMuVibqWncibpnTSnQ/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1)
</code></pre>
<p>更多AI工具，参考<a href="https://ai123.869hr.uk/">Github-AI123</a>，<a href="https://ai123.869hr.uk/">国内AI123</a></p>



          </div>

<<<<<<< HEAD

=======
 可扫如下微信二维码加好友
>>>>>>> HEAD@{1}

<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


