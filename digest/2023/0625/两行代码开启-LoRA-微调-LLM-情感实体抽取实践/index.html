

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>两行代码开启 LoRA 微调 &amp;&amp; LLM 情感实体抽取实践 作者： AINLP 来源： [AINLP](https://mp.weixin.qq.com/s/F5SZIvYocwimopOCghpU1Q) Huggingface 开源的 PEFT 大模型高效微调工具包，让普通老百姓玩起大模型不再是梦。下面介绍了笔者的一个 github 仓库，对代表性中文大模型进行 LoRA 微调，只要你有训练数据，然后本地下载好大模型的checkpoint，就可以最少只需 2 行代码 就可以微调你自己的  | AI123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AI123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-cCAOSG8MBO" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2073588164294660"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://ai123.869hr.uk/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://ai123.869hr.uk/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AI123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">两行代码开启 LoRA 微调 &amp;&amp; LLM 情感实体抽取实践</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://ai123.869hr.uk/about>AI123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              June 23, 2023 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://ai123.869hr.uk/images/20230623/11602343095298588028.webp" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <pre><code>作者： AINLP  来源： [AINLP](https://mp.weixin.qq.com/s/F5SZIvYocwimopOCghpU1Q)
</code></pre>
<blockquote>
<p><img src="/images/20230623/11602343095298588028.webp" alt=""></p>
</blockquote>
<blockquote>
<p>Huggingface 开源的 PEFT
大模型高效微调工具包，让普通老百姓玩起大模型不再是梦。下面介绍了笔者的一个 github 仓库，对代表性中文大模型进行 LoRA 微调，只要你有训练数据，然后本地下载好大模型的checkpoint，就可以<strong>最少只需 2 行代码</strong> 就可以微调你自己的 LLM。然后，介绍了我使用这个工具，进行 <strong>LLM</strong>  <strong>情感实体抽取</strong> 的一个实践。</p>
</blockquote>
<p><strong>仓库地址：</strong> *<strong><a href="https://github.com/beyondguo/LLM-Tuning">https://github.com/beyondguo/LLM-Tuning</a></strong> *</p>
<p>目前支持：</p>
<ul>
<li>清华 ChatGLM-6B 的 LoRA 微调</li>
<li>百川智能 baichuan-7B 的 LoRA 微调</li>
<li>更多模型持续更新中&hellip;</li>
</ul>
<p><strong>两行代码开启训练</strong> ：</p>
<ul>
<li>数据集分词预处理：sh tokenize.sh
，对比不同的 LLM，需在 tokenize.sh 文件里切换 model_checkpoint 参数</li>
<li>开启 LoRA 微调：sh train.sh
，对于不同的 LLM，需切换不同的 python 文件来执行：
<ul>
<li>
<p>ChatGLM-6B 应使用 chatglm_lora_tuning.py</p>
</li>
<li>
<p>baichuan-7B 应使用 baichuan_lora_tuning.py</p>
</li>
</ul>
</li>
</ul>
<p><strong>环境准备</strong> ：<br>
pip install transformers datasets accelerate sentencepiece tensorboard peft</p>
<p>目前测试的环境为：</p>
<pre><code>- torch, Version: 2.0.1  
- transformers, Version: 4.29.1  
- datasets, Version: 2.12.0  
- accelerate, Version: 0.19.0  
- peft, Version: 0.3.0  
- sentencepiece, Version: 0.1.99  
- tensorboard, Version: 2.13.0  
</code></pre>
<h4 id="教程">教程：</h4>
<p>下面的教程以及代码使用 ChatGLM-6B
作为例子，如果更换其他模型，可能需要略微修改具体文件代码。</p>
<h4 id="1-指令微调数据准备">1. 指令微调数据准备</h4>
<p><strong>① 原始文件的准备</strong></p>
<p>指令微调数据一般有输入和输出两部分，输入是特定的content加上instruction，这里我们将二者直接拼在一起，不单独区分；输出则是希望模型的回答。我们统一使用json
的格式在整理数据，可以自定义输出输出的字段名，例如下面的例子中我使用的是q
和a
代表模型的输入和输出：</p>
<pre><code>{&quot;q&quot;: &quot;请计算：39 * 0 = 什么？&quot;, &quot;a&quot;: &quot;这是简单的乘法运算，39乘以0得到的是0&quot;}  
{&quot;q&quot;: &quot;题目：51/186的答案是什么?&quot;, &quot;a&quot;: &quot;这是简单的除法运算，51除以186大概为0.274&quot;}  
{&quot;q&quot;: &quot;鹿妈妈买了24个苹果，她想平均分给她的3只小鹿吃，每只小鹿可以分到几个苹果？&quot;, &quot;a&quot;: &quot;鹿妈妈买了24个苹果，平均分给3只小鹿吃，那么每只小鹿可以分到的苹果数就是总苹果数除以小鹿的只数。\n24÷3=8\n每只小鹿可以分到8个苹果。所以，答案是每只小鹿可以分到8个苹果。&quot;}  
...  
</code></pre>
<p>整理好数据后，保存为.json
或者.jsonl
文件，然后放入目录中的data/
文件夹中。</p>
<p><strong>② 对数据集进行分词</strong></p>
<p>为了避免每次训练的时候都要重新对数据集分词，我们先分好词形成特征后保存成可直接用于训练的数据集。</p>
<p>例如，</p>
<ul>
<li>
<p>我们的原始指令微调文件为：data/
文件夹下的 simple_math_4op.json
文件</p>
</li>
<li>
<p>输入字段为q
，输出字段为a</p>
</li>
<li>
<p>希望经过 tokenize 之后保存到 data/tokenized_data/
下名为 simple_math_4op
的文件夹中</p>
</li>
<li>
<p>设定文本最大程度为 2000</p>
</li>
</ul>
<p>则我们可以直接使用下面这段命令 (即tokenize.sh
文件) 进行处理：</p>
<pre><code>CUDA_VISIBLE_DEVICES=0,1 python tokenize_dataset_rows.py \  
    --model_checkpoint THUDM/chatglm-6b \  
    --input_file simple_math_4op.json \  
    --prompt_key q \  
    --target_key a \  
    --save_name simple_math_4op \  
    --max_seq_length 2000 \  
    --skip_overlength False  
</code></pre>
<p>处理完毕之后，我们会在 data/tokenized_data/
下发现名为 simple_math_4op
的文件夹，这就是下一步中我们可以直接用于训练的数据。</p>
<h4 id="2-使用-lora">2. 使用 LoRA</h4>
<p>微调</p>
<p>得到 tokenize 之后的数据集，就可以直接运行 chatglm_lora_tuning.py
来训练 LoRA 模型了，具体可设置的主要参数包括：</p>
<ul>
<li>tokenized_dataset
, 分词后的数据集，即在 data/tokenized_data/ 地址下的文件夹名称</li>
<li>lora_rank
, 设置 LoRA 的秩，推荐为4或8，显存够的话使用8</li>
<li>per_device_train_batch_size
, 每块 GPU 上的 batch size</li>
<li>gradient_accumulation_steps
, 梯度累加，可以在不提升显存占用的情况下增大 batch size</li>
<li>max_steps
, 训练步数</li>
<li>save_steps
, 多少步保存一次</li>
<li>save_total_limit
, 保存多少个checkpoint</li>
<li>logging_steps
, 多少步打印一次训练情况(loss, lr, etc.)</li>
<li>output_dir
, 模型文件保存地址</li>
</ul>
<p>例如我们的数据集为 simple_math_4op，希望保存到 weights/simple_math_4op ，则执行下面命令(即train.sh
文件)：</p>
<pre><code>CUDA_VISIBLE_DEVICES=2,3 python chatglm_lora_tuning.py \  
    --tokenized_dataset simple_math_4op \  
    --lora_rank 8 \  
    --per_device_train_batch_size 10 \  
    --gradient_accumulation_steps 1 \  
    --max_steps 100000 \  
    --save_steps 200 \  
    --save_total_limit 2 \  
    --learning_rate 1e-4 \  
    --fp16 \  
    --remove_unused_columns false \  
    --logging_steps 50 \  
    --output_dir weights/simple_math_4op  
</code></pre>
<p>训练完之后，可以在 output_dir 中找到 LoRA 的相关模型权重，主要是adapter_model.bin
和adapter_config.json
两个文件。</p>
<blockquote>
<p>如何查看 tensorboard：</p>
</blockquote>
<ul>
<li>
<p>在 output_dir 中找到 runs 文件夹，复制其中日期最大的文件夹的地址，假设为 your_log_path</p>
</li>
<li>
<p>执行 tensorboard &ndash;logdir your_log_path
命令，就会在 http://localhost:6006/ 上开启tensorboard</p>
</li>
<li>
<p>如果是在服务器上开启，则还需要做端口映射到本地。推荐使用 VSCode 在服务器上写代码，可以自动帮你进行端口映射。</p>
</li>
<li>
<p>如果要自己手动进行端口映射，具体方式是在使用 ssh 登录时，后面加上 -L 6006:127.0.0.1:6006
参数，将服务器端的6006端口映射到本地的6006端口。</p>
</li>
</ul>
<h4 id="3-拿走-lora-小小的文件到你本地的大模型上加载并推理">3. 拿走 LoRA 小小的文件，到你本地的大模型上加载并推理</h4>
<p>我们可以把上面的 output_dir 打包带走，假设文件夹为 weights/simple_math_4op
， 其中（至少）包含 adapter_model.bin
和 adapter_config.json
两个文件，则我们可以用下面的方式直接加载，并推理</p>
<pre><code>from peft import PeftModel  
from transformers import AutoTokenizer, AutoModel  
import torch  
  
device = torch.device(1)  
# 加载原始 LLM  
model_path = &quot;THUDM/chatglm-6b&quot;  
model = AutoModel.from_pretrained(model_path, trust_remote_code=True).half().to(device)  
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)  
model.chat(tokenizer, &quot;你好&quot;, history=[])  
  
  
# 给原始 LLM 安装上你的 LoRA tool  
model = PeftModel.from_pretrained(model, &quot;weights/simple_math_4op&quot;).half()  
model.chat(tokenizer, &quot;你好&quot;, history=[])  
</code></pre>
<p>理论上，可以通过多次执行 model = PeftModel.from_pretrained(model, &ldquo;weights/simple_math_4op&rdquo;).half()
的方式，加载多个 LoRA 模型，从而混合不同Tool的能力，但实际测试的时候，由于暂时还不支持设置不同 LoRA weights的权重，往往效果不太好，存在覆盖或者遗忘的情况。</p>
<h4 id="heading"></h4>
<h4 id="情感实体抽实践--效果展示">情感实体抽实践 | 效果展示</h4>
<p>我最近对使用 LLM 做信息抽取比较感兴趣，因此我微调的目的是让模型做某些特殊场景下的复杂抽取。比如对于下面这段文本（我个人<strong>胡编乱造</strong> 的新闻）：</p>
<pre><code>ChatGPT的提出对谷嘎、万度的搜索业务产生巨大打击，传统搜索引擎的作用性降低了。  
与此同时，OChat，Linguo等新兴语义搜索公司，迅速推出自己的类ChatGPT模型，并结合进自家搜索引擎，受到了很多用户的青睐。  
腾势、艾里等公司表示会迅速跟进ChatGPT和AIGC的发展，并预计在年底前推出自己的大模型。  
大型图片供应商视觉中国称ChatGPT对公司业务暂无影响，还在观望状态。  
（本文图片来自视觉中国，上观新闻为您报道。）  
更多报道：  
- 亚牛逊公司关于AIGC的表态  
- 巨硬公司昨日在A股上市  
</code></pre>
<p>在情感分析中，我们不仅想知道新闻的情感，<strong>更想知道其中涉及的各种实体的情感，以及对应的原因。</strong> 这类似于“方面情感分析”任务，然而LLM时代前的模型很难做好这个任务。</p>
<p>我设计了这样的 instruction：</p>
<pre><code>请从上文中抽取出所有公司，以及对应的在本文中的情感倾向（积极、消极、中性）以及原因。  
请用这样的格式返回：  
{&quot;ORG&quot;:..., &quot;sentiment&quot;:..., &quot;reason&quot;:...}  
</code></pre>
<p>然后交给ChatGPT来做，下面是 <strong>ChatGPT</strong>  的输出：</p>
<pre><code>{&quot;ORG&quot;: &quot;谷嘎&quot;, &quot;sentiment&quot;: &quot;消极&quot;, &quot;reason&quot;: &quot;ChatGPT的提出对谷嘎的搜索业务产生巨大打击&quot;}  
{&quot;ORG&quot;: &quot;万度&quot;, &quot;sentiment&quot;: &quot;消极&quot;, &quot;reason&quot;: &quot;ChatGPT的提出对万度的搜索业务产生巨大打击&quot;}  
{&quot;ORG&quot;: &quot;OChat&quot;, &quot;sentiment&quot;: &quot;积极&quot;, &quot;reason&quot;: &quot;新兴语义搜索公司迅速推出自己的类ChatGPT模型，并受到很多用户的青睐&quot;}  
{&quot;ORG&quot;: &quot;Linguo&quot;, &quot;sentiment&quot;: &quot;积极&quot;, &quot;reason&quot;: &quot;新兴语义搜索公司迅速推出自己的类ChatGPT模型，并受到很多用户的青睐&quot;}  
{&quot;ORG&quot;: &quot;腾势&quot;, &quot;sentiment&quot;: &quot;积极&quot;, &quot;reason&quot;: &quot;表示会迅速跟进ChatGPT和AIGC的发展，并预计在年底前推出自己的大模型&quot;}  
{&quot;ORG&quot;: &quot;艾里&quot;, &quot;sentiment&quot;: &quot;积极&quot;, &quot;reason&quot;: &quot;表示会迅速跟进ChatGPT和AIGC的发展，并预计在年底前推出自己的大模型&quot;}  
{&quot;ORG&quot;: &quot;视觉中国&quot;, &quot;sentiment&quot;: &quot;中性&quot;, &quot;reason&quot;: &quot;称ChatGPT对公司业务暂无影响，还在观望状态&quot;}  
{&quot;ORG&quot;: &quot;亚牛逊&quot;, &quot;sentiment&quot;: &quot;中性&quot;, &quot;reason&quot;: &quot;没有提及具体的情感倾向和原因&quot;}  
{&quot;ORG&quot;: &quot;巨硬&quot;, &quot;sentiment&quot;: &quot;中性&quot;, &quot;reason&quot;: &quot;没有提及具体的情感倾向和原因&quot;}  
</code></pre>
<p>可见效果还是非常好的。</p>
<p>然后我们直接试试 <strong>ChatGLM-6B</strong>  呢：</p>
<pre><code>{&quot;ORG&quot;: &quot;谷嘎&quot;, &quot;sentiment&quot;: &quot;消极&quot;, &quot;reason&quot;: &quot;ChatGPT的提出对谷嘎、万度的搜索业务产生巨大打击，传统搜索引擎的作用性降低了。&quot;}  
{&quot;ORG&quot;: &quot;万度&quot;, &quot;sentiment&quot;: &quot;消极&quot;, &quot;reason&quot;: &quot;ChatGPT的提出对谷嘎、万度的搜索业务产生巨大打击，传统搜索引擎的作用性降低了。&quot;}  
{&quot;ORG&quot;: &quot;OChat&quot;, &quot;sentiment&quot;: &quot;中性&quot;, &quot;reason&quot;: &quot;新兴语义搜索公司，迅速推出自己的类ChatGPT模型，并结合进自家搜索引擎，受到了很多用户的青睐。&quot;}  
{&quot;ORG&quot;: &quot;腾势&quot;, &quot;sentiment&quot;: &quot;中性&quot;, &quot;reason&quot;: &quot;会迅速跟进ChatGPT和AIGC的发展，并预计在年底前推出自己的大模型。&quot;}  
{&quot;ORG&quot;: &quot;艾里&quot;, &quot;sentiment&quot;: &quot;中性&quot;, &quot;reason&quot;: &quot;大型图片供应商视觉中国称ChatGPT对公司业务暂无影响，还在观望状态。&quot;}  
{&quot;ORG&quot;: &quot;亚牛逊&quot;, &quot;sentiment&quot;: &quot;消极&quot;, &quot;reason&quot;: &quot;关于AIGC的表态。&quot;}  
</code></pre>
<p>乍一眼好像还行，但仔细一看，存在<strong>情感理解错误、漏掉实体</strong> 等情况，例如“亚牛逊”应该是中性，&ldquo;腾势&rdquo;、&ldquo;艾里”应该是积极的，漏掉了&quot;视觉中国&rdquo;。</p>
<p>然后，我使用 ChatGPT 的 API(gpt-3.5-turbo) 标注了大概一万多条数据，使用我的仓库进行微调，下面是微调后的效果，姑且称之为 <strong>ChatGLM-6B-lora</strong> ：</p>
<pre><code>{&quot;ORG&quot;: &quot;谷嘎&quot;, &quot;sentiment&quot;: &quot;消极&quot;, &quot;reason&quot;: &quot;搜索业务受到打击&quot;}  
{&quot;ORG&quot;: &quot;万度&quot;, &quot;sentiment&quot;: &quot;消极&quot;, &quot;reason&quot;: &quot;搜索业务受到打击&quot;}  
{&quot;ORG&quot;: &quot;OChat&quot;, &quot;sentiment&quot;: &quot;积极&quot;, &quot;reason&quot;: &quot;迅速推出自己的类ChatGPT模型，并结合进自家搜索引擎，受到了很多用户的青睐&quot;}  
{&quot;ORG&quot;: &quot;Linguo&quot;, &quot;sentiment&quot;: &quot;积极&quot;, &quot;reason&quot;: &quot;迅速推出自己的类ChatGPT模型，并结合进自家搜索引擎，受到了很多用户的青睐&quot;}  
{&quot;ORG&quot;: &quot;腾势&quot;, &quot;sentiment&quot;: &quot;积极&quot;, &quot;reason&quot;: &quot;会迅速跟进ChatGPT和AIGC的发展，并预计在年底前推出自己的大模型&quot;}  
{&quot;ORG&quot;: &quot;艾里&quot;, &quot;sentiment&quot;: &quot;积极&quot;, &quot;reason&quot;: &quot;会迅速跟进ChatGPT和AIGC的发展，并预计在年底前推出自己的大模型&quot;}  
{&quot;ORG&quot;: &quot;视觉中国&quot;, &quot;sentiment&quot;: &quot;中性&quot;, &quot;reason&quot;: &quot;表示ChatGPT对公司业务暂无影响，还在观望状态&quot;}  
{&quot;ORG&quot;: &quot;亚牛逊&quot;, &quot;sentiment&quot;: &quot;中性&quot;, &quot;reason&quot;: &quot;关于AIGC的表态&quot;}  
{&quot;ORG&quot;: &quot;巨硬&quot;, &quot;sentiment&quot;: &quot;中性&quot;, &quot;reason&quot;: &quot;昨日在A股上市&quot;}  
</code></pre>
<p>不解释了，非常不错！</p>
<p>对于<strong>百川大模型（baichuan-7B）</strong> ，这其实是一个基座模型，没有Chat能力，所以原始模型对这样的 instruction 根本无法输出，经过我的微调之后，也具备了听从instruction的能力，称之为 <strong>baichuan-7B-lora</strong>  吧：</p>
<pre><code>{&quot;ORG&quot;:&quot;谷歌&quot;,&quot;sentiment&quot;:&quot;消极&quot;,&quot;reason&quot;:&quot;受到ChatGPT的影响，其作用性下降&quot;}  
{&quot;ORG&quot;:&quot;百度&quot;,&quot;sentiment&quot;:&quot;消极&quot;,&quot;reason&quot;:&quot;同样受到ChatGPT的影响，其作用性下降&quot;}  
{&quot;ORG&quot;:&quot;腾讯&quot;,&quot;sentiment&quot;:&quot;中性&quot;,&quot;reason&quot;:&quot;没有明确表达态度或情绪&quot;}  
{&quot;ORG&quot;:&quot;阿里巴巴&quot;,&quot;sentiment&quot;:&quot;中性&quot;,&quot;reason&quot;:&quot;没有明确表达态度或情绪&quot;}  
{&quot;ORG&quot;:&quot;视觉中国&quot;,&quot;sentiment&quot;:&quot;中性&quot;,&quot;reason&quot;:&quot;目前还没有明显表现出来受ChatGPT的影响，但仍在观察之中&quot;}  
{&quot;ORG&quot;:&quot;亚马逊&quot;,&quot;sentiment&quot;:&quot;中性&quot;,&quot;reason&quot;:&quot;该公司对于AIGC的态度是谨慎而保守的，并没有给出具体评价&quot;}  
{&quot;ORG&quot;:&quot;微软&quot;,&quot;sentiment&quot;:&quot;中性&quot;,&quot;reason&quot;:&quot;该公司的股价已经上涨到历史新高，并且宣布将在国内市场进行二次上市，因此对其未来的发展持乐观态度&quot;}  
</code></pre>
<p>这里有点搞笑，我明明给的新闻都是“谷嘎”，“万度”，“腾势”这样的我编造的公司（虽然大家肯定知道我改编自是哪家公司）这个百川居然都给我掰回来了。。。甚至，“巨硬”它都能给我掰回来成“微软”。。。真不知道是该夸它呢，还是该骂它。</p>
<p>不过，至少也让一个从来都不会听 instruction 的基座模型，听从我的抽取指示进行十分规范地抽取了。</p>
<p>以上。</p>
<p>欢迎大家使用我的这个仓库：</p>
<p>*<strong><a href="https://github.com/beyondguo/LLM-Tuning">https://github.com/beyondguo/LLM-Tuning</a></strong> *</p>
<h4 id="heading-1"></h4>
<h4 id="acknowledgement">Acknowledgement</h4>
<ul>
<li>首先最感谢的是 🤗Huggingface 团队开源的 peft (<a href="https://github.com/huggingface/peft">https://github.com/huggingface/peft</a>) 工具包，懂的都懂！</li>
<li>ChatGLM 的 LoRA 微调代码主要基于 ChatGLM-Tuning (<a href="https://github.com/mymusise/ChatGLM-Tuning">https://github.com/mymusise/ChatGLM-Tuning</a>) 项目中的 LoRA 微调部分修改而来；</li>
<li>baichuan-7B 微调部分，参考了 LLaMA-Efficient-Tuning (<a href="https://github.com/hiyouga/LLaMA-Efficient-Tuning">https://github.com/hiyouga/LLaMA-Efficient-Tuning</a>) 项目中的解决方案；</li>
</ul>
<p>对这些优秀开源项目表示感谢！</p>
<pre><code>**进技术交流群请添加AINLP小助手微信（id: ainlp2)**   


**请备注具体方向+所用到的相关技术点** ![](/images/20230623/8930214020137928598.webp)

**关于AINLP** 

AINLP 是一个有趣有AI的自然语言处理社区，专注于 AI、NLP、机器学习、深度学习、推荐算法等相关技术的分享，主题包括文本摘要、智能问答、聊天机器人、机器翻译、自动生成、知识图谱、预训练模型、推荐系统、计算广告、招聘信息、求职经验分享等，欢迎关注！加技术交流群请添加AINLP小助手微信(id：ainlp2)，备注工作/研究方向+加群目的。

  


  


![](/images/20230623/3932909149814453281.webp)

**阅读至此了，分享、点赞、在看三选一吧🙏** 
</code></pre>



          </div>



<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


