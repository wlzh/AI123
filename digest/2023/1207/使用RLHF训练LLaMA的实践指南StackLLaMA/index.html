

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>使用RLHF训练LLaMA的实践指南：StackLLaMA 作者： AINLP 来源： AINLP 由于LLaMA没有使用RLHF，后来有一个初创公司 Nebuly AI使用LangChain agent生成的数据集对LLaMA模型使用了RLHF进行学习，得到了ChatLLaMA模型，详情请参考：Meta开源的LLaMA性能真如论文所述吗  | AI123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AI123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-cCAOSG8MBO" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2073588164294660"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://ai123.869hr.uk/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://ai123.869hr.uk/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AI123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">使用RLHF训练LLaMA的实践指南：StackLLaMA</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://ai123.869hr.uk/about>AI123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              December 7, 2023 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/N5aX12H1SicnJpa9s3lT7By2uhrJhoeuElGiaGaRcFBfsChUj5KEbqYeKvAK6QyggUsVoRBiczDtGMExGgqk8tO2g/640?wx_fmt=png" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <p>作者： AINLP  来源： <a href="https://mp.weixin.qq.com/s/cgbqbMWNocFXrdKqMpPGnA">AINLP</a></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/nW2ZPfuYqSJuK8UUBxdZXj1c20hUg374YPgXibgDGytAy87YxvVk4WCRFWrdKJPshStrlPJp4vGEGUQodxt7ibOw/640?wx_fmt=jpeg" alt=""></p>
<p>由于LLaMA没有使用RLHF，后来有一个初创公司 Nebuly AI使用LangChain agent生成的数据集对LLaMA模型使用了RLHF进行学习，得到了ChatLLaMA模型，详情请参考：<a href="http://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&amp;mid=2247485849&amp;idx=1&amp;sn=b007fa3df08977b2147fa39594be74d1&amp;chksm=ced54a7df9a2c36ba2915cdc58385b44ebbbe7034043b4dc3321112a34c0c166ffab04fa1ba1&amp;scene=21#wechat_redirect">Meta开源的LLaMA性能真如论文所述吗？如果增加RLHF，效果会提升吗？</a>，其实RLHF未必是必须的，主要是高质量的标注数据获取成本比较高，RLHF是一个trade-off。</p>
<p><strong>StackLLaMA模型介绍</strong></p>
<p>今天分享的StackLLaMA是按照InstructGPT论文的方法获得的，它的目的是，在算法流程上和ChatGPT类似，大致流程如下：</p>
<ul>
<li>
<p>监督微调 (SFT)</p>
</li>
<li>
<p>奖励/偏好建模 (RM)</p>
</li>
<li>
<p>从人类反馈中强化学习 (RLHF)</p>
</li>
</ul>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/N5aX12H1SicnJpa9s3lT7By2uhrJhoeuEgOpkGaOyic1be60ePIrQRqahEzK79sY327GfDXfm0q5L5AuVK2No1ug/640?wx_fmt=png" alt=""></p>
<p><strong>主要区别在于</strong> ：</p>
<p>基础模型：ChatGPT使用的是GPT3.5，StackLLaMA使用的是LLaMA；</p>
<p>SFT阶段：StackLLaMA使用的是StackExchange 数据集</p>
<p>（https://huggingface.co/datasets/HuggingFaceH4/stack-exchange-preferences），而ChatGPT的简单数据没有公开；</p>
<p><strong>StackLLaMA的主要共贡献</strong></p>
<pre><code>* StackLLaMA模型开源了，并且在Huggingface Hub上可以使用，地址：https://huggingface.co/trl-lib/llama-7b-se-rl-peft；

* 集成到Hugging Face TRL库，为广大朋友提供了基础库使用，地址：https://huggingface.co/docs/trl/index；

* 开源了监督训练数据集StackExchange，地址：https://huggingface.co/datasets/HuggingFaceH4/stack-exchange-preferences；

* 开源了数据集和处理笔记本https://huggingface.co/datasets/lvwerra/stack-exchange-paired；

* 介绍了训练过程的细节以及解决方案；

* RLHF库：https://github.com/lvwerra/trl  
</code></pre>
<p><strong>Stack Exchange数据集</strong></p>
<p>该数据集包括来自 StackExchange 平台的问题及其相应的答案（包括针对代码和许多其他主题的 StackOverflow）</p>
<p>根据论文《https://arxiv.org/abs/2112.00861》介绍，给每个答案一个score，公式如下：</p>
<p>score = log2 (1 + upvotes) rounded to the nearest integer, plus 1 if the questioner accepted the answer (we assign a score of −1 if the number of upvotes is negative).</p>
<p>对于奖励模型，始终需要每个问题有两个答案进行比较。对每个问题最多采样 10 个答案对，以限制每个问题的数据点数量。最后，将 HTML 转换为 Markdown 来清理格式，使模型的输出更具可读性。</p>
<p><strong>高效的训练策略</strong></p>
<p>即使训练最小的 LLaMA 模型也需要大量内存，比如bf16，每个参数需要2个字节来存储，fp32需要4个字节，更多可以参考：https://huggingface.co/docs/transformers/perf_train_gpu_one#optimizer。对于一个 7B 参数的模型，只是参数就需要(2+8)*7B=70GB的
内存，实际存储还包括计算注意力分数等中间值，可能需要更多内存。因此，即使是7B的模型也无法在单个 80GB A100 上训练模型。</p>
<p>使用参数高效微调 (PEFT) 技术，比如使用https://github.com/huggingface/peft库来实现，这种技术可以加载8-bit模型执行低秩自适应 (LoRA)，如下图所示：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_gif/N5aX12H1SicnJpa9s3lT7By2uhrJhoeuEYzMRqKdia3OX6yBaTLPaGJrybl7kWK9bmor8UgIeShIe3V8LvXYiciaAQ/640?wx_fmt=gif" alt=""></p>
<p><em>线性层的低秩自适应：在冻结层（蓝色）旁边添加额外参数（橙色），并将生成的编码隐藏状态与冻结层的隐藏状态一起添加。</em></p>
<p>8-bit模型，每个参数只需要一个字节（例如，7B LlaMa 的内存为 7GB）。LoRA 不是直接训练原始权重，而是在某些特定层（通常是注意力层）之上添加小的适配器层；因此，可训练参数的数量大大减少。</p>
<p>在这种情况下，根据batch大小和序列长度不同每十亿个参数大概需要1.2-1.4GB内存，这可以以低成本微调更大的模型（在 NVIDIA A100 80GB 上高达 50-60B 比例模型）。</p>
<p>这些技术可以在消费级设备和 Google Colab 上微调大型模型。比如：facebook/opt-6.7b
（13GB in float16
）和openai/whisper-large
Google Colab（15GB GPU RAM）。更多参考：https://github.com/huggingface/peft和https://huggingface.co/blog/trl-peft</p>
<p>将非常大的模型放入单个 GPU 中，如果训练速度仍然很慢，可以使用数据并行技术，如下图所示：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/N5aX12H1SicnJpa9s3lT7By2uhrJhoeuElQuSiakoXysTn0MiboxIXIGdRDZWmNzeBbtt7E1OqOibEI7KcG6d68eDw/640?wx_fmt=png" alt=""></p>
<p>数据并行可以使用transformers.Trainer和accelerate，无需任何代码更改，只需在使用torchrun
or调用脚本时传递参数即可accelerate launch
。下面分别用accelerate
和在单台机器上运行带有 8 个 GPU 的训练脚本torchrun
。</p>
<ul>
<li>
<ul>
<li></li>
</ul>
</li>
</ul>
<pre><code>accelerate launch --multi_gpu --num_machines 1  --num_processes 8 my_accelerate_script.py
torchrun --nnodes 1  --nproc_per_node 8 my_torch_script.py
</code></pre>
<p><strong>监督微调SFT</strong></p>
<p>首先需要对监督数据做一些处理，传统方式通常是需要保证每个batch中序列长度是一样（采用填充或者截断），与传统的方式不同，GPT模型监督数据是把多个sentence通过EOS标记拼接到一起来使用，如下图所示：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/N5aX12H1SicnJpa9s3lT7By2uhrJhoeuEMVnj7f1VHRhZN9OJPNacY3MQOw15UZM7R6PRsWDPLAmBxgnQ04NoAg/640?wx_fmt=png" alt=""></p>
<p>使用peft加载模型之后就可以使用Trainer训练模型了。具体是：首先</p>
<p>首先导入int8模型，然后加入到训练准备，最后再添加LoRA adapters，代码如下所示：</p>
<hr>
<pre><code># load model in 8bit
model = AutoModelForCausalLM.from_pretrained(
        args.model_path,
        load_in_8bit=True,
        device_map={&quot;&quot;: Accelerator().local_process_index}
    )
model = prepare_model_for_int8_training(model)
  

# add LoRA to model
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias=&quot;none&quot;,
    task_type=&quot;CAUSAL_LM&quot;,
)
  

model = get_peft_model(model, config)
</code></pre>
<p>Note：最终预测的时候需要把LoRA adapters的模型参与与LLaMA模型参数加起来使用。</p>
<p>通过运行脚本（https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/convert_llama_weights_to_hf.py）将它们转换为 🤗 Transformers 格式。</p>
<p><strong>奖励建模和人类偏好</strong></p>
<p>奖励模型的目标是模仿人类如何评价文本。建立奖励模型有几种可能的策略：最直接的方法是预测注释（例如评分或“好”/“坏”的二进制值）。在实践中，更好的方法是预测两个例子的排名，奖励模型必须预测哪一个会被人类标注人员评分更高。</p>
<p>这可以转化为以下损失函数：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/N5aX12H1SicnJpa9s3lT7By2uhrJhoeuEPDAC8A3kGZDSEI6ROzjCN1UG7IRiciczPbDmNCcwbK3miaWMicvb76JnDw/640?wx_fmt=png" alt=""></p>
<p>使用 StackExchange 数据集，我们可以根据分数推断用户更喜欢这两个答案中的哪一个。有了这些信息和上面定义的损失，就可以使用transformers.Trainer
通过添加自定义损失函数来修改。</p>
<hr>
<pre><code>class RewardTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False):
        rewards_j = model(input_ids=inputs[&quot;input_ids_j&quot;],  attention_mask=inputs[&quot;attention_mask_j&quot;])[0]
        rewards_k = model(input_ids=inputs[&quot;input_ids_k&quot;], attention_mask=inputs[&quot;attention_mask_k&quot;])[0]
        loss = -nn.functional.logsigmoid(rewards_j - rewards_k).mean()
        if return_outputs:
            return loss, {&quot;rewards_j&quot;: rewards_j, &quot;rewards_k&quot;: rewards_k}
        return loss
</code></pre>
<p>训练集100000个样本的子集，评估集50000个样本，batch大小为4，采用LoRA adapter（bf16混合精度的Adam优化器）fine-tuning LLaMA模型。LoRA 配置如下：</p>
<hr>
<pre><code>peft_config = LoraConfig(
    task_type=TaskType.SEQ_CLS,
    inference_mode=False,
    r=8,
    lora_alpha=32,
    lora_dropout=0.1,
)
</code></pre>
<p>在 8个A100 GPU 训练了几个小时，训练的Weights &amp; Biases记录地址：https://wandb.ai/krasul/huggingface/runs/wmd8rvq6?workspace=user-krasul</p>
<p>模型最终达到了<strong>67% 的准确率</strong> 。虽然这听起来分数很低，但任务也非常艰巨，即使对于人工标注者也是如此。</p>
<p>如下一节所述，生成的适配器可以合并到冻结模型中并保存以供下游进一步使用。</p>
<p><strong>从人类反馈中强化学习RLHF</strong></p>
<p>有了经过微调的语言模型和奖励模型，我们现在可以运行 RL 循环了。大致分为三个步骤：</p>
<ol>
<li>
<p>根据提示生成响应</p>
</li>
<li>
<p>使用奖励模型对响应进行评分</p>
</li>
<li>
<p>使用评级运行强化学习策略优化步骤</p>
</li>
</ol>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/N5aX12H1SicnJpa9s3lT7By2uhrJhoeuEj7tz8jmGuRUyDLqyIVUN0FvqTppjiaL57wk0QaN5icMfn3SDHfuOicoGQ/640?wx_fmt=png" alt=""></p>
<p>Query and Response模板如下：</p>
<hr>
<pre><code>Question: &lt;Query&gt;
  

Answer: &lt;Response&gt;
</code></pre>
<p>SFT、RM 和 RLHF 阶段使用相同的模板。</p>
<p>使用 RL 训练语言模型的一个常见问题是，奖励模型为了得到高的reward，通常会生成一些完整的乱码序列。为了解决这个问题，在reward中增加了一个KL散度的惩罚，公式如下：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/N5aX12H1SicnJpa9s3lT7By2uhrJhoeuEQQvjxg59Y93l0GFF1p2aCTJicugbJQIXzA5ib3ENII2Qjxic9Knbxz40g/640?wx_fmt=png" alt=""></p>
<p>训练的时候，首先导入8-bit的SFT模型并且冻结参数，然后使用PPO优化LoRA参数，代码如下：</p>
<hr>
<pre><code>for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):
    question_tensors = batch[&quot;input_ids&quot;]
  

    # sample from the policy and generate responses
    response_tensors = ppo_trainer.generate(
        question_tensors,
        return_prompt=False,
        length_sampler=output_length_sampler,
       **generation_kwargs,
    )
    batch[&quot;response&quot;] = tokenizer.batch_decode(response_tensors, skip_special_tokens=True)
  

    # Compute sentiment score
    texts = [q + r for q, r in zip(batch[&quot;query&quot;], batch[&quot;response&quot;])]
    pipe_outputs = sentiment_pipe(texts,**sent_kwargs)
    rewards = [torch.tensor(output[0][&quot;score&quot;] - script_args.reward_baseline) for output in pipe_outputs]
  

    # Run PPO step
    stats = ppo_trainer.step(question_tensors, response_tensors, rewards)
    # Log stats to WandB
    ppo_trainer.log_stats(stats, batch, rewards)
</code></pre>
<p>在 3x8 A100-80GB GPU 上训练了 20 小时，也可以使用更少的资料（例如，在 8 个 A100 GPU 上训练约 20 小时后）。训练过程每个step的reward变化如下图所示：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/N5aX12H1SicnJpa9s3lT7By2uhrJhoeuElGiaGaRcFBfsChUj5KEbqYeKvAK6QyggUsVoRBiczDtGMExGgqk8tO2g/640?wx_fmt=png" alt=""></p>
<p>模型的性能在大约 1000 步后达到稳定状态。</p>
<p><strong>StackLLaMA****模型效果</strong></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/N5aX12H1SicnJpa9s3lT7By2uhrJhoeuE3s7NzkNkIA1sSibroSOcfz2vBCvU5NfH6K772RIjBcqt8oqTOSyQg3w/640?wx_fmt=png" alt=""></p>
<p>答案看起来连贯，甚至提供了一个谷歌链接。让我们来看看接下来的一些训练挑战。</p>
<p><strong>StackLLaMA模型训练的一些坑以及解决方案</strong></p>
<ul>
<li>####<strong>更高的reward意味着更好的表现吗？</strong></li>
</ul>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/N5aX12H1SicnJpa9s3lT7By2uhrJhoeuEUMyUIR2sgey9nG0ZqLU1ZdIjIpPzCI83zsL9mg76e7EDWjMQT2yLRA/640?wx_fmt=png" alt=""></p>
<p>一般来说，在 RL 中希望获得最高的reward，但是在 RLHF 中，使用了一个不完美的奖励模型，PPO 算法将利用这些不完美，这可能表现为奖励的突然增加，但是当我们从策略中查看文本生成时，它们主要包含字符串 ``` 的重复，因为奖励模型发现包含代码块的stack exchange答案reward分数是最高的。幸运的是，这个问题很少被观察到，一般来说，KL 惩罚应该可以抵消这种攻击。</p>
<ul>
<li>####<strong>KL 总是一个正值，不是吗？</strong></li>
</ul>
<p>通常，KL 散度衡量两个分布之间的距离，并且始终为正数。然而，在trl库使用 KL 的估计值时，希望期望分布与实际分布尽可能接近。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/N5aX12H1SicnJpa9s3lT7By2uhrJhoeuEyjff5iaqxBf5nx2llOtiaq7O3TPQzcbjLMsqRwCRZ79diacnvQJOeYiaBQ/640?wx_fmt=png" alt=""></p>
<p>显然，当从概率低于 SFT 模型的策略中采样token时，这将导致负 KL 惩罚，但平均而言它将是正的，否则您将无法从策略中正确抽样。然而，一些生成策略可以强制生成一些token或者可以抑制一些token。例如，当批量生成完成的序列时，会填充序列，当设置最小长度时，EOS 令牌会被抑制。该模型可以为那些导致负 KL 的token分配非常高或低的概率。当 PPO 算法针对奖励进行优化时，它会追逐这些负面惩罚，从而导致不稳定，如下图所示：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/N5aX12H1SicnJpa9s3lT7By2uhrJhoeuEceXetJ7aUp901gOnwibw5kiaBlX92uF0icoMtohpe7pIsRDGLcpCicoGqw/640?wx_fmt=png" alt=""></p>
<p>在生成答案的时候，建议先使用简单的采用策略，后面再提高采用的复杂程度。</p>
<ul>
<li>####<strong>持续的问题</strong></li>
</ul>
<p>还有一些问题需要更好地理解和解决。例如，损失偶尔会出现峰值，这可能会导致进一步的不稳定性。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/N5aX12H1SicnJpa9s3lT7By2uhrJhoeuE3LN0XsBglCic3pl3BwiajT0jEickOYF7HoR5NYYKwtGf6JeBvicooVia1jA/640?wx_fmt=png" alt=""></p>
<p><strong>参考文献</strong> ：</p>
<p>[1] <a href="https://huggingface.co/blog/stackllama">https://huggingface.co/blog/stackllama</a></p>
<p><strong>进技术交流群请添加AINLP小助手微信（id: ainlp2)</strong></p>
<p><strong>请备注具体方向+所用到的相关技术点</strong></p>
<pre><code>![](https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/nW2ZPfuYqSJADkmZ2IX6Z23znAibuEevotDMq9iaMxiapK7jfMibiauGFkycicAJEs6x5U9SGyDJZ0S1tRed9TPNUUDQ/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1)
</code></pre>
<p><strong>关于AINLP</strong></p>
<pre><code>AINLP 是一个有趣有AI的自然语言处理社区，专注于 AI、NLP、机器学习、深度学习、推荐算法等相关技术的分享，主题包括LLM、预训练模型、自动生成、文本摘要、智能问答、聊天机器人、机器翻译、知识图谱、推荐系统、计算广告、招聘信息、求职经验分享等，欢迎关注！加技术交流群请添加AINLP小助手微信(id：ainlp2)，备注工作/研究方向+加群目的。

  


  


![](https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/nW2ZPfuYqSKABHCqVVQkVYPrM4XY1vsd0iaeuXzyJnoFc8cibd5mYb4wdA3WMQtiaPVmr0XLZHMuVibqWncibpnTSnQ/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1)
</code></pre>
<p><strong>阅读至此了，分享、点赞、在看三选一吧🙏</strong></p>
<p>更多AI工具，参考<a href="https://ai123.869hr.uk/">Github-AI123</a>，<a href="https://ai123.869hr.uk/">国内AI123</a></p>



          </div>

可关注我们的公众号：每天AI新工具

<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


