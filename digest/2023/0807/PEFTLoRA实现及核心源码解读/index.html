

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>PEFTLoRA实现及核心源码解读 作者： AINLP 来源： AINLP 1. PEFT 介绍 HuggingFace的PEFT(Parameter-Efficient Fine-Tuning）中提供了模型微调加速的方法，参数高效微调（PEFT）方法能够使预先训练好的语言模型（PLMs）有效地适应各种下游应用，而  | AI123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AI123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-cCAOSG8MBO" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2073588164294660"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://ai123.869hr.uk/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://ai123.869hr.uk/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AI123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">PEFTLoRA实现及核心源码解读</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://ai123.869hr.uk/about>AI123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              August 7, 2023 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/BmOUlEtqycAwHQp0VcviaO8aet5bfuavIvjhUcOWqibPvzaGCxAJiaibhGYNfGGj2oPABenHajFibibhh6KPQUn1uZZg/640?wx_fmt=png" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <p>作者： AINLP  来源： <a href="https://mp.weixin.qq.com/s/PwJexVti0qOH80WIuP5WGQ">AINLP</a></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/nW2ZPfuYqSJuK8UUBxdZXj1c20hUg374YPgXibgDGytAy87YxvVk4WCRFWrdKJPshStrlPJp4vGEGUQodxt7ibOw/640?wx_fmt=jpeg" alt=""></p>
<h4 id="heading"></h4>
<p><strong>1. PEFT 介绍</strong></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/BmOUlEtqycAwHQp0VcviaO8aet5bfuavISReMpSfXwXuaao9OaUULheJFd6gknfickLgkWq4KnictZwsu59lUtvHQ/640?wx_fmt=png" alt=""></p>
<p>HuggingFace的PEFT(Parameter-Efficient Fine-Tuning）中提供了模型微调加速的方法，参数高效微调（PEFT）方法能够使预先训练好的语言模型（PLMs）有效地适应各种下游应用，而不需要对模型的所有参数进行微调。</p>
<p>对大规模的PLM进行微调往往成本过高，在这方面，PEFT方法只对少数（额外的）模型参数进行微调，基本思想在于仅微调少量 (额外) 模型参数，同时冻结预训练 LLM 的大部分参数，从而大大降低了计算和存储成本，这也克服了灾难性遗忘的问题，这是在 LLM 的全参数微调期间观察到的一种现象，同时PEFT 方法也显示出在低数据状态下比微调更好，可以更好地泛化到域外场景，参数高效微调有如下好处</p>
<p>（1）由于在训练时只更新少量参数，可以大大减少GPU显存的使用量，让大语言模型可以在消费级GPU进行训练。</p>
<p>（2）大模型的参数存在冗余，通过参数有效微调可以达到甚至比全参数微调的效果还要好</p>
<p>（3）无需全量保存参数，减少下游子任务参数存储成本</p>
<p>**2.**<strong>LoRA 介绍</strong></p>
<p>LoRA的原理比较简单，原始全量微调就是在原始模型参数上通过微调加入增量W=W0+ΔW，那我们可以通过冻结原始参数W0，并且把增量部分通过低秩分解方式进一步降低参数量级ΔW=A<em>B，原始参数的维度是d</em>d, 则低秩分解后的参数量级是2<em>r</em>d，因为这里的r&laquo;d，因此可以起到大幅降低微调参数量级的效果，如下图</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/BmOUlEtqycDBos9iakpMhWtNnSCianFg7P7yxuyo8BVvELicxHYrf57FYJXpVFopia6UeasvSf2EZngR1grz5y2WYQ/640?wx_fmt=png" alt=""></p>
<p>总结Lora特点：</p>
<p>（1）给原模型增加旁路，通过低秩分解（先降维再升维）来模拟参数的更新量；</p>
<p>（2）训练时，原模型固定，只训练降维矩阵A和升维矩B；</p>
<p>（3）推理时，可将BA加到原参数上，不引入额外的推理延迟；</p>
<p>（4）初始化，A采用高斯分布初始化，B初始化为全0，保证训练开始时旁路为0矩阵（严格讲，对不同算子采用不同的A初始化方式，例如，Linear算子采用kaiming_uniform，对于Embedding算子采用normal高斯分布）；</p>
<p>（5）可插拔式的切换任务，当前任务W0+B1A1，将lora部分减掉，换成B2A2，即可实现任务切换。</p>
<p><strong>3. PEFT 实现****LoRA</strong></p>
<p>基于PEFT框架实现指定模型的LoRA封装非常方便，仅需实例化模型，设置LoRA的config文件，调用get_peft_model方法即可。基于Transformer结构，LoRA一般只对每层的Self-Attention的部分进行微调，即对Wq、Wk、Wv、Wo四个映射层参数进行微调。消融实验显示只微调Wq效果略差，微调Wq、Wv的效果和微调Wq、Wk、Wv、Wo的效果相似（如下所示），以下示例微调Wq、Wv。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/BmOUlEtqycDBos9iakpMhWtNnSCianFg7PARp2icibYb9AJLdXhOC5j9MUwOcpgbm3PbGcian6Wrib5pfLVs932OQYBA/640?wx_fmt=png" alt=""></p>
<p><strong>3.1 PEFT核心类</strong></p>
<p>截至发文，PEFT支持LoRA、Prefix Tuning、P-Tuning、Prompt Tuning、AdaLoRA、Adaption Prompt共六种对大模型高效调参的方法，分别对应框架六个核心方法类即LoraModel、PrefixEncoder、PromptEncoder、PromptEmbedding、AdaLoraModel、AdaptionPromptModel，每个核心方法对应配置文件类为LoraConfig、PrefixTuningConfig、PromptEncoderConfig、PromptTuningConfig、AdaLoraConfig、AdaptionPromptConfig，如下</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/sz_mmbiz_png/BmOUlEtqycAwHQp0VcviaO8aet5bfuavIvjhUcOWqibPvzaGCxAJiaibhGYNfGGj2oPABenHajFibibhh6KPQUn1uZZg/640?wx_fmt=png" alt=""></p>
<p>PeftModel类支持上述六种方法配置文件，对PromptLearning类 (PrefixTuning、PromptEncoder、PromptTuning)和非PromptLearning类（LORA、ADALORA、ADAPTION_PROMPT）不同分支进行处理，得到对应的base_model，其__init__函数如下</p>
<hr>
<pre><code>def __init__(self, model: PreTrainedModel, peft_config: PeftConfig, adapter_name: str = &quot;default&quot;):
    super().__init__()
    self.base_model = model
    self.config = self.base_model.config
    self.modules_to_save = None
    self.peft_config = {}
    self.active_adapter = adapter_name
    self.peft_type = peft_config.peft_type
    self.base_model_torch_dtype = getattr(model, &quot;dtype&quot;, None)
    if not isinstance(peft_config, PromptLearningConfig):
        self.peft_config[adapter_name] = peft_config
        self.base_model = PEFT_TYPE_TO_MODEL_MAPPING[peft_config.peft_type](
            self.base_model, self.peft_config, adapter_name
        )
        self.set_additional_trainable_modules(peft_config, adapter_name)
    else:
        self.add_adapter(adapter_name, peft_config)
  

    if getattr(model, &quot;is_gradient_checkpointing&quot;, True):
        model = self._prepare_model_for_gradient_checkpointing(model)
</code></pre>
<p>根据不同高效调参方法适配PeftModel类得到base_model，不同下游子任务基于PeftModel类构造子任务类，PEFT框架当前支持五种下游子任务，即PeftModelForSequenceClassification、PeftModelForSeq2SeqLM、PeftModelForCausalLM、PeftModelForTokenClassification、PeftModelForQuestionAnswering，这些子任务类就是借助PEFT框架形成的最终的peft_model，用于后续训练与推理。</p>
<p><strong>3.2 LoraModel类的实现</strong></p>
<p>LoraModel类实现对模型Lora化的方法封装，以下显式调用LoraModel实现Lora</p>
<hr>
<pre><code>from transformers import AutoModelForSeq2SeqLM, LoraConfig
from peft import LoraModel, LoraConfig
# step1. Lora配置
config = LoraConfig(peft_type=&quot;LORA&quot;, task_type=&quot;SEQ_2_SEQ_LM&quot;, r=8, lora_alpha=32, target_modules=[&quot;q&quot;, &quot;v&quot;], lora_dropout=0.01,...)
# step2. 预训练模型加载
model = AutoModelForSeq2SeqLM.from_pretrained(&quot;t5-base&quot;)
# step3. 显示生成Lora模型
lora_model = LoraModel(config, model)
</code></pre>
<p>LoraModel是如何实现的呢？其__init__函数如下</p>
<hr>
<pre><code>class LoraModel(torch.nn.Module):
    def __init__(self, model, config, adapter_name):
        super().__init__()
        self.model = model
        self.forward = self.model.forward
        self.peft_config = config
        self.add_adapter(adapter_name, self.peft_config[adapter_name])
</code></pre>
<p>主要实现对预训练模型add_adapter操作，该操作由_find_and_replace和mark_only_lora_as_trainable组成，_find_and_replace找到所有需要加入lora策略的层，例如q_proj，把它们替换成lora模式，mark_only_lora_as_trainable保留lora部分的参数可训练，其余参数全都固定下来不动。</p>
<hr>
<pre><code>  def add_adapter(self, adapter_name, config=None):
      if config is not None:
          model_config = self.model.config.to_dict() if hasattr(self.model.config, &quot;to_dict&quot;) else self.model.config
          config = self._prepare_lora_config(config, model_config)
          self.peft_config[adapter_name] = config
      self._find_and_replace(adapter_name)
      if len(self.peft_config) &gt; 1 and self.peft_config[adapter_name].bias != &quot;none&quot;:
          raise ValueError(
              &quot;LoraModel supports only 1 adapter with bias. When using multiple adapters, set bias to 'none' for all adapters.&quot;
          )
      mark_only_lora_as_trainable(self.model, self.peft_config[adapter_name].bias)
      if self.peft_config[adapter_name].inference_mode:
          _freeze_adapter(self.model, adapter_name)
</code></pre>
<p><strong>3.3 LoraLayer层的实现</strong></p>
<p>定义低秩r、缩放参数alpha、归一化尺度字典scaling、A、B矩阵等，如下</p>
<hr>
<pre><code>class LoraLayer:
    def __init__(self, in_features: int, out_features: int,**kwargs):
        self.r = {}
        self.lora_alpha = {}
        self.scaling = {} # scaling[adapter_name] = lora_alpha / r
        self.lora_dropout = nn.ModuleDict({})
        self.lora_A = nn.ModuleDict({})
        self.lora_B = nn.ModuleDict({})
        # For Embedding layer
        self.lora_embedding_A = nn.ParameterDict({})
        self.lora_embedding_B = nn.ParameterDict({})
        # Mark the weight as unmerged
        self.merged = False
        self.disable_adapters = False
        self.in_features = in_features
        self.out_features = out_features
        self.kwargs = kwargs
  

    def update_layer(self, adapter_name, r, lora_alpha, lora_dropout, init_lora_weights):
        ...
  

    def update_layer_conv2d(self, adapter_name, r, lora_alpha, lora_dropout, init_lora_weights):
        ...
  

    def update_layer_embedding(self, adapter_name, r, lora_alpha, lora_dropout, init_lora_weights):
        ...
  

    def reset_lora_parameters(self, adapter_name):
        ...
</code></pre>
<p>PEFT框架通过直接继承LoraLayer类已内置实现对nn.Linear、nn.Embedding、nn.Conv2d、bnb.nn.Linear8bitLt、bnb.nn.Linear4bit的Lora化支持，代码基本逻辑如下，每个模块可通过LoraLayer.disable_adapters字段决定forward推理中是否使用ΔW参数，使用则是Lora模型参数，否则为原模型参数。</p>
<hr>
<pre><code>class Linear(nn.Linear, LoraLayer): 
  ...
  def forward(self, x: torch.Tensor):
      ...
      if self.disable_adapters:
          if self.r[self.active_adapter] &gt; 0 and self.merged:
              self.unmerge()
      ...
  ...
class Embedding(nn.Embedding, LoraLayer):
  ...
class Conv2d(nn.Conv2d, LoraLayer):
  ...
class Linear8bitLt(bnb.nn.Linear8bitLt, LoraLayer):
  ...
class Linear4bit(bnb.nn.Linear4bit, LoraLayer):
  ...
</code></pre>
<p><strong>3.4 三步实现LoRA及参数解释</strong></p>
<hr>
<pre><code># step1. 参数配置
R = 8
LORA_ALPHA = 16
LORA_DROPOUT = 0.04
TARGET_MODULES = [&quot;q_proj&quot;, &quot;v_proj&quot;]
  

config = LoraConfig(
    r=R,
    lora_alpha=LORA_ALPHA,
    target_modules=TARGET_MODULES,
    lora_dropout=LORA_DROPOUT,
    bias=&quot;none&quot;,
    task_type=&quot;CAUSAL_LM&quot;,
)
  

# step2. 加载transformer预训练模型
model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)
# step3. 获取LoRA模型
model = get_peft_model(model, config)
</code></pre>
<p>PEFT源码中LoraConfig参数描述如下</p>
<hr>
<pre><code>class LoraConfig(PeftConfig):
    &quot;&quot;&quot;
    This is the configuration class to store the configuration of a [`LoraModel`].
  

    Args:
        r (`int`): Lora attention dimension.
        target_modules (`Union[List[str],str]`): The names of the modules to apply Lora to.
        lora_alpha (`int`): The alpha parameter for Lora scaling.
        lora_dropout (`float`): The dropout probability for Lora layers.
        fan_in_fan_out (`bool`): Set this to True if the layer to replace stores weight like (fan_in, fan_out).
        For example, gpt-2 uses `Conv1D` which stores weights like (fan_in, fan_out) and hence this should be set to `True`.:
        bias (`str`): Bias type for Lora. Can be 'none', 'all' or 'lora_only'
        modules_to_save (`List[str]`):List of modules apart from LoRA layers to be set as trainable
            and saved in the final checkpoint.
        layers_to_transform (`Union[List[int],int]`):
            The layer indexes to transform, if this argument is specified, it will apply the LoRA transformations on
            the layer indexes that are specified in this list. If a single integer is passed, it will apply the LoRA
            transformations on the layer at this index.
        layers_pattern (`str`):
            The layer pattern name, used only if `layers_to_transform` is different from `None` and if the layer
            pattern is not in the common layers pattern.
    &quot;&quot;&quot;
</code></pre>
<h4 id="heading-1"></h4>
<p>参数名</p>
<p>含义</p>
<p>r</p>
<p>lora的秩，矩阵A和矩阵B相连接的宽度，r&laquo;d</p>
<p>lora_alpha</p>
<p>尺度缩放参数，lora参数ΔWx乘以 α/r 尺度归一化 ,本质和learning rate相同</p>
<p>lora_dropout</p>
<p>lora层的dropout比率</p>
<p>bias</p>
<p>是否可训练bias，none：均不可；all：均可；lora_only：只有lora部分的bias可训练</p>
<p>modules_to_save</p>
<p>除了lora部分之外，还有哪些层可以被训练，并且需要保存</p>
<p>fan_in_fan_out</p>
<p>只有应用在Conv1D层时置为True，其他情况False</p>
<p>target_modules
指定应用lora的目标模块</p>
<p>**4.**<strong>LoRA 模型微调范式示例</strong></p>
<p>前述得到Lora的模型peft model，接下来如何实现模型存储加载、混合精度训练？这里我们给出一个有代表性的范例，基于该范例根据具体任务做适当调整即可。</p>
<hr>
<pre><code>import datasets
from transformers import Trainer, DataCollatorForSeq2Seq
  

if resume_from_checkpoint:
    lora_weight = torch.load(ckpt_name)
    set_peft_model_state_dict(model, lora_weight)
  

train_data = datasets.load_from_disk(dataset_path)
  

class ModifiedTrainer(Trainer):
    def save_model(self, output_dir=None, _internal_call=False):
        # 改写trainer的save_model，在checkpoint的时候只存lora权重
        from transformers.trainer import TRAINING_ARGS_NAME
  

        os.makedirs(output_dir, exist_ok=True)
        torch.save(self.args, os.path.join(output_dir, TRAINING_ARGS_NAME))
        saved_params = {
            k: v.to(&quot;cpu&quot;) for k, v in self.model.named_parameters() if v.requires_grad
        }
        torch.save(saved_params, os.path.join(output_dir, &quot;adapter_model.bin&quot;))
  

trainer = ModifiedTrainer(
    model=model,
    train_dataset=train_data,
        args=transformers.TrainingArguments(
            per_device_train_batch_size=8,
            gradient_accumulation_steps=16,
            num_train_epochs=10,
            learning_rate=3e-4,
            fp16=True,
            logging_steps=10,
            save_steps=200,
            output_dir=output_dir
        ),
    data_collator=DataCollatorForSeq2Seq(
        tokenizer, pad_to_multiple_of=8, return_tensors=&quot;pt&quot;, padding=True
    ),
)
trainer.train()
model.save_pretrained(train_args.output_dir)
</code></pre>
<p>因为peft model重写了原始model的save_pretrained函数，只把lora层的权重及配置文件进行存储，因此model.save_pretrained只会存储lora权重，这里trainer的save_model函数没有做相应的重写，因此我们重写下对应的function，避免checkpoint写入原始模型全部参数。</p>
<p>总结，本文对PEFT框架、LoRA原理做了简单介绍，也通过代码对PEFT中不同算子Lora化的逻辑和细节进行分析，对这些分析的理解将有助于开发者对不同transformer实现更灵活的Lora模型，助力实现对大模型的微调及应用落地。</p>
<p>*<strong>&mdash;-<img src="https://api.allorigins.win/raw?url=https://res.wx.qq.com/t/wx_fed/we-emoji/res/v1.3.10/assets/newemoji/2_11.png" alt="">END<img src="https://api.allorigins.win/raw?url=https://res.wx.qq.com/t/wx_fed/we-emoji/res/v1.3.10/assets/newemoji/2_11.png" alt="">&mdash;-</strong> *</p>
<p><em>附录：</em></p>
<p><em><a href="https://github.com/huggingface/peft">https://github.com/huggingface/peft</a></em></p>
<p><em><a href="https://github.com/huggingface/safetensors">https://github.com/huggingface/safetensors</a></em></p>
<p><em><a href="https://huggingface.co/docs/transformers/model_doc/rag">https://huggingface.co/docs/transformers/model_doc/rag</a></em></p>
<p><em><a href="https://github.com/microsoft/LoRA">https://github.com/microsoft/LoRA</a></em></p>
<p><em><a href="https://cloud.tencent.com/developer/article/2276508">https://cloud.tencent.com/developer/article/2276508</a></em></p>
<h4 id="heading-2"></h4>
<p><strong>进技术交流群请添加AINLP小助手微信（id: ainlp2)</strong></p>
<p><strong>请备注具体方向+所用到的相关技术点</strong></p>
<pre><code>![](https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/nW2ZPfuYqSJADkmZ2IX6Z23znAibuEevotDMq9iaMxiapK7jfMibiauGFkycicAJEs6x5U9SGyDJZ0S1tRed9TPNUUDQ/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1)
</code></pre>
<p><strong>关于AINLP</strong></p>
<pre><code>AINLP 是一个有趣有AI的自然语言处理社区，专注于 AI、NLP、机器学习、深度学习、推荐算法等相关技术的分享，主题包括LLM、预训练模型、自动生成、文本摘要、智能问答、聊天机器人、机器翻译、知识图谱、推荐系统、计算广告、招聘信息、求职经验分享等，欢迎关注！加技术交流群请添加AINLP小助手微信(id：ainlp2)，备注工作/研究方向+加群目的。

  


  


![](https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/nW2ZPfuYqSKABHCqVVQkVYPrM4XY1vsd0iaeuXzyJnoFc8cibd5mYb4wdA3WMQtiaPVmr0XLZHMuVibqWncibpnTSnQ/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1)
</code></pre>
<p><strong>阅读至此了，分享、点赞、在看三选一吧🙏</strong></p>
<p>更多AI工具，参考<a href="https://ai123.869hr.uk/">Github-AI123</a>，<a href="https://ai123.869hr.uk/">国内AI123</a></p>



          </div>

 可扫如下微信二维码加好友

<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


