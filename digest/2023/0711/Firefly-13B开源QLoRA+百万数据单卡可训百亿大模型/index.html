

<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="theme-color" content="#f9f9f9" />

	<title>Firefly-13B开源，QLoRA&#43;百万数据，单卡可训百亿大模型 作者： AINLP 来源： [AINLP](https://mp.weixin.qq.com/s/yDDC8FZWLeHY9imUukmHqw) 前言 ：欢迎关注我们的中文大语言模型开源项目Firefly(流萤)。目前我们的项目支持对baichuan、ziya、bloom、llama等主流大模型进行指令微调，同时支持全量微调和QLoRA高效微调。我们整理并开源了多个主流  | AI123| ai工具网址导航,ai最新产品</title>
	<link rel="shortcut icon" href="/assets/images/favicon.png" />
    <meta name="keywords" content="chatgpt,AI,AI聊天,AI文本生成,AI绘画,AI编程,AI电商" />
    <meta name="description" content="AI123 网址导航 | 免费chatgpt 汇集各类先进的人工智能产品，旨在帮助用户更快速地了解和使用这些产品,轻松地浏览不同领域的AI产品，包括语音识别、图像处理、自然语言处理。" />
    
    <meta name="baidu-site-verification" content="codeva-cCAOSG8MBO" />
    
    <link rel="stylesheet" id="block-library-css"
        href="/assets/css/block-library.min-5.6.2.css" type="text/css" media="all" />
    <link rel="stylesheet" id="iconfont-css" href="/assets/css/iconfont-3.03029.1.css"
        type="text/css" media="all" />

    
    <link href="/scss/style.min.css" rel="stylesheet" />
    
		    <link rel="stylesheet" id="iowen-css" href="/assets/css/style-3.03029.1.css"
        type="text/css" media="all" />
    <link rel="stylesheet" id="custom-css" href="/assets/css/custom-style.css"
        type="text/css" media="all" />
		
		<link rel="stylesheet" href=/plugins/font-awesome/css/font-awesome.min.css />


    <link rel="stylesheet" id="fortawesome-css" href="/assets/fontawesome-5.15.4/css/all.min.css" type="text/css" />


    <script type="text/javascript" src="/assets/js/jquery.min-3.2.1.js" id="jquery-js"></script>
    <script type="text/javascript" src="/assets/js/content-search.js"  id="content-search-js"></script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2073588164294660"
     crossorigin="anonymous"></script>

	
    <script>
        

		var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8450bc732b2a86f7e4aec4ebd9fd8252";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();

        
    </script>
    

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7071W80M2K"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-7071W80M2K');
    </script>

</head>


    <div class="page-container">
	
	<div id="sidebar" class="sticky sidebar-nav fade animate-nav" style="width: 170px">
        
            <div class="modal-dialog h-100 sidebar-nav-inner">
                <div class="sidebar-logo border-bottom border-color">
                    
                    <div class="logo overflow-hidden">
                        <a href="https://ai123.869hr.uk/" class="logo-expanded">
                            <img src="/assets/images/bt8-expand-light.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt8-expand-dark.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                        <a href="https://ai123.869hr.uk/" class="logo-collapsed">
                            <img src="/assets/images/bt.png" height="40" class="logo-light"
                                alt="AI123| ai工具网址导航,ai最新产品">
                            <img src="/assets/images/bt.png" height="40" class="logo-dark d-none"
                                alt="AI123| ai工具网址导航,ai最新产品">
                        </a>
                    </div>
                    
                </div>
                <div class="sidebar-menu flex-fill">
                    <div class="sidebar-scroll">
                        <div class="sidebar-menu-inner">
                            <ul>
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#00834a9dd147b04c5d53d4368cdb0b57" class="smooth">
                                            <i class="fas fa-sun fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>本月热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db0311e7ecfedd24d157f0ceb4a0897f" class="smooth">
                                            <i class="fas fa-star-and-crescent fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>热门网站</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#21b5cbb2c769010fec3ce029a5f8a4a3" class="smooth">
                                            <i class="far fa-star fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>国内热门</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#8310718935e8ec25ce0350de01e3f7dc" class="smooth">
                                            <i class="fas fa-phone fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>对话工具</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#d58e850d9115797306c2edf61ac6ddd8" class="smooth">
                                            <i class="fas fa-newspaper fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>写作</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2a7418a5f8f1ca4e054364a9300657df" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#7808a68ee1b34dab43011429a12de19e" class="smooth">
                                            <i class="fas fa-image fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>图像处理</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#6729afc51f5ac49a828812fa0eb0c82f" class="smooth">
                                            <i class="fas fa-video fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音视频</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#e5ce844860451fff3faf3d8f8894971d" class="smooth">
                                            <i class="fas fa-music fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>音乐生成</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#db53804b7d726967c58fcc8c9ca03d27" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>办公</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#47b7af9547e034d28fe6f6d439968ac8" class="smooth">
                                            <i class="fas fa-copy fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>提示词</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#41282bf95e43c64d579757573a03cdde" class="smooth">
                                            <i class="fas fa-code fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>编程</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#fd71852fd52d5e18ef4f9a252f1eac58" class="smooth">
                                            <i class="fas fa-search fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>AI搜索</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#81b1637fbe47625dbdf2094acd3b6683" class="smooth">
                                            <i class="fas fa-language fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>文本翻译</span>
                                        </a>
                                    </li>
                                    
                                
                                    
                                    <li class="sidebar-item">
                                        <a href="/#2e9ba3fa6e1ed0e9311b3e97f97f9a40" class="smooth">
                                            <i class="fas fa-book fa-lg fa-lg icon-fw icon-lg mr-2"></i>
                                            <span>学习网站</span>
                                        </a>
                                    </li>
                                    
                                
                            </ul>           
                        </div>
                    </div>
                </div>
                <div class="border-top py-2 border-color">
                    <div class="flex-bottom">
                        <ul>
			    <li id="menu-item-212"
                                 class="menu-item menu-item-type-custom menu-item-object-custom menu-item-212 sidebar-item">
                                 <a href="#friendlink" class="smooth">
                                     <i class="fab fa-staylinked icon-fw icon-lg mr-2"></i>
                                     <span>友情链接</span>
                                 </a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>


<div class="flex-fill grid-bg">
    <div class="big-header-banner">
        <div id="header" class="page-header sticky">
            <div class="navbar navbar-expand-md">
                <div class="container-fluid p-0">

                    <a href="" class="navbar-brand d-md-none" title="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-light"
                            alt="AI123| ai工具网址导航,ai最新产品">
                        <img src="/assets/images/bt.png" class="logo-dark d-none"
                            alt="AI123| ai工具网址导航,ai最新产品">
                    </a>

                    <div class="collapse navbar-collapse order-2 order-md-1">
                        <div class="header-mini-btn">
                            <label>
                                <input id="mini-button" type="checkbox">
                                <svg viewbox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                                    <path class="line--1" d="M0 40h62c18 0 18-20-17 5L31 55"></path>
                                    <path class="line--2" d="M0 50h80"></path>
                                    <path class="line--3" d="M0 60h62c18 0 18 20-17-5L31 45"></path>
                                </svg>
                            </label>

                        </div>

                        <ul class="navbar-nav site-menu" style="margin-right: 16px;">
                        
			<li >
				<a href="/">
                                    <i class="fa fa-home fa-lg mr-2"></i>
                                    <span>首页</span>
                                </a>
				<ul class="sub-menu">
				
				</ul>
			    </li>
			
			</ul>

                        
                        <div class="rounded-circle weather">
                            <div id="he-plugin-simple" style="display: contents;"></div>
                            <script>WIDGET = {
                                    CONFIG: {
                                        "modules": "01234",
                                        "background": 5,
                                        "tmpColor": "008000",
                                        "tmpSize": 14,
                                        "cityColor": "008000",
                                        "citySize": 14,
                                        "aqiColor": "#008000",
                                        "aqiSize": 14,
                                        "weatherIconSize": 24,
                                        "alertIconSize": 18,
                                        "padding": "10px 10px 10px 10px",
                                        "shadow": "1",
                                        "language": "auto",
                                        "borderRadius": 5,
                                        "fixed": "false",
                                        "vertical": "middle",
                                        "horizontal": "left",
                                        "key": "085791e805a24491b43b06cf58ab31e7"
                                    }
                                }
                            </script>
                            <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script>
                        </div>
                        
                    </div>

                    <ul class="nav navbar-menu text-xs order-1 order-md-2">
                        
                        
                        <li class="nav-item mr-3 mr-lg-0 d-none d-lg-block">
                            <script>
                                fetch('https://v1.hitokoto.cn')
                                    .then(response => response.json())
                                    .then(data => {
                                    const hitokoto = document.getElementById('hitokoto_text')
                                    hitokoto.href = 'https://hitokoto.cn/?uuid=' + data.uuid
                                    hitokoto.innerText = data.hitokoto
                                    })
                                    .catch(console.error)
                            </script>                           
                            <div id="hitokoto"><a href="#" target="_blank" id="hitokoto_text">疏影横斜水清浅，暗香浮动月黄昏。</a></div>
                        </li>
                        
                        
                        <li class="nav-search ml-3 ml-md-4">
                            <a href="javascript:" data-toggle="modal" data-target="#search-modal"><i
                                    class="iconfont icon-search icon-2x"></i></a>
                        </li>
                        <li class="nav-item d-md-none mobile-menu ml-3 ml-md-4">
                            <a href="javascript:" id="sidebar-switch" data-toggle="modal"
                                data-target="#sidebar"><i class="iconfont icon-classification icon-2x"></i></a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="placeholder" style="height:74px"></div>
    </div>




<body class="page-body boxed-container  io-grey-mode">
    <main role="main" class="flex-shrink-0">
    <div class="container">
        
        <div class="content">
            <style>
    body{
	    background: #f9f9f9;
	}

    h1, h2, h3, h4, h5, h6 {
        margin-top: 1.5rem;
        margin-bottom: 1.5rem;
    }


 
@media (min-width: 1000px) {
  .container, .container-sm {
    max-width: 800px;
  }
}

</style>

<div class="featured-post-content">

    <a href="/digest/" class="featured-post-title">
       AI 文摘
    </a>

</div>

<section class="blog-single">
  <div class="container">
    <div class="row">

      <div class="col-lg-12 order-1 order-lg-2">
        <article class="single-blog">
          <p class="title">Firefly-13B开源，QLoRA&#43;百万数据，单卡可训百亿大模型</p>
            <br/>
          <ul class="meta">
            <li>
              By <a href=https://ai123.869hr.uk/about>AI123</a>
            </li>
            <li>
              <i class="fa fa-clock-o"></i>
              July 11, 2023 - 2 min read
            </li>
          </ul>

          <div class="_1NCGf">
              <img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/JrHT8u594NHMfnWPD59utZq4URkEficqpZJf8DjqgnT6rF8GkeFJz2BW4Ps3DgSdNMoLBxznQI6NqDa1YnJD4ibQ/640?wx_fmt=jpeg" width="640" >
          </div>
            <br>
            <br>
            <br>
          
          <div class="single-blog-content">
            <pre><code>作者： AINLP  来源： [AINLP](https://mp.weixin.qq.com/s/yDDC8FZWLeHY9imUukmHqw)
</code></pre>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/nW2ZPfuYqSJuK8UUBxdZXj1c20hUg374YPgXibgDGytAy87YxvVk4WCRFWrdKJPshStrlPJp4vGEGUQodxt7ibOw/640?wx_fmt=jpeg" alt=""></p>
<p><strong>前言</strong> ：欢迎关注我们的中文大语言模型开源项目Firefly(流萤)。目前我们的项目支持对baichuan、ziya、bloom、llama等主流大模型进行指令微调，同时支持全量微调和QLoRA高效微调。我们整理并开源了多个主流的高质量的中英文指令数据集，读者可以快速上手微调自己的大模型。</p>
<p>项目地址：https://github.com/yangjianxin1/Firefly</p>
<p>此前，Firefly项目依次开源了firefly-bloom-1b4、firefly-bloom-2b6、firefly-bloom-7b1和firefly-baichuan-7b等中文大模型，这些模型也见证了我们项目的迭代历程。</p>
<p>此次，我们将开源Firefly项目的第一个百亿参数规模的中英文大模型firefly-ziya-13b，该模型基于ziya-13b的预训练权重，使用百万中英文指令数据进行微调。</p>
<p>接下来的章节主要介绍firefly-ziya-13b的基座模型、训练策略、模型效果等。模型权重和训练数据等，详见文末链接。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NEDbyFs3de5HfTmNibGr68TykZVPbib8EbN9ILFYRRSibWKJR913Y2xH9TVvHwqjsiaeJuic09bNZyeQfw/640?wx_fmt=png" alt=""></p>
<p><strong>01</strong></p>
<p>Ziya模型简介</p>
<p>此次我们开源的firefly-ziya-13b模型，正如其名称所示，我们选择了IDEA团队的Ziya-LLaMA-13B-Pretrain-v1作为基座模型。本章节主要对该基座模型进行介绍。</p>
<p>Ziya-LLaMA-13B-Pretrain-v1 是基于LLaMA的130亿参数大规模预训练模型，针对中文分词优化，并完成了中英文 110B tokens 的增量预训练，进一步提升了中文生成和理解能力。</p>
<p>原始数据包含英文和中文，其中英文数据来自openwebtext、Books、Wikipedia和Code，中文数据来自清洗后的悟道数据集、IDEA自建的中文数据集。在对原始数据进行去重、模型打分、数据分桶、规则过滤、敏感主题过滤和数据评估后，最终得到125B tokens的有效数据。</p>
<p>为了解决LLaMA原生分词对中文编解码效率低下的问题，IDEA在LLaMA词表的基础上增加了7k+个常见中文字，通过和LLaMA原生的词表去重，最终得到一个39410大小的词表，并通过复用Transformers里LlamaTokenizer来实现了这一效果。</p>
<p>以下是Ziya-LLaMA-13B-Pertrain-v1 和原始的LLaMA 模型分别在中英文评测集上的表现。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHmBNjsTbI9YiapeORqbwdLbL9R3wEyAIJf9quJo2vlaCibR6NRcEWTpt70dLEsJ7ricr6CL4vhib09oQ/640?wx_fmt=png" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHmBNjsTbI9YiapeORqbwdLbh8mZMNdP6lUlAMDPWuQeYlhYYUgmKDeHStkicdq7xwBhISgxgczWEmw/640?wx_fmt=png" alt=""></p>
<p>可以看到，相比于LLaMA模型，Ziya-LLaMA-13B-Pertrain-v1在中文评测集上的0-shot与5-shot效果都更优秀，证明了其在中文能力上有显著的提升。且两者在英文评测集HELM上的效果基本上持平，在部分子任务上互有胜负，表明其英文能力没有受到较大的损失。</p>
<p>除此之外，我们关注到Ziya官方的sft模型在SuperCLUE中文大模型榜单上的表现也不错。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHmBNjsTbI9YiapeORqbwdLb56aFGpVBApcSrVzHAEezpg0VroGyRupboy3u1CrO1icOEm93A4BvzfQ/640?wx_fmt=png" alt=""></p>
<p>Ziya-LLaMA-13B-Pertrain-v1在增量预训练时，采用的是全量参数训练，而不是LoRA等轻量级微调的方式，理论上来说会比LoRA增量预训练的模型效果更好。</p>
<p>基于上述分析，我们项目选择了Ziya-LLaMA-13B-Pertrain-v1作为13b的基座模型。</p>
<p><strong>02</strong></p>
<p>训练策略</p>
<p>QLoRA是一种可以使用较低成本对大模型进行微调的技术，该方法具有非常不错的效果。QLoRA官方的Guanaco-65b模型在LLM Leaderboard中目前排名第二（<strong>注：该模型仅使用了9千多条OASST1的数据进行微调</strong> ）。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/JrHT8u594NHmBNjsTbI9YiapeORqbwdLb0t7Xa0xK5QS3T8Z6ZlvKiauBp0OkWdQRmKOOvf257jO58RzicZQ4sfog/640?wx_fmt=jpeg" alt=""></p>
<p>Firefly项目中集成了QLoRA训练流程，并且我们已经多次使用QLoRA训练模型，开源了firefly-bloom-7b1和firefly-baichuan-7b模型，获得了不错的效果。基于上述原因，我们依旧采用QLoRA技术训练firefly-ziya-13b模型。</p>
<p>对于QLoRA的原理和训练流程尚不熟悉的同学，可参考我们的往期文章：</p>
<ol>
<li>
<p><a href="http://mp.weixin.qq.com/s?__biz=MzA3MTgwODE1Ng==&amp;mid=2247484183&amp;idx=1&amp;sn=5ed7b3e2eb6a7af36c5900d589d7395a&amp;chksm=9f26a6e4a8512ff26a406ed7cf796b02337ab3f14eda0a5c8eff8b3c5bbb8a239b0272e9a97b&amp;scene=21#wechat_redirect">【QLoRA实战】使用单卡高效微调bloom-7b1，效果惊艳</a></p>
</li>
<li>
<p><a href="http://mp.weixin.qq.com/s?__biz=MzA3MTgwODE1Ng==&amp;mid=2247484205&amp;idx=1&amp;sn=6d42a755d6195b023e357052fcd87475&amp;chksm=9f26a6dea8512fc8c21020ec1bff2cbe32c82816b36fba062f5eb813f0a8f6e5cca226c80d00&amp;scene=21#wechat_redirect">Firefly | QLoRA+百万数据，多卡高效微调bloom-7b1模型</a>。</p>
</li>
<li>
<p><a href="http://mp.weixin.qq.com/s?__biz=MzA3MTgwODE1Ng==&amp;mid=2247484237&amp;idx=1&amp;sn=74650dc9ccef16e887a358a3e7d2bf88&amp;chksm=9f26a6bea8512fa830573cf7af37fb7f436c7df00d8840dd8887d61a4f352c91c98dd27c7060&amp;scene=21#wechat_redirect">Firefly｜百川baichuan-7B实测，QLoRA+百万指令数据微调</a></p>
</li>
</ol>
<p>训练数据方面，我们依旧使用moss-003-sft-data数据，并且从BELLE项目的数学数据中，随机采样了5000条数据。合并之后数据量为100万+，训练一个epoch。</p>
<p>训练时，我们将多轮对话拼接成如下格式，然后进行tokenize。</p>
<ul>
<li></li>
</ul>
<pre><code>&lt;s&gt;input1&lt;/s&gt;target1&lt;/s&gt;input2&lt;/s&gt;target2&lt;/s&gt;...
</code></pre>
<p>在计算loss时，我们通过mask的方式，input部分的loss不参与参数更新，只有“target</s>”部分的loss参与参数更新。这种方式充分利用了模型并行计算的优势，训练更加高效，且多轮对话中的每个target部分都参与了训练，训练更充分。否则，就需要把一个n轮对话，拆分成n条数据，且只计算最后一个target的loss，大大降低了训练效率。</p>
<p>loss计算的实现方式可参考以下代码：</p>
<p><a href="https://github.com/yangjianxin1/Firefly/blob/master/component/loss.py#L3">https://github.com/yangjianxin1/Firefly/blob/master/component/loss.py#L3</a></p>
<p>对于QLoRA，除了embedding和lm_head外，我们在所有全连接层都插入adapter，其中lora_rank为64，lora_alpha为16，lora_dropout为0.05。最终<strong>参与训练的参数量约为2.5亿</strong> 。</p>
<p>训练超参数如下所示：</p>
<p>max length
1024</p>
<p>lr_scheduler_type
constant_with_warmup</p>
<p>batch size
64</p>
<p>lr
1e-4</p>
<p>warmup step
3000</p>
<p>optimizer
paged_adamw_32bit</p>
<p>training step
15k</p>
<p>在单张V100上，使用QLoRA技术并且开启gradient_checkpointing后，可以将batch size设为8，长度设为1024，对13b的模型进行训练，所以读者可以低资源复现我们的模型效果。</p>
<p>模型的训练损失的变化趋势如下图所示，训练损失的下降比较平滑，且比我们之前训练baichun-7b和bloom-7b1时的loss下降得更快更低。训完一个epoch之后，loss尚未有收敛的趋势。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHcdXlG6519jcslBxjzk4yfs0wlDgsbJSqAauVKSZ0GGFCw1Y3UU5haiczqUsGZC4ic9NnjFnPngl5A/640?wx_fmt=png" alt=""></p>
<p><strong>03</strong></p>
<p>使用方式</p>
<p>模型的用法非常简单，直接运行下面的脚本即可，我们提供了单轮对话和多轮对话的脚本。该脚本兼容多模型，只需要修改model_name，即可使用我们之前开源的firefly-bloom-7b1和firefly-baichuan-7b模型。</p>
<p>使用firefly-ziya-13b进行单轮对话的方式如下：</p>
<hr>
<pre><code>from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
&quot;&quot;&quot;
单轮对话，不具有对话历史的记忆功能
&quot;&quot;&quot;
  

  

def main():
    # model_name = 'YeungNLP/firefly-baichuan-7b'
    model_name = 'YeungNLP/firefly-ziya-13b'
    # model_name = 'YeungNLP/firefly-bloom-7b1'
  

    max_new_tokens = 500
    top_p = 0.9
    temperature = 0.35
    repetition_penalty = 1.0
    device = 'cuda'
    input_pattern = '&lt;s&gt;{}&lt;/s&gt;'
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        trust_remote_code=True,
        low_cpu_mem_usage=True,
        torch_dtype=torch.float16,
        device_map='auto'
    ).to(device).eval()
    tokenizer = AutoTokenizer.from_pretrained(
        model_name,
        trust_remote_code=True,
        # llama不支持fast
        use_fast=False if model.config.model_type == 'llama' else True
    )
    text = input('User：')
    while True:
        text = text.strip()
        text = input_pattern.format(text)
        input_ids = tokenizer(text, return_tensors=&quot;pt&quot;, add_special_tokens=False).input_ids.to(device)
        with torch.no_grad():
            outputs = model.generate(
                input_ids=input_ids, max_new_tokens=max_new_tokens, do_sample=True,
                top_p=top_p, temperature=temperature, repetition_penalty=repetition_penalty,
                eos_token_id=tokenizer.eos_token_id
            )
        outputs = outputs.tolist()[0][len(input_ids[0]):]
        response = tokenizer.decode(outputs)
        response = response.strip().replace(text, &quot;&quot;).replace('&lt;/s&gt;', &quot;&quot;).replace('&lt;s&gt;', &quot;&quot;).strip()
        print(&quot;Firefly：{}&quot;.format(response))
        text = input('User：')
  

  

if __name__ == '__main__':
    main()
</code></pre>
<p>使用firefly-ziya-13b进行多轮对话的方式如下：</p>
<hr>
<pre><code>from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
  

  

def main():
    # model_name = 'YeungNLP/firefly-baichuan-7b'
    model_name = 'YeungNLP/firefly-ziya-13b'
    # model_name = 'YeungNLP/firefly-bloom-7b1'
  

    device = 'cuda'
    max_new_tokens = 500    # 每轮对话最多生成多少个token
    history_max_len = 1000  # 模型记忆的最大token长度
    top_p = 0.9
    temperature = 0.35
    repetition_penalty = 1.0
  

    # 加载模型
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        trust_remote_code=True,
        low_cpu_mem_usage=True,
        torch_dtype=torch.float16,
        device_map='auto'
    ).to(device).eval()
    tokenizer = AutoTokenizer.from_pretrained(
        model_name,
        trust_remote_code=True,
        # llama不支持fast
        use_fast=False if model.config.model_type == 'llama' else True
    )
    # 记录所有历史记录
    history_token_ids = tokenizer('&lt;s&gt;', return_tensors=&quot;pt&quot;).input_ids
  

    # 开始对话
    user_input = input('User：')
    while True:
        user_input = '{}&lt;/s&gt;'.format(user_input)
        user_input_ids = tokenizer(user_input, return_tensors=&quot;pt&quot;, add_special_tokens=False).input_ids
        history_token_ids = torch.concat((history_token_ids, user_input_ids), dim=1)
        model_input_ids = history_token_ids[:, -history_max_len:].to(device)
        with torch.no_grad():
            outputs = model.generate(
                input_ids=model_input_ids, max_new_tokens=max_new_tokens, do_sample=True, top_p=top_p,
                temperature=temperature, repetition_penalty=repetition_penalty, eos_token_id=tokenizer.eos_token_id
            )
        model_input_ids_len = model_input_ids.size(1)
        response_ids = outputs[:, model_input_ids_len:]
        history_token_ids = torch.concat((history_token_ids, response_ids.cpu()), dim=1)
        response = tokenizer.batch_decode(response_ids)
        print(&quot;Firefly：&quot; + response[0].strip().replace('&lt;/s&gt;', &quot;&quot;))
        user_input = input('User：')
  

  

if __name__ == '__main__':
    main()
</code></pre>
<p><strong>04</strong></p>
<p>模型效果</p>
<p>下面的样例均为firefly-ziya-13b模型所生成，未经修改，可能存在事实性错误，仅供参考。由于图片中的字体过小，建议放大图片后进行阅读。</p>
<p>更好的阅读效果，以及更丰富的生成样例，请查看文末的共享文档链接。</p>
<p><strong>多轮对话</strong></p>
<p>我们测试了模型的多轮对话能力，效果远超出了我们的预期，非常惊艳。模型在上下文理解、指代消歧方面的能力都非常优秀。即使是非常长的对话历史，模型也能正确地理解用户当前对话意图。**</p>
<p>对话示例1：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqpD6WwO43gLltQLzf9LzyXltC5mia3mQDUtbM9yF64cTE2de13nTwu0icA/640?wx_fmt=png" alt=""><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqpWREfWVL4C4ReyCNGp2Aicicd9rHMtAc8qdnfXaBibRuldqe9QFrNeQvPg/640?wx_fmt=png" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqpGtzDAsA5g0p3AdkauT1QDNcvIVILDhYs5fxDW358uLmKJQfrlEAPmA/640?wx_fmt=png" alt=""></p>
<p>对话示例2：</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqpTXdhGSz79HhUnlLzv0A17Nchpg3FmRav0YgAP65XDz1DbYsmAJfqOw/640?wx_fmt=png" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqpqx26HsEtROwzqPwTHnImhaR2InQTNeRj86spb3veUspBuibbpy0IrbQ/640?wx_fmt=png" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqpoWoJicWCPZvBalcxep4iateojFz0PAz89MtUwMDgkCW2oPbI89u62nnA/640?wx_fmt=png" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqpAx746Hkqzax2Ql1ZDGz9yxiaT2TZfvEB7WDQ6gBVz3jgNfql503ticNw/640?wx_fmt=png" alt=""></p>
<p><strong>数学题</strong></p>
<p>尽管我们只在训练语料中加入了5000条数学题的数据，但是模型依然给了我们很大的惊喜。这5000条数据，激活了模型的数学推理能力，在做一些常见的加减乘除数学题时，大多数情况下，模型能够清晰地给出解题步骤，并给出正确的答案。</p>
<p>仅用5000条数学数据激活模型的数学推理能力，这与LIMA和Guanaco，以及近来的研究结论相契合：知识来源于预训练，指令微调更多是与人类指令对齐，少数高质量的指令数据，即可很大程度激活模型的能力。</p>
<p>由于topp解码方式中带有一定的随机性，有时可能会采样到错误的解题思路，从而得到错误的结果。在解数学题的时候，可以尝试beam search或者贪婪解码等确定性解码策略。</p>
<p>为了避免数学题在训练集中出现过，下面的测试题目均为我们大开脑洞，随机书写的。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqp7xDvUxNxtZVTWe26kd13xqBXc85BvCZiaHFs5KyJCh6U0xPNv1l0YXA/640?wx_fmt=png" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqp0X0icsY9WMWQgnj67niawexZjJhd4NybSepoeHSoT0ic2UP3nKQPpovpQ/640?wx_fmt=png" alt=""></p>
<p><strong>知识库问答</strong></p>
<p>我们从网上找了一些近期的新闻片段，来测试模型的知识库问答能力。模型的表现也相当不错，基本上都能够根据给定的文章内容，生成合适的答案，这在知识库问答场景中有非常大的实用价值。</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqpwnOrHqaBJ1L41NfrhPWjK7BPITCE6NLZHcwpndVZ7awwAARvfqHwwg/640?wx_fmt=png" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqp8ufV6QZlB1tJJrB8v3SwSJM4mVFiaT7vAQEB3sSZZzZ65U6O9gYFNicQ/640?wx_fmt=png" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/JrHT8u594NHMfnWPD59utZq4URkEficqpZJf8DjqgnT6rF8GkeFJz2BW4Ps3DgSdNMoLBxznQI6NqDa1YnJD4ibQ/640?wx_fmt=jpeg" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqp7fq7zzkecAnruxoa2BgheKUputicavXicIq8icVc312pxg657dqXJTyuw/640?wx_fmt=png" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqpuS6ITI1R4CteVchsghTYzFqfXmBwqEOnOwT45c8WtNfyvIjTLHQJuw/640?wx_fmt=png" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqp5j2ooIvGTRtYic20icU7erJGAPUCUzywKTPJ4SgqGzhb2U6erRzp6ic0Q/640?wx_fmt=png" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqpKGRDm933YgFawm0N5ym0SSAJibStlWN84YhSvcuobyicSpDkdGhnjAKA/640?wx_fmt=png" alt=""></p>
<p><strong>医疗问答</strong></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqpgsBWDHFS0owkJ1v2zOJLzaIic3vuUR5yiaSRLx3krO0Ks7MJ9hHt0oew/640?wx_fmt=png" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqpY5udYrW2l3wibI4E5CJa18saF1pgCcRSn49ab9cMjeib2GFymmW3tKog/640?wx_fmt=png" alt=""></p>
<p><strong>中英翻译</strong></p>
<p>我们测试了一些常规的中英翻译case，以及将古诗词翻译成英文的能力，表现也不错，翻译结果与古诗词表达的意境相近。****</p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqps6e6ZqXRgzdNg7NRMMr1KibuXFicCibXJfCy1iaARYiaLIfLatNeqrcgh0w/640?wx_fmt=png" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqptZlN5mqJSHyK0yOmLcob88FgSZgvpmazjv9oZdhtdrXiaDqu1TqYuyA/640?wx_fmt=png" alt=""></p>
<p><strong>邮件生成</strong></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqpTyDicSzZ52CIjeOGvwic71SOfzte6bibSiaJjrgclAj51etzwLwYiaOs6JA/640?wx_fmt=png" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqpiaVDicv97RIXiaKsgg1nVys3B0aYlucguGia4r0GuJkXia65qYGImtl5wrw/640?wx_fmt=png" alt=""></p>
<p><strong>商品文案生成</strong></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqpKf1CTEPg5zZUdrMuumwgHabaN9DpqHlTpsMvZZEFVtogK67O6Px65Q/640?wx_fmt=png" alt=""></p>
<p><strong>其他示例</strong></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqpGy0NujTbJtwLrP96ZBcWgYTMI95iaQGONeuSibvWiclHdqKWGdbumFGibQ/640?wx_fmt=png" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqp5VT3x8eNHLW6DLjIIlyZHqLAf5ic0GM40FCibCuykbicytDGhbED6uq5g/640?wx_fmt=png" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqp9Hw9wOlheZf0kpuL07XQQ5NwzdTkkr2w2V0Q9ibw3UOibFqnYla8WGWQ/640?wx_fmt=png" alt=""></p>
<p><img src="https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_png/JrHT8u594NHMfnWPD59utZq4URkEficqpB1nv9EQsjRHjdSKBiboK19yXkPVvFwgPejGG57YQzHA210nNVVMW9aA/640?wx_fmt=png" alt=""></p>
<p><strong>05</strong></p>
<p>结语</p>
<p>从有限的评测case来看，firefly-ziya-13b具有十分优秀的指令遵从能力，且Ziya-LLaMA-13B-Pretrain-v1+QLoRA的方式，值得在中英文下游任务中进行尝试。</p>
<p>由于尚未在开源测试集或LLM榜单上进行评测，客观的评测结果尚不得知。后续若有时间精力，将会对评测部分的工作进行补充。</p>
<p>后续我们将会在模型量化、推理加速、模型评测等方面对项目进行优化，欢迎大家持续关注Firefly项目：</p>
<p><strong><a href="https://github.com/yangjianxin1/Firefly">https://github.com/yangjianxin1/Firefly</a></strong></p>
<p>欢迎大家到<strong>知乎</strong> 评论区一起讨论交流，点击<strong>阅读原文</strong> 即可跳转到知乎文章。</p>
<p>firefly-ziya-13b权重：</p>
<p><a href="https://huggingface.co/YeungNLP/firefly-ziya-13b">https://huggingface.co/YeungNLP/firefly-ziya-13b</a></p>
<p>Ziya-LLaMA-13B-Pretrain-v1权重：</p>
<p><a href="https://huggingface.co/YeungNLP/Ziya-LLaMA-13B-Pretrain-v1">https://huggingface.co/YeungNLP/Ziya-LLaMA-13B-Pretrain-v1</a></p>
<p>moss数据集：</p>
<p><a href="https://huggingface.co/datasets/YeungNLP/moss-003-sft-data">https://huggingface.co/datasets/YeungNLP/moss-003-sft-data</a></p>
<p>math数据集：</p>
<p><a href="https://huggingface.co/datasets/YeungNLP/school_math_0.25M">https://huggingface.co/datasets/YeungNLP/school_math_0.25M</a></p>
<pre><code>**进技术交流群请添加AINLP小助手微信（id: ainlp2)**   


**请备注具体方向+所用到的相关技术点** 

![](https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/nW2ZPfuYqSJADkmZ2IX6Z23znAibuEevotDMq9iaMxiapK7jfMibiauGFkycicAJEs6x5U9SGyDJZ0S1tRed9TPNUUDQ/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1)



**关于AINLP** 

AINLP 是一个有趣有AI的自然语言处理社区，专注于 AI、NLP、机器学习、深度学习、推荐算法等相关技术的分享，主题包括文本摘要、智能问答、聊天机器人、机器翻译、自动生成、知识图谱、预训练模型、推荐系统、计算广告、招聘信息、求职经验分享等，欢迎关注！加技术交流群请添加AINLP小助手微信(id：ainlp2)，备注工作/研究方向+加群目的。

  


  


![](https://api.allorigins.win/raw?url=https://mmbiz.qpic.cn/mmbiz_jpg/nW2ZPfuYqSKABHCqVVQkVYPrM4XY1vsd0iaeuXzyJnoFc8cibd5mYb4wdA3WMQtiaPVmr0XLZHMuVibqWncibpnTSnQ/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1)

  


**阅读至此了，分享、点赞、在看三选一吧🙏** 
</code></pre>



          </div>

<<<<<<< HEAD

=======
 可扫如下微信二维码加好友
>>>>>>> HEAD@{1}

<p><img src="/images/aitools/2024/03/qrcode_for_gh_dde1b429630d_258.jpg" alt=""></p>

        </article>

      </div>
    </div>
  </div>
</section>
        </div>
    </div>
    </main>




<script type='text/javascript' src='/assets/js/jquery.ui.touch-punch.min-0.2.2.js' id='jqueryui-touch-js'></script>
<script type='text/javascript' src='/assets/js/clipboard.min-5.6.2.js' id='clipboard-js'></script>
<script type='text/javascript' src='/assets/js/tooltip-extend.js' id='iplaycode-nav-js'></script>
<script type='text/javascript' id='popper-js-extra'>
 

var theme = {"ajaxurl":"","addico":"https:\/\/nav.baidu.cn\/wp-content\/themes\/onenav\/images\/add.png","order":"asc","formpostion":"top","defaultclass":"io-grey-mode","isCustomize":"1","icourl":"","icopng":".png","urlformat":"1","customizemax":"10","newWindow":"0","lazyload":"1","minNav":"1","loading":"1","hotWords":"baidu","classColumns":" col-sm-6 col-md-4 col-xl-5a col-xxl-6a ","apikey":"TWpBeU1UVTNOekk1TWpVMEIvZ1M2bFVIQllUMmxsV1dZelkxQTVPVzB3UW04eldGQmxhM3BNWW14bVNtWk4="};
 
</script>
<script type='text/javascript' src='/assets/js/popper.min.js' id='popper-js'></script>
<script type='text/javascript' src='/assets/js/bootstrap.min-4.3.1.js' id='bootstrap-js'></script>
<script type='text/javascript' src='/assets/js/theia-sticky-sidebar-1.5.0.js' id='sidebar-js'></script>
<script type='text/javascript' src='/assets/js/lazyload.min-12.4.0.js' id='lazyload-js'></script>
<script type='text/javascript' src='/assets/js/fancybox.min-3.5.7.js' id='lightbox-js-js'></script>

<script type='text/javascript' src='/assets/js/app-anim.js' id='appanim-js'></script>

<script type="text/javascript">
    $(document).ready(function(){
        var siteWelcome = $('#loading');
        siteWelcome.addClass('close');
        setTimeout(function() {
            siteWelcome.remove();
        }, 600);
    });
</script>
<script>        
    $(document).ready(function(){
        setTimeout(function () {
            if ($('a.smooth[href="' + window.location.hash + '"]')[0]) {
                $('a.smooth[href="' + window.location.hash + '"]').click();
            }else if (window.location.hash != '') {
                $("html, body").animate({
                    scrollTop: $(window.location.hash).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
        }, 300);
        $(document).on('click','a.smooth',function(ev) {
            if($('#sidebar').hasClass('show') && !$(this).hasClass('change-href')){
                $('#sidebar').modal('toggle');
            }
            if($(this).attr("href").substr(0, 1) == "#"){
                $("html, body").animate({
                    scrollTop: $($(this).attr("href")).offset().top - 90
                }, {
                    duration: 500,
                    easing: "swing"
                });
            }
            if($(this).hasClass('go-search-btn')){
                $('#search-text').focus();
            }
            if(!$(this).hasClass('change-href')){
                var menu =  $("a"+$(this).attr("href"));
                menu.click();
                toTarget(menu.parent().parent(),true,true);
            }
        });
        $(document).on('click','a.tab-noajax',function(ev) {
            var url = $(this).data('link');
            if(url)
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').show().attr('href', url);
            else
                $(this).parents('.d-flex.flex-fill.flex-tab').children('.btn-move.tab-move').hide();
        });
        
    });
</script>

<script>

(function(){
    if(document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") === ''){
        if(new Date().getHours() > 22 || new Date().getHours() < 6){
            document.body.classList.remove('io-black-mode');
            document.body.classList.add('io-grey-mode');
            document.cookie = "night=1;path=/";
            console.log('夜间模式开启');
        }else{
            document.body.classList.remove('night');
            document.cookie = "night=0;path=/";
            console.log('夜间模式关闭');
        }
    }else{
        var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
        if(night == '0'){
            document.body.classList.remove('night');
        }else if(night == '1'){
            document.body.classList.add('night');
        }
    }
})();

$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");   
function switchNightMode(){
    var night = document.cookie.replace(/(?:(?:^|.*;\s*)night\s*\=\s*([^;]*).*$)|^.*$/, "$1") || '0';
    if(night == '0'){
	$("#search-bg").css("background", "linear-gradient(#e2c4c4, #d8d8d8)");
        document.body.classList.remove('io-grey-mode');
        document.body.classList.add('io-black-mode');
        document.cookie = "night=1;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","日间模式");
        $(".mode-ico").removeClass("icon-night");
        $(".mode-ico").addClass("icon-light");
    }else{
	$("#search-bg").css("background", "linear-gradient(#4f4040, #1b1d1f)");
        document.body.classList.remove('io-black-mode');
        document.body.classList.add('io-grey-mode');
        document.cookie = "night=0;path=/"
        console.log(' ');
        $(".switch-dark-mode").attr("data-original-title","夜间模式");
        $(".mode-ico").removeClass("icon-light");
        $(".mode-ico").addClass("icon-night");
    }
}
</script>


<script>
    var newsContainer = document.getElementById('news-container');
    var newsItems = document.getElementsByClassName('news-item');
    var currentItem = 0;

    setInterval(function() {
        
        newsItems[currentItem].classList.remove('show');
        newsItems[currentItem].style.transform = 'translateY(-20px)';
        
        currentItem = (currentItem + 1) % newsItems.length;
        newsItems[currentItem].style.transform = 'translateY(' + (newsContainer.offsetHeight - 20) + 'px)';
        setTimeout(function() {
            newsItems[currentItem].classList.add('show');
        }, 500);
    }, 8000);
</script>

</body>
</html>


